{"pages":[],"posts":[{"title":"互联网 Java 工程师进阶知识完全扫盲","date":"2020-09-10T04:00:01.000Z","updated":"2020-09-10T06:19:24.627Z","comments":true,"path":"2020/09/10/互联网 Java 工程师进阶知识完全扫盲/","permalink":"https://binchencoder.github.io/2020/09/10/%E4%BA%92%E8%81%94%E7%BD%91%20Java%20%E5%B7%A5%E7%A8%8B%E5%B8%88%E8%BF%9B%E9%98%B6%E7%9F%A5%E8%AF%86%E5%AE%8C%E5%85%A8%E6%89%AB%E7%9B%B2/","excerpt":"","text":"互联网 Java 工程师进阶知识完全扫盲 本项目大部分内容来自中华石杉，版权归作者所有，内容涵盖高并发、分布式、高可用、微服务、海量数据处理等领域知识。我对这部分知识做了一个系统的整理，方便学习查阅。 学习之前，先来看看 Issues 讨论区的技术面试官是怎么说的吧。本项目也欢迎各位开发者朋友到 Issues 讨论区分享自己的一些想法和实践经验。 Netlify: https://adjava.netlify.app Gitee Pages: https://doocs.gitee.io/advanced-java GitHub Pages: https://doocs.github.io/advanced-java 注：由于本项目站点基于 Docsify 构建，如果你希望在本地运行，请按照以下步骤进行操作： 安装 NodeJS 环境：https://nodejs.org/zh-cn/ 安装 Docsify：npm i docsify-cli -g 使用 Git 克隆本项目到你的本地环境：git clone git@github.com:doocs/advanced-java.git 进入 advanced-java 根目录：cd advanced-java 执行命令，运行本项目：docsify serve 高并发架构消息队列 为什么使用消息队列？消息队列有什么优点和缺点？Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么优点和缺点？ 如何保证消息队列的高可用？ 如何保证消息不被重复消费？（如何保证消息消费的幂等性） 如何保证消息的可靠性传输？（如何处理消息丢失的问题） 如何保证消息的顺序性？ 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？ 如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路。 搜索引擎 ES 的分布式架构原理能说一下么（ES 是如何实现分布式的啊）？ ES 写入数据的工作原理是什么啊？ES 查询数据的工作原理是什么啊？底层的 Lucene 介绍一下呗？倒排索引了解吗？ ES 在数据量很大的情况下（数十亿级别）如何提高查询效率啊？ ES 生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？ 缓存 在项目中缓存是如何使用的？缓存如果使用不当会造成什么后果？ Redis 和 Memcached 有什么区别？Redis 的线程模型是什么？为什么单线程的 Redis 比多线程的 Memcached 效率要高得多？ Redis 都有哪些数据类型？分别在哪些场景下使用比较合适？ Redis 的过期策略都有哪些？手写一下 LRU 代码实现？ 如何保证 Redis 高并发、高可用？Redis 的主从复制原理能介绍一下么？Redis 的哨兵原理能介绍一下么？ Redis 主从架构是怎样的？ Redis 的持久化有哪几种方式？不同的持久化机制都有什么优缺点？持久化机制具体底层是如何实现的？ Redis 集群模式的工作原理能说一下么？在集群模式下，Redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？如何动态增加和删除一个节点？ 了解什么是 Redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？ 如何保证缓存与数据库的双写一致性？ Redis 的并发竞争问题是什么？如何解决这个问题？了解 Redis 事务的 CAS 方案吗？ 生产环境中的 Redis 是怎么部署的？ 分库分表 为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？你们具体是如何对数据库如何进行垂直拆分或水平拆分的？ 现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表动态切换到分库分表上？ 如何设计可以动态扩容缩容的分库分表方案？ 分库分表之后，id 主键如何处理？ 读写分离 如何实现 MySQL 的读写分离？MySQL 主从复制原理是啥？如何解决 MySQL 主从同步的延时问题？ 高并发系统 如何设计一个高并发系统？ 分布式系统面试连环炮系统拆分 为什么要进行系统拆分？如何进行系统拆分？拆分后不用 Dubbo 可以吗？ 分布式服务框架 说一下 Dubbo 的工作原理？注册中心挂了可以继续通信吗？ Dubbo 支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？ Dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？ Dubbo 的 spi 思想是什么？ 如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？ 分布式服务接口的幂等性如何设计（比如不能重复扣款）？ 分布式服务接口请求的顺序性如何保证？ 如何自己设计一个类似 Dubbo 的 RPC 框架？ CAP 定理的 P 是什么？ 分布式锁 Zookeeper 都有哪些应用场景？ 使用 Redis 如何设计分布式锁？使用 Zookeeper 来设计分布式锁可以吗？以上两种分布式锁的实现方式哪种效率比较高？ 分布式事务 分布式事务了解吗？你们如何解决分布式事务问题的？TCC 如果出现网络连不通怎么办？XA 的一致性如何保证？ 分布式会话 集群部署时的分布式 Session 如何实现？ 高可用架构 Hystrix 介绍 电商网站详情页系统架构 Hystrix 线程池技术实现资源隔离 Hystrix 信号量机制实现资源隔离 Hystrix 隔离策略细粒度控制 深入 Hystrix 执行时内部原理 基于 request cache 请求缓存技术优化批量商品数据查询接口 基于本地缓存的 fallback 降级机制 深入 Hystrix 断路器执行原理 深入 Hystrix 线程池隔离与接口限流 基于 timeout 机制为服务接口调用超时提供安全保护 高可用系统 如何设计一个高可用系统？ 限流 如何限流？在工作中是怎么做的？说一下具体的实现？ 熔断 如何进行熔断？ 熔断框架都有哪些？具体实现原理知道吗？ 熔断框架如何做技术选型？选用 Sentinel 还是 Hystrix？ 降级 如何进行降级？ 微服务架构 微服务架构整个章节内容属额外新增，后续抽空更新，也欢迎读者们参与补充完善 关于微服务架构的描述 从单体式架构迁移到微服务架构 微服务的事件驱动数据管理 选择微服务部署策略 微服务架构的优势与不足 Spring Cloud 微服务架构 什么是微服务？微服务之间是如何独立通讯的？ Spring Cloud 和 Dubbo 有哪些区别？ Spring Boot 和 Spring Cloud，谈谈你对它们的理解？ 什么是服务熔断？什么是服务降级？ 微服务的优缺点分别是什么？说一下你在项目开发中碰到的坑？ 你所知道的微服务技术栈都有哪些？ 微服务治理策略 Eureka 和 Zookeeper 都可以提供服务注册与发现的功能，它们有什么区别？ 谈谈服务发现组件 Eureka 的主要调用过程？ …… 海量数据处理 如何从大量的 URL 中找出相同的 URL？ 如何从大量数据中找出高频词？ 如何找出某一天访问百度网站最多的 IP？ 如何在大量的数据中找出不重复的整数？ 如何在大量的数据中判断一个数是否存在？ 如何查询最热门的查询串？ 如何统计不同电话号码的个数？ 如何从 5 亿个数中找出中位数？ 如何按照 query 的频度排序？ 如何找出排名前 500 的数？ Doocs 社区优质项目Doocs 技术社区，致力于打造一个内容完整、持续成长的互联网开发者学习生态圈！以下是 Doocs 旗下的一些优秀项目，欢迎各位开发者朋友持续保持关注。 # 项目 描述 热度 1 advanced-java 互联网 Java 工程师进阶知识完全扫盲：涵盖高并发、分布式、高可用、微服务、海量数据处理等领域知识。 2 leetcode 多种编程语言实现 LeetCode、《剑指 Offer（第 2 版）》、《程序员面试金典（第 6 版）》题解。 3 source-code-hunter 互联网常用组件框架源码分析。 4 jvm Java 虚拟机底层原理知识总结。 5 coding-interview 代码面试题集，包括《剑指 Offer》、《编程之美》等。 6 md 一款高度简洁的微信 Markdown 编辑器。 7 technical-books 值得一看的技术书籍列表。 References 原文链接 公众号Doocs 技术社区旗下唯一公众号「Doocs开源社区」​，欢迎扫码关注，专注分享技术领域相关知识及行业最新资讯。当然，也可以加我个人微信（备注：GitHub），拉你进技术交流群。 关注「Doocs开源社区」公众号，回复 PDF，即可获取本项目离线 PDF 文档（283 页精华），学习更加方便！"},{"title":"架构师技术图谱，助你早日成为架构师","date":"2020-08-20T04:00:08.000Z","updated":"2020-08-21T10:00:39.592Z","comments":true,"path":"2020/08/20/架构师技术图谱，助你早日成为架构师/","permalink":"https://binchencoder.github.io/2020/08/20/%E6%9E%B6%E6%9E%84%E5%B8%88%E6%8A%80%E6%9C%AF%E5%9B%BE%E8%B0%B1%EF%BC%8C%E5%8A%A9%E4%BD%A0%E6%97%A9%E6%97%A5%E6%88%90%E4%B8%BA%E6%9E%B6%E6%9E%84%E5%B8%88/","excerpt":"","text":"架构师技术图谱，助你早日成为架构师 本项目是《码农周刊》架构学习资料精选，码农周刊团队官方出品。架构师必读，助你早日成为架构师！ 架构师技术图谱包括：分布式、前端、大数据、存储、微服务、推荐系统、框架 、消息队列、编程语言、设计模式、重构、集群等内容。 分布式 前端 大数据 存储 微服务 推荐系统 框架 消息队列 编程语言 设计模式 重构 集群 分布式 分布式架构链路追踪：SkyWalking 介绍 漫谈分布式系统 (20)：基于规则的优化 架构设计：分布式服务，库表拆分模式详解 走出微服务误区：避免从单体到分布式单体 熬夜之作：一文带你了解 Cat 分布式监控 初识 etcd 分布式场景下基于重试机制的一致性解决方案 一文读懂 HDFS 架构与设计 MIT 6.824 分布式系统课程第六课之错误容忍：Raft（一） 漫谈分布式事务的那些解决方案 我司用了 6 年的 Redis 分布式限流器，可以说是非常厉害了 架构设计基础：单服务、集群、分布式的基本区别和联系 用匠心精神，打造高可用分布式系统 MIT 6.824 分布式系统课程第四课：主备复制 面试被问分布式事务（2PC、3PC、TCC），这样解释没毛病 MIT 6.824 分布式系统课程第三课：GFS 分布式定时任务调度框架实践 MIT 6.824 分布式系统课程第一课：介绍笔记 2019 我的技术之路：分布式系统到分布式制造 分布式 ID 生成方案 Filebeat + Kafka + ELK 分布式日志收集 [译] 一切系统都是分布式的 (OReilly, 2015) SOSP19’ Ceph 的十年经验总结：文件系统是否适合做分布式文件系统的后端 如果有人再问你怎么实现分布式延时消息，这篇文章丢给他 中间件底层实现的分布式协议之 Raft 在分布式链路下，蚂蚁金服如何快速构建低成本、高可用联调环境？ 解耦并不难：分布式系统中的解耦 分布式唯一 ID 之 Snowflake 算法 漫谈分布式系统（一）：为什么要有分布式系统 技术中台：分布式架构在蚂蚁金服的实践 图解各路分布式 ID 生成算法 ElasticDL：蚂蚁金服开源基于 TensorFlow 的弹性分布式深度学习系统 逻辑时钟：如何刻画分布式中的事件顺序 线性一致性实现原理剖析 XSQL：低门槛、易部署、更稳定的多数据源分布式查询引擎 分布式消息系统设计要点 React Native 分布式热更新系统 端到端一致性，流系统 Spark/Flink/Kafka/DataFlow 对比总结 盘点 Zookeeper 在分布式架构中的应用 [译] 分布式系统经典论文：Google Bigtable 的设计和实现 (OSDI 2006) [译] 分布式系统经典论文：Amazon Dynamo 的设计和实现 (SOSP 2007) Apollo 配置中心：分布式部署 分布式系统原理介绍 高并发场景下分布式实时信令系统的架构实践 8 个月打磨，一份送给程序员的 “分布式系统” 合集 分布式系统关注点：360° 的全方位监控 设计一个分布式 RPC 框架 分布式时序数据库 QTSDB 的设计与实现 轻松构建微服务之分布式配置中心 分布式系统关注点：构建易测试系统的 “六脉神剑” 个推基于 Zipkin 的分布式链路追踪实践 MXNet 结合 kubeflow 进行分布式训练 分布式数据缓存中的一致性哈希算法 聊一聊分布式对象存储解决方案 分布式系统关注点：阻塞与非阻塞有什么区别？ UidGenerator：百度开源的分布式 ID 服务 如何设计一个优秀的分布式系统？ 分布式 ID 生成策略 从一个真实的分布式 ID 案例看如何做架构 近万字长文，设计分布式系统需要考虑因素的都在这里 分布式 TensorFlow 编程模型演进 基于 Redis 和 Lua 的分布式限流 Aloha：一个分布式调度框架的设计与实现 可线性化检查：与 NP 完全问题做斗争 分布式架构设计之架构演进之路 分布式系统设计经典论文 Leaf：美团分布式 ID 生成服务开源 宜信分布式安全服务编排实践 xxl-registry：轻量级分布式服务注册中心 CAP 一致性协议及应用实践 分布式系统关注点：弹性架构 Etcd Raft 使用入门及原理解析 滴滴开源分布式消息中间件产品 DDMQ 企业实施分布式架构的挑战以及应对建议 云端分布式架构下的编程语言：elixir; pattern matching 让 Raft 变快 100 倍：Dragonboat 的写优化 GMKV：分布式 kv 在更美 App 的落地 基于 Licode 的 WebRTC 全球分布式架构 手绘 raft 一致性算法 kingbus：基于 Raft 的分布式 MySQL binlog 存储系统 为自己搭建一个分布式 IM（即时通讯）系统 分布式系统的基石：深入浅出共识算法 [译] 伯克利开源多数据流实时分布式分析系统 Confluo，吞吐超 Kafka 4-10 倍 Ambry：LinkedIn 对象存储论文翻译 Go 分布式实时服务架构 自己写分布式配置中心（上）：单机模式 唯品会分布式强一致日志存储系统 VDL 正式对外开源 浅谈分布式最终一致性 MIT 6.824 学习笔记（一）：MapReduce 详解 用 Redis 实现分布式幂等服务中间件 [译] 深度神经网络的分布式训练概述：常用方法和技巧全面总结 分布式基础，通俗易懂 CAP？ 分布式系统关注点：做了负载均衡就可以随便加机器了吗？ 大规模 MySQL 运维陷阱之基于 MyCat 的伪分布式架构 分布式之消息队列复习精讲 自己写分布式限流组件：基于 Redis 的 RateLimter 分布式高性能 Redis 集群线上常见问题 如果再有人问你分布式 ID，这篇文章丢给他 详解分布式协调服务 ZooKeeper 带着问题学习分布式系统之数据分片 [译] 构建大型支付系统时学到的分布式体系结构概念 分布式数据库 MVCC 技术探秘（二）：混合逻辑时钟 分布式系统关注点：通过 “共识” 达成数据一致性 如何设计分布式系统开关 分布式系统与消息的投递 使用开源技术构建有赞分布式 KV 存储服务 美图分布式 Bitmap 实践：Naix 分布式数据库 MVCC 技术探秘（一） Node.js：浅析高并发与分布式集群 扯什么区块链，应该是分布式账本和面向通证架构 学习分布式不得不会的 CAP 理论 知乎十万级容器规模的分布式镜像仓库实践 主流分布式架构的风流韵事 如何快速开发一个 Dubbo 应用？ Google F1 是如何做 Schema 变更的 [译] 浅显易懂的分布式 TensorFlow 入门教程 Raft 协议学习笔记 基于可靠消息方案的分布式事务（二）：Java 中的事务 青云新一代分布式数据库 RadonDB 开源了 一个 Raft 开源项目的结构分析 分布式跟踪工具 Pinpoint 初探 分布式强一致性数据库的灵魂：Raft 算法 分布式系统：一致性 hash 算法的应用 分布式单点登录框架 XXL-SSO 同为分布式缓存，为何 Redis 更胜一筹？ [译] Uber 是如何用 Kafka 构建可靠的重试处理保证数据不丢失 MPP 的进化：深入理解 Batch 和 MPP 优缺点 Zookeeper 源码：总体流程概览 分布式理论：CAP 是三选二吗？ 分布式系统设计：批处理模式之作业队列系统 GlusterFS 纠删码最佳实践应用 加密货币和区块链（二）：分布式共识与去中心化 饿了么异地多活技术实现（三）：GZS &amp; DAL 分布式技术集锦 漫谈分布式系统、拜占庭将军问题与区块链 Zeppelin：奇虎 360 出品的高性能分布式 KV 存储平台 分布式系统数据层设计模式 跟繁琐的命令行说拜拜，Gerapy 分布式爬虫管理框架来袭 分布式 Redis 架构设计简介 分布式文件系统 FastDFS 详解 ELK 6.0 部署：Elasticsearch + Logstash + Kibana 搭建分布式日志平台 VDL：唯品会强一致、高可用、高性能分布式日志存储介绍 分布式一致性与共识算法 RAID 6 应用于消息队列 分布式系统中的必备良药：RPC 区块链：利用 IPFS 构建自己的去中心化分布式 Wiki 系统 分布式消息队列实现概要 dedid：为分布式数据库而设计的全局唯一 ID（主键）生成器 分布式实时日志分析解决方案 ELK 部署架构 OceanBase 1.0 分布式技术架构 分布式数据库的故障和常见处理机制 日志：分布式系统的核心 Netflix Archaius 分布式配置管理依赖构件 Pegasus：小米出品的分布式 Key-Value 存储系统 XXL-CRAWLER：灵活高效、面向对象的分布式爬虫框架 使用 Redis 实现分布式锁及其优化 Kafka 的复制机制 Zookeeper：分布式过程协同技术详解 浅谈大规模分布式系统中那些技术点 分布式键值存储 Dynamo 的实现原理 浅谈分布式存储系统中的数据一致性要求 [译] 创建一个分布式网络爬虫的故事 分布式文件管理系统 JDFS（五）：整体架构描述 使用 Chaos 测试分布式系统线性一致性 分布式搜索数据库性能探究 微信开源 PhxQueue：高可用、高可靠、高性能的分布式队列 一文教你迅速解决分布式事务 XA 一致性问题 分布式 ID 生成方案概述 分布式系统架构设计 如何用 Go 打造亿级实时分布式出行平台 molten：PHP 应用透明链路追踪工具 分布式流式处理的新贵 Kafka Stream 微服务架构上云最佳实践 如何在 Spring Cloud 分布式系统中实现分布式锁？ 漫谈分布式系统：三种通信范型 [译] 如何选择合适的分布式机器学习平台 浅谈分布式服务协调技术 Zookeeper Hystrix 实现分布式系统中的故障容错 [译] Metrics, tracing 和 logging 的关系 使用 DDAL 快速构建分布式数据库应用 etcd raft 如何实现成员变更 单体中心代码库 vs. 分布式代码库 Laravel + go-micro + grpc 实践基于 Zipkin 的分布式链路追踪系统 分布式系统概念 jd_spider：两只蠢萌京东的分布式爬虫 例解 Poxos 算法 分布式调用链监控资源总结 Angel：腾讯出品的基于参数服务器理念开发的高性能分布式机器学习平台 针对 PHP 做的 Ragnar Fiery 分布式性能跟踪系统 GFS 阅读笔记 自己动手扩展分布式调用链 分布式系统常见的事务处理机制 KAFKA：如何做到 1 秒发布百万级条消息 [译] 再谈 CAP 理论 Kudu：一个融合低延迟写入和高性能分析的存储系统 MapReduce 阅读笔记 Leaf：美团点评分布式 ID 生成系统 微博百万用户分布式压测实践手记 如何打造支撑百万用户的分布式代码托管平台 Voyage：Java 实现的基于 Netty 的轻量、高性能分布式 RPC 服务框架 Spark 自己的分布式存储系统：BlockManager 最大努力通知？No，事务消息 分布式任务队列 Celery 介绍 分布式事务之聊聊 TCC 分布式服务化系统一致性的 “最佳实干” 一个简单的分布式 Web 扫描器的设计与实践 微服务架构下的分布式数据管理 XXL-JOB：分布式任务调度平台 Spark 分布式的基础：通信系统 rpc 腾讯云分布式高可靠消息队列 CMQ 架构 分布式系统研发心得 Golang 高性能分布式游戏服务器框架 mqant Antares：分布式任务调度平台 RPC 基本原理与 Apache Thrift 初体验 OceanBase 1.0 分布式技术架构 万亿级数据洪峰下的分布式消息引擎 分布式系统调用链监控 从 ACID 到 CAP/BASE NewSQL 究竟新在哪里？ 分布式系统本质论（3/3） 不妥协：分布式事务的一致性、可用性和性能 CAP 初窥 深度剖析开源分布式监控 CAT 一名分布式存储工程师的技能树是怎样的？ 分布式锁总结 浅析分布式系统 RSF 分布式 RPC 服务框架的分层设计 自己动手写分布式 KV 存储引擎（二）：网络框架中的定时器原理和实现 JLiteSpider：轻量级的分布式 Java 爬虫框架 分布式会话跟踪系统架构设计与实践 分布式事务（一）：两阶段提交及 JTA 分布式队列编程（优化篇） 探秘阿里分布式任务调度服务 SchedulerX 分布式队列编程：模型、实战 Dora RPC：PHP 的分布式 RPC，支持微服务、服务发现 不懂点 CAP 理论，你好意思说你是做分布式的吗？ SeimiCrawler：敏捷、独立部署、支持分布式的 Java 爬虫框架 分布式系统设计的求生之路 [PPT] 一次重构引发的分布式服务管理 基于 Dubbo 框架构建分布式服务 深入理解分布式系统的 2PC 和 3PC 分布式搜索引擎（二） RPCX：类似 Dubbo 的分布式 RPC 框架 可靠分布式系统基础 Paxos 的直观解释 高性能分布式 Mock 平台的框架与设计 Zipkin：分布式追踪系统 一名分布式存储工程师的技能树是怎样的？ 使用 DRPC 构建分布式多语言编程架构 美团云分布式块存储系统 Ursa 的设计与实现 Sky Walking：对 Java 分布式应用程序集群业务运行情况进行追踪、告警和分析的系统 几个分布式基础算法 zerg：基于 Docker 的分布式爬虫服务 微博分布式存储考试题：案例讲解及作业精选 [译] Dapper，大规模分布式系统的跟踪系统 日志系统之基于 Zookeeper 的分布式协同设计 [译] 当讨论分布式系统时，我们都会讨论些什么？ [译] 设计全球级的分布式、任务关键型应用 分布式文件系统 FastDFS 架构剖析 .NET 大型分布式电子商务架构说明 开源分布式计算系统框架比较 系统分布式情况下最终一致性方案梳理 前端 [译] 高性能前端架构解决方案 前端为什么要关注 Serverless? 一文道尽软件架构及前端架构演进 爱奇艺号微前端架构实践 千万级流量业务的 Serverless 实践，看 FaaS 给前端带来的变化 [译] 不容错过的 Node.js 项目架构 学习 sentry 源码整体架构，打造属于自己的前端异常监控 SDK Egg.js 打造高可用服务集群 闲鱼前端基于 Serverless 的一种多端开发解决方案 2019 JSConf China《面向传统，Serverless 进化之路》分享文字版 巨树：基于 ztree 封装的 Vue 树形组件 你想知道的 React 组件设计模式这里都有（上） 前端要知道的 RESTful API 架构风格 Serverless 掀起新的前端技术变革 记一次前端项目重构要点总结 大型项目前端架构浅谈 简单高性能的 JavaScript 组件框架 Ale.js 前端重构范式之 position 面向体验的重构优化 用微前端的方式搭建类单页应用 前端重构范式之 float layout size-sensor：开源高性能 DOM 元素尺寸监听器 [译] Uber 开源 Fusion.js：一个基于插件架构的通用 Web 框架 Node.js：浅析高并发与分布式集群 微前端快速选型指南 移动应用架构演变及泛前端趋势下移动团队破局 实施前端微服务化的六七种方式 重构 React 组件的实用清单 Web 框架的架构模式探讨（JavaScript 语言） [译] 你需要了解的 23 种 JavaScript 设计模式 Webpack 基本架构浅析 浅谈 Chromium 中的设计模式（一）：Chromium 中模块分层和进程模型 技术雷达之 “微前端”：将微服务理念扩展到前端开发 从 Nuxt.js 学习到了什么 技术雷达之 “微前端”：将微服务理念扩展到前端开发 React 应用架构设计 基于 Egg 的高可靠高性能 React 同构解决方案 beidou 开源了 当 Web 前端架构方案遇上《金瓶梅》 [译] 实现达到 60FPS 的高性能交互动画 [译] 探索 ReactJS 中的 CSS 架构 [译] 如何实现前端微服务化？ webpack 多页应用架构系列（十六）：善用浏览器缓存，该去则去，该留则留 你了解 CSS 设计模式吗？ 前端高并发策略的更深层思考 美团点评酒旅前端的技术体系 [译] 解析 Twitter 前端架构，学习复杂场景数据设计 [译] Twitter Lite 以及大规模的高性能 React 渐进式网络应用 小程序底层框架实现原理解析 API 设计之道 [译] Google 是如何开发 Web 框架的 《webpack 多页应用架构系列》电子书 在重构脚手架中掌握 React / Redux / Webpack2 基本套路 支付宝前端应用架构的发展和选择 [译] Node.js 架构概览 如何重构一个大型历史项目：百度经验改版总结 公司前端开发架构改造 58 同城前后端分离开发模式实践 [译] Redux：一个启发自 Flux 的架构风格 从两个角度，一个小例子浅析 Node.js 架构 前端也应该了解点 Docker 知识：Docker 架构（上） 前端技能训练：重构一 (@Phodal) 大数据 我司用了 6 年的 Redis 分布式限流器，可以说是非常厉害了 Data Lake 架构揭秘 [译] EOS 的 BM：为什么区块链是更好的应用服务器/数据库架构？ 大数据平台架构设计探究 漫谈大数据平台架构 基于 Redis 实现的延迟消息队列 小米 Go 开发实践：用 Go 构建高性能数据库中间件 微服务架构下，MySQL 读写分离后，数据库 CPU 飙升卡壳问题解析 使用 MySQL 模拟 Redis 海量数据实时分析服务技术架构演进 浅谈车联网数据架构的那些坑 端到端一致性，流系统 Spark/Flink/Kafka/DataFlow 对比总结 支撑微信支付的数据库如何提供超 300 万 TPCC 事务处理能力？ 每秒千万级的实时数据处理是怎么实现的？ 流沙：宜信安全数据平台实践 数据与广告系列（七）：广告与推荐系统技术架构 分布式数据缓存中的一致性哈希算法 从零开始入门推荐算法工程师 Alluxio 创始成员范斌：AI 与开源背景下数据架构的演变 基于 Redis 和 Lua 的分布式限流 NutsDB：纯 Go 编写的高性能内嵌型 KV 数据库 那些年用过的 Redis 集群架构 为什么使用主数据思维构建微服务是一种好方式？ 业务库负载翻了百倍，我做了什么来拯救 MySQL 架构？ MIT 6.824 学习笔记（一）：MapReduce 详解 毫秒级从百亿大表任意维度筛选数据是怎么做到的？ 用 Redis 实现分布式幂等服务中间件 携程数据库高可用和容灾架构演进 大规模 MySQL 运维陷阱之基于 MyCat 的伪分布式架构 自己写分布式限流组件：基于 Redis 的 RateLimter 分布式高性能 Redis 集群线上常见问题 海量数据的挑战：微博直播答题架构实践 大数据推荐系统实时架构和离线架构 ZooKeeper 架构设计与角色分工 从单机到 2000 万 QPS：知乎 Redis 平台发展与演进之路 阿里如何实现秒级百万 TPS？搜索离线大数据平台架构解读 分布式数据库 MVCC 技术探秘（二）：混合逻辑时钟 美图大数据平台架构实践 360 大数据中心平台化的演进与实践 金融级数据库的多活架构实践 分布式数据库 MVCC 技术探秘（一） 58 速运架构实战：拆分服务与 DB，突破 “中心化” 瓶颈 面向机器学习数据平台的设计与搭建 [译] Flink 创始人谈流计算核心架构演化和现状 京东推荐系统架构揭秘：大数据时代下的智能化改造 HBase 高性能随机查询之道：HFile 原理解析 沪江订单系统分表项目实践 快速理解 OpenTSDB 的 Schema 设计 Google F1 是如何做 Schema 变更的 理解索引：HBase 介绍和架构 PB 级海量数据服务平台架构设计实践 MySQL 高可用集群方案之 PXC 青云新一代分布式数据库 RadonDB 开源了 [译] 使用 Redis 实现高流量的限速器 BigTable 系统的设计与实现 分布式强一致性数据库的灵魂：Raft 算法 史上最全 Redis 高可用技术解决方案大全 同为分布式缓存，为何 Redis 更胜一筹？ MPP 的进化：深入理解 Batch 和 MPP 优缺点 每天数百亿用户行为数据，美团点评怎么实现秒级转化分析？ 浅谈大数据平台基建的逻辑 分布式系统数据层设计模式 分布式 Redis 架构设计简介 Hulu 大数据架构与应用经验 dedid：为分布式数据库而设计的全局唯一 ID（主键）生成器 OceanBase 1.0 分布式技术架构 分布式数据库的故障和常见处理机制 如何打造千万级 Feed 流系统？ 基于 Redis 的限流系统的设计 使用 Redis 实现分布式锁及其优化 浅谈分布式存储系统中的数据一致性要求 分布式搜索数据库性能探究 人工智能在线特征系统中的生产调度 Redis 在京东到家的订单中的使用 PhxSQL 设计与实现（详细版） 1 对多业务，数据库水平切分架构一次搞定 使用 DDAL 快速构建分布式数据库应用 基于大数据平台的实时质量监控平台的架构设计 一张思维导图学会如何构建高性能 MySQL 系统 美团点评数据库高可用架构的演进与设想 揭秘网易大数据实践与基于微服务的应用架构设计实践 典型数据库架构设计与实践 360 海量数据存储 Zeppelin 设计与实现 搭建一个 Redis 高可用系统 滴滴出行海量数据背后的高可用架构 iOS 无埋点数据 SDK 的整体设计与技术实现 大数据环境下该如何优雅地设计数据分层 美团的大数据平台架构实践 日处理 20 亿数据，实时用户行为服务系统架构实践 CRS：腾讯云 Redis 产品架构解析 微服务架构下的分布式数据管理 中华万年历大数据平台演进 京东发布 MySQL Group Replication 官方文档中文版 微店索引数据 dump 架构演进 OceanBase 1.0 分布式技术架构 万亿级数据洪峰下的分布式消息引擎 Gores：Go 语言编写的基于 Redis 的消息队列系统 MySQL 高性能存储引擎：TokuDB 初探 [译] 不使用 Trigger 的设计理念 NewSQL 究竟新在哪里？ 神策分析的技术选型与架构实现 MySQL 数据库中间件的高可用方案 数据系统架构：Lambda architecture 用 MHA 轻松实现 MySQL 高可用（一） 大数据环境下互联网行业数据仓库/数据平台的架构之漫谈（续） 海量高性能列式数据库 HiStore 技术架构解析 MySQL 架构优化实战系列（二）：主从复制同步与查询性能调优 iOS MVVM 架构：界面与数据 I/O 逻辑分离的实践 Redis 字符串类型实现内幕 乐视秒杀：每秒十万笔交易的数据架构解读 从日志统计到大数据分析（十六）：元 秒级处理海量数据，浙江移动大数据平台是怎么做到的？ Hadoop NameNode 高可用 (High Availability) 实现解析 用 Swift 搭建数据驱动型 iOS 架构 [译] 数据处理平台架构中的 SMACK 组合 大数据 / 数据挖掘 / 推荐系统 / 机器学习相关资源 我所理解的大数据个性化推荐 数据库软件架构设计些什么 基于用户画像大数据的电商防刷架构 存储 Ambry：LinkedIn 对象存储论文翻译 唯品会分布式强一致日志存储系统 VDL 正式对外开源 使用开源技术构建有赞分布式 KV 存储服务 天池中间件大赛：单机百万消息队列存储分享 GlusterFS 纠删码最佳实践应用 Zeppelin：奇虎 360 出品的高性能分布式 KV 存储平台 VDL：唯品会强一致、高可用、高性能分布式日志存储介绍 Pegasus：小米出品的分布式 Key-Value 存储系统 分布式键值存储 Dynamo 的实现原理 浅谈分布式存储系统中的数据一致性要求 badger：一个高性能的 LSM K/V store 我跟存储的这 10 年 360 海量数据存储 Zeppelin 设计与实现 Kudu：一个融合低延迟写入和高性能分析的存储系统 Spark 自己的分布式存储系统：BlockManager 微信红包订单存储架构变迁的最佳实践 MySQL 高性能存储引擎：TokuDB 初探 一名分布式存储工程师的技能树是怎样的？ 自己动手写分布式 KV 存储引擎（二）：网络框架中的定时器原理和实现 Android 存储系统之架构篇 一名分布式存储工程师的技能树是怎样的？ 美团云分布式块存储系统 Ursa 的设计与实现 微博分布式存储考试题：案例讲解及作业精选 微服务 微服务如何对齐业务架构 [译] 如何使用 Istio 1.6 管理多集群中的微服务？ 走出微服务误区：避免从单体到分布式单体 一次漫长的 Dubbo 网关内存泄露排查经历 微服务、DevOps…不是效率银弹，请同时升级你的管理方式 微服务超全的设计选型参考 微信 10 亿日活场景下，后台系统微服务架构实践 Spring Cloud 微服务：阿里开源组件 Nacos，服务和配置管理 [译] 5 分钟搭建 Node.js 微服务原型 花椒直播 Kong 应用实践 微服务杂谈 企业级微服务解决方案 v3.2.0 发布 Spring Boot 与微服务从 0 到 1 的实践 微服务统一认证与授权的 Go 语言实现（上） 不是银弹：关于微服务的一点思考 CODING 微服务架构演进之路 探探如何三个月完成微服务改造，以及踩过的 “坑” 余额宝背后的服务治理架构 2w 字长文，让你瞬间拥有 “调用链” 开发经验 腾讯微服务框架 Tars 的 Go 性能提升之路 Go 微服务全链路跟踪详解 微服务架构之网关层 Zuul 剖析 .NET Core 微服务网关 Bumblebee 架设 微服务架构下，MySQL 读写分离后，数据库 CPU 飙升卡壳问题解析 微服务 API 通过 ip 可访问，域名不可访问问题分析 Service Mesh 发展趋势（续）：棋到中盘路往何方 互联网架构微服务已经成为主流，Go 语言如何去打造呢？ 万字长文全面解析 GraphQL，携程微服务背景下的前后端数据交互方案 颠覆微服务认知：深入思考微服务的七个主流观点 微服务中使用 OpenJ9 JVM 内存占用降 60%（相对 HotSpot） 高性能微服务网关 .NETCore 客户端 Kong.Net 开源发布 微服务任务调度平台 SIA-TASK 入手实践 [译] 为什么微服务适合我们 微服务架构与领域驱动设计应用实践 [译] 容器、微服务和服务网格简史 轻松构建微服务之分布式配置中心 个推基于 Zipkin 的分布式链路追踪实践 可落地的 DDD（三）：如何利用 DDD 进行微服务的划分 轻松构建微服务之远程调用 微服务架构下的配置管理：Apollo 土味微服务 微服务化后缓存怎么做 最全的微服务知识科普 聊一聊微服务网关 kong 近期的模型变迁 小团队微服务落地实践 [译] 未来我们对微服务和 Serverless 架构有什么期望 [译] 混合微服务模式 微保 API 网关的探索与实践 [译] 使用 Grab 的实验平台进行混沌实验编排 离不开的微服务架构，脱不开的 RPC 细节 小团队的微服务之路 对没有监控的微服务 Say No 虎牙直播在微服务改造方面的实践和总结 B 站基于大仓库的 CI/CD 及微服务实践 从 “挖光缆” 到 “剪网线”：蚂蚁金服异地多活单元化架构下的微服务体系 重新理解 Martin Fowler 对微服务的定义 小型系统如何 “微服务” 开发 Kafka 如何解决常见的微服务通信问题 为什么使用主数据思维构建微服务是一种好方式？ [译] 微服务通信的设计模式 随行付微服务之数据同步 Porter [译] 微服务设计指南 走进 Service Mesh Restful API 监控实践 DAGOR：微信微服务过载控制系统（附论文） 微服务测试的思考与实践 基于 Spring Cloud 的微服务架构演变史 致传统企业朋友：不够痛就别微服务，有坑 讨论微服务之前，你知道微服务的 4 个定义吗？ 个推基于 Docker 和 Kubernetes 的微服务实践 爱奇艺视频后台从 “单兵作战” 到 “团队协作” 的微服务实践 基于 consul 实现微服务的服务发现和负载均衡 认证鉴权与 API 权限控制在微服务架构中的设计与实现：升级 SOFA 微服务多语言演进 用微前端的方式搭建类单页应用 为啥我用了微服务架构，软件还是不好修改啊？ 携程微服务架构下的测试浅谈 [译] 推荐 30 个用于微服务的顶级工具 [译] 微服务的 10 个挑战和解决方案 服务框架的技术栈 如何构建安全的微服务应用 深入解读 Service Mesh 背后的技术细节 微前端快速选型指南 Spring Cloud 微服务版本灰度发布新神器 微服务设计模式之 API 网关 基于 Restful 的微服务架构 微服务架构实践：API Gateway 实施前端微服务化的六七种方式 蚂蚁金服大规模微服务架构下的 Service Mesh 探索之路 苏宁数据中台基于 Spring Cloud 微服务架构实践 微服务化的基石：持续集成 基于微服务的日志中心设计、实现与关键配置 Go 微服务实战汇总 微服务化之缓存的设计 API 管理的正确姿势：API Gateway Netflix 的微服务是如何分层的 Eureka + Zuul + Feign + Hystrix 构建微服务架构 如何基于 Golang 设计一套微服务架构 微服务 2.0 技术栈选型手册 从跨语言调用到 dubbo2.js 51 信用卡在微服务架构下的监控平台架构实践 [译] 事件溯源|日志记录：一个基础的微服务模式 无服务器架构下的运维 从零搭建一个基于 Istio 的服务网格 Service Mesh 及其主流开源实现解析 罗辑思维 Go 语言微服务改造实践 基于 Spring Cloud 的 Microservices 架构实战案例：配置文件属性内容加解密 为什么 Kubernetes 天然适合微服务？ 腾讯出品的微服务框架的名字服务解决方案 TSeer 正式开源 微服务化的不同阶段 Kubernetes 的不同玩法 从 Spring Cloud 看一个微服务框架的 “五脏六腑” 基于 Spring Cloud 的 Microservices 架构实战案例：架构拆解 基于 Spring Cloud 的微服务落地 认证鉴权与 API 权限控制在微服务架构中的设计与实现：授权码模式 微网关与服务啮合 全面解析京东微服务平台 手把手教你搭建一套可自动化构建的微服务框架 微服务架构下的立体监控系统设计和实现 基于 Sanic 的微服务基础架构 技术雷达之 “微前端”：将微服务理念扩展到前端开发 使用 Istio 治理微服务入门 技术雷达之 “微前端”：将微服务理念扩展到前端开发 TDD 开发容器化的 Python 微服务应用（一） Go 使用 grpc + http 打造高性能微服务 [译] 如何设计实现真正的响应式微服务系统？ 腾讯与阅文技术合作，微服务框架 Tars 再添 PHP 阿里云基于 Go 的微服务架构分享 [译] 微服务从设计到部署（七）：重构单体为微服务 [译] 微服务生态系统的 4 层模型 Kubernetes、微服务以及 Service Mesh 微服务 API 级权限的技术架构 微服务的 4 个设计原则和 19 个解决方案 php-msf：基于 Swoole 的工程级企业微服务框架 [译] 微服务从设计到部署（二）：使用 API 网关 轻量级微服务架构及最佳部署 连接管理安全化微服务的利器 Istio [译] 微服务从设计到部署（一）：微服务简介 [译] 设计一个容错的微服务架构 如何构建微服务架构 微服务架构上云最佳实践 swoft：基于 Swoole 协程 2.x 的高性能 PHP 微服务框架 [译] 使用 Spring Cloud 和 Docker 构建微服务架构 [译] 如何实现前端微服务化？ 几种常见的微服务架构方案简述：ZeroC IceGrid、Spring Cloud、基于消息队列 微服务注册发现集群搭建：Registrator + Consul + Consul-template + nginx [译] REST？RPC？是时候改变你对微服务的认知了 京麦微服务技术架构演变之下的 618 备战实践 NHMicro：脚本化微服务框架 详解微服务实践从架构到部署 Istio：Google、IBM 和 Lyft 联合开源的微服务 Service Mesh 框架 微服务初级设计指南 多研究些架构，少谈些框架（二）：微服务和充血模型 揭秘网易大数据实践与基于微服务的应用架构设计实践 解析微软微服务架构 eShopOnContainers（一） [译] 为了更好地支持微服务，我们从 PHP 迁移到了 Go 自己动手扩展分布式调用链 华尔街见闻基于 Golang 的微服务实践 《微服务设计》之演化式架构师 基于 Spring Cloud 的微服务架构 v1.0 StatsD 使用小结 《微服务设计》读书笔记之微服务 为基于 Spring Boot 的微服务架构搭建一套自动化、集中管理的 API 文档中心 腾讯自用的微服务架构 Tars 正式开源 微服务架构下的分布式数据管理 使用微服务架构重构支付网关 Faas，又一个未来？ [译] Uber 微服务经验谈 微服务部署：蓝绿部署、滚动部署、灰度发布等部署方案对比与总结 Spring Cloud 构建微服务架构（一）：服务注册与发现 微服务架构的基础框架选择：Spring Cloud 还是 Dubbo？ 微服务的反模式和陷阱 阿里巴巴前架构师 360 度无死角剖析微服务 spring-cloud-netflix-example：基于 Spring Cloud 的微服务实例 产品级微服务的八大原则 微服务场景下的自动化测试 [译] REST 和微服务：用异步交互分解单体系统 [译] 微服务到头了？ [译] 用 Spring Cloud 治理微服务 Dora RPC：PHP 的分布式 RPC，支持微服务、服务发现 [译] NGINX 微服务参考架构简介 微服务的团队应对之道 微服务独家笔记 [译] 微服务即演进式架构 [译] 介绍 Nginx 微服务参考架构 [译] 从微服务同步 REST 的天然缺陷说起 [译] Cookpad 基于 Docker 的微服务经验总结 Golang 微服务工具包 实施微服务，我们需要哪些基础框架？ [译] Rails 微服务架构 [译] 无服务器的微服务 极速切入 Spring Boot 微服务框架 (float.lu) 谈谈微服务 (王福强) [译] Martin Folwer 谈微服务的优缺点 (黄帅) [译] 构建微服务：使用 API Gateway (陈杰) [译] 微服务实战（一）：微服务架构的优势与不足 (杨峰) 推荐系统 基于 DNN 的推荐算法介绍 B站的视频，都是怎么推荐的 推荐系统中不得不说的 DSSM 双塔模型 推荐系统的人工调控 推荐系统提供 web 服务的 2 种方式 [译] 如何使用深度学习模型构建推荐系统？ 推荐算法团队介绍 推荐系统的 UI 交互与视觉展示 wide &amp; deep 在贝壳推荐场景的实践 混合推荐系统介绍 微信开发工程师带你一文了解推荐领域最新工作 推荐技术系列（四）：利用社交关系的隐式矩阵分解原理和实践 YouTube 基于多任务学习的视频排序推荐系统 Facebook 面向个性化推荐系统的深度学习推荐模型 深度学习在推荐系统中的应用 如何优化大规模推荐？下一代算法技术 JTM 来了 基于 Flink 实现的商品实时推荐系统 序列推荐模型 TransFM 矩阵分解推荐算法 论文：基于三部图网络结构的知识推荐算法 《推荐系统开发实战》之冷启动问题 《推荐系统开发实战》之推荐系统的灵魂伴侣：数据挖掘 基于 Erlang 语言的视频相似推荐系统 推荐系统之矩阵分解模型（原理篇） 数据与广告系列（七）：广告与推荐系统技术架构 构建可解释的推荐系统 从零开始入门推荐算法工程师 推荐系统冷启动 深度召回模型在 QQ 看点推荐中的应用实践 机器学习在微博信息流推荐中的应用实践 推荐系统融合排序之 LR 重读 YouTube 深度学习推荐系统论文 58 部落帖子推荐系统的抬手动作 大数据推荐系统实时架构和离线架构 2018 年最全的推荐系统干货 [译] 2018 年推荐系统入门指南 京东推荐系统架构揭秘：大数据时代下的智能化改造 推荐系统遇上深度学习（十五）：强化学习在京东推荐中的探索 推荐系统遇上深度学习（十一）：神经协同过滤 NCF 原理及实战 从先进走向普遍的广告和推荐系统方法之一：在线学习 微软亚洲研究院论文解读：GAN 在网络特征学习中的应用 深度学习在 58 同城智能推荐系统中的应用实践 深度学习在推荐系统上的应用 今日头条推荐算法原理全文详解 从原理到策略算法再到架构产品看推荐系统 [译] 一分钟整明白 Netflix 的 Contextual Bandits 的推荐探索策略 融合了用户兴趣的推荐系统才更具个性 就算是非技术人员也都有必要了解的一些推荐系统常识 推荐系统之用户行为分析 推荐系统那些事儿 3 亿会员、4 亿商品，深度学习在大型电商商品推荐的应用实践 深度学习在美团点评推荐平台排序中的运用 今日头条成功的核心技术秘诀是什么？ [译] 亚马逊推荐二十年 蘑菇街推荐工程实践 写给设计师的人工智能指南：推荐系统 Pinterest 推荐系统四年进化之路 深度学习在推荐领域的应用 Deep Learning for Recommendation Systems Bandit 算法与推荐系统 深度学习在推荐算法上的应用进展 魅族推荐平台的架构演进之路 淘宝搜索/推荐系统背后深度强化学习与自适应在线学习的实践之路 [译] 工作职位推荐系统的算法与架构 基于用户画像的实时异步化视频推荐系统 兴趣 Feed 技术架构与实现 推荐系统老司机的十条经验 推荐系统的苟且和远方 [译] 如何从零构建实时的个性化推荐系统？ 大数据 / 数据挖掘 / 推荐系统 / 机器学习相关资源 为豆瓣电影实现 User-based 协同过滤的推荐系统 推荐系统基础知识 美团推荐系统整体框架与关键工作 (沈国阳) 使用 Python 实现一个简单的推荐系统 (Kai Zhou) 框架 分布式定时任务调度框架实践 腾讯微服务框架 Tars 的 Go 性能提升之路 花椒移动端基础框架架构 设计一个分布式 RPC 框架 [译] Linkerd or Istio？哪个 Service Mesh 框架更适合你？ Golang 轻量级高并发 socket 框架 chitchat Aloha：一个分布式调度框架的设计与实现 架构认知（二）：企业架构的框架和作用 简单高性能的 JavaScript 组件框架 Ale.js [译] 评估 Kubernetes 中的 Serverless 框架 [译] Uber 开源 Fusion.js：一个基于插件架构的通用 Web 框架 服务框架的技术栈 Scala 实现 DSL 的框架案例 Web 框架的架构模式探讨（JavaScript 语言） 腾讯出品的微服务框架的名字服务解决方案 TSeer 正式开源 分布式单点登录框架 XXL-SSO 蚂蚁通信框架实践 从 Spring Cloud 看一个微服务框架的 “五脏六腑” swoolefy：基于 Swoole 扩展实现的高性能 MVC 框架 手把手教你搭建一套可自动化构建的微服务框架 跟繁琐的命令行说拜拜，Gerapy 分布式爬虫管理框架来袭 设计和实现一款轻量级的爬虫框架 Blade：高性能、简洁优雅的 Java Web 框架 Log4a：基于 mmap 的高性能、高可用的 Android 日志收集框架 Android 高级进阶（源码剖析篇）：Twitter 的高性能序列化框架 Serial（一） 腾讯与阅文技术合作，微服务框架 Tars 再添 PHP XXL-CRAWLER：灵活高效、面向对象的分布式爬虫框架 TSF：腾讯出品的基于协程和 Swoole 驱动的高性能 PHP 框架 Colly：Go 实现的快速、优雅的高性能网页采集框架 Biny：腾讯出品的高性能的超轻量级 PHP 框架 php-msf：基于 Swoole 的工程级企业微服务框架 基于 Java、Kafka、ElasticSearch 的搜索框架的设计与实现 swoft：基于 Swoole 协程 2.x 的高性能 PHP 微服务框架 iOS 从 0 到 1 搭建高可用 App 框架（二） NHMicro：脚本化微服务框架 Istio：Google、IBM 和 Lyft 联合开源的微服务 Service Mesh 框架 Google 应用框架实践 多研究些架构，少谈些框架（二）：微服务和充血模型 基于 Spring Cloud 的微服务架构 v1.0 [译] 用分层结构打造苗条 MVC 框架 Voyage：Java 实现的基于 Netty 的轻量、高性能分布式 RPC 服务框架 小程序底层框架实现原理解析 Golang 高性能分布式游戏服务器框架 mqant [译] Google 是如何开发 Web 框架的 FastD：PHP 高性能 API 框架 微服务架构的基础框架选择：Spring Cloud 还是 Dubbo？ JLiteSpider：轻量级的分布式 Java 爬虫框架 SeimiCrawler：敏捷、独立部署、支持分布式的 Java 爬虫框架 基于 Dubbo 框架构建分布式服务 RPCX：类似 Dubbo 的分布式 RPC 框架 魅族 C++ 协程框架 Kiev 技术内幕 高性能分布式 Mock 平台的框架与设计 深入分析 iBATIS 框架之系统架构与映射原理 实施微服务，我们需要哪些基础框架？ kiteq - 一个多种持久化方案的 MQ 框架 (@Beta版厨子) 消息队列 浅入浅出消息队列 深度剖析如何实现事务消息 基于 Redis 实现的延迟消息队列 万亿级消息背后: 小米消息队列的实践 金融行业消息队列选型及实践 QMQ：去哪儿网内部广泛使用的消息中间件 分布式之消息队列复习精讲 天池中间件大赛：单机百万消息队列存储分享 消息队列实现概要：深度解读分区 Topic 的实现 消息队列事务型消息原理浅析 RAID 6 应用于消息队列 分布式消息队列实现概要 几种常见的微服务架构方案简述：ZeroC IceGrid、Spring Cloud、基于消息队列 LocalMQ：从零构建类 RocketMQ 高性能消息队列 消息队列的对比调研 Message Queue 的设计和实现（七） 腾讯云分布式高可靠消息队列 CMQ 架构 Message Queue 的设计和实现（三） Gores：Go 语言编写的基于 Redis 的消息队列系统 php-queue：PHP 开发的磁盘存储消息队列服务 PHP 高级编程之消息队列 消息队列设计精要 Disque - 一个分布式消息队列 (antirez) 可靠消息队列浅谈 (@招牌疯子) kiteq - 一个多种持久化方案的 MQ 框架 (@Beta版厨子) 编程语言 Go 1.14 实现高性能内存分配器 Spring Boot 与微服务从 0 到 1 的实践 微服务统一认证与授权的 Go 语言实现（上） iOS 基于静态库插桩的⼆进制重排启动优化 Gbox：基于 Litho 的 Android 高性能动态业务容器，解决首页动态化的痛点 Go 微服务全链路跟踪详解 小米 Go 开发实践：用 Go 构建高性能数据库中间件 Golang 设计模式 互联网架构微服务已经成为主流，Go 语言如何去打造呢？ 微服务中使用 OpenJ9 JVM 内存占用降 60%（相对 HotSpot） Go 并发设计模式之 Active Object 函数式编程让你忘记设计模式 AAC 系列（四）：深入理解架构组件 ViewModel 自治对象才是好对象 轻松构建微服务之远程调用 拍拍贷消息系统原理与应用 微服务化后缓存怎么做 Golang Failpoint 的设计与实现 [译] 高性能 Go 服务的内存优化 Golang 轻量级高并发 socket 框架 chitchat 马蜂窝搜索基于 Golang 并发代理的一次架构升级 Android 技术架构演进与未来 Android 架构组件：让天下没有难做的 App NutsDB：纯 Go 编写的高性能内嵌型 KV 数据库 指令集架构、机器码与 Go 语言 让 Raft 变快 100 倍：Dragonboat 的写优化 Flutter 混合开发组件化与工程化架构 Go 分布式实时服务架构 被滥用的 GUI 设计模式 Android 架构之长连接技术 Android Architecture Component 和架构升级在铭师堂的实践 杭州有赞招聘资深 Java 开发工程师/垂直业务架构师 gorouter：简单高性能的 Go router Android 架构：ViewModel 与 View 之间的通信 最佳实践：重构 AppDelegate（iOS） 从 Go 高性能日志库 zap 看如何实现高性能 Go 组件 Android 架构组件 [译] 微服务的 10 个挑战和解决方案 天池中间件大赛 Golang 版 Service Mesh 思路分享 MyPerf4J：针对高并发、低延迟应用设计的高性能且无侵入的实时 Java 方法性能监控和统计工具 Spring Cloud 微服务版本灰度发布新神器 Python 后端架构演进 使用 Android 架构组件实现 MVVM 模式的应用 Go 代码重构：23 倍的性能爆增 继承和面向接口（iOS 架构思想篇） 苏宁数据中台基于 Spring Cloud 微服务架构实践 Go 微服务实战汇总 基于可靠消息方案的分布式事务（二）：Java 中的事务 如何基于 Golang 设计一套微服务架构 从跨语言调用到 dubbo2.js 什么时候能用上设计模式？ 秒杀架构实践 罗辑思维 Go 语言微服务改造实践 [译] PHP-FPM 调优：为了高性能使用 pm static Android 工程模块化平台的设计 苏宁易购 Android 架构演进史 Golang 高性能实战 浅析 iOS 中的设计模式 基于 Spring Cloud 的 Microservices 架构实战案例：架构拆解 基于 Spring Cloud 的微服务落地 跨平台长连接组件设计及可插拔改造 从 Spring Cloud 看一个微服务框架的 “五脏六腑” MMKV：基于 mmap 的 iOS 高性能通用 key-value 组件 阿里架构师分享的 Java 程序员需要突破的技术要点 swoolefy：基于 Swoole 扩展实现的高性能 MVC 框架 全面解析京东微服务平台 基于 Sanic 的微服务基础架构 Android Architecture Component 解析之 ViewModel Android Architecture Components 和可测试代码 guard：高性能熔断器 + 代理服务器（Golang） Dubbo 作者聊设计原则（2011） Android 应用架构前世今生 TDD 开发容器化的 Python 微服务应用（一） [译] 2018 PHP 应用程序安全设计指北 探索 Android 架构组件 Room MultiHttp：高性能 PHP 封装的 HTTP Restful 多线程并发请求库 Blade：高性能、简洁优雅的 Java Web 框架 搭建 Keepalived + Nginx + Tomcat 的高可用负载均衡架构 读懂唱吧 KTVHTTPCache 设计思想（iOS） Log4a：基于 mmap 的高性能、高可用的 Android 日志收集框架 Android 高级进阶（源码剖析篇）：Twitter 的高性能序列化框架 Serial（一） 一文读懂连接池技术原理、设计与实现（Python） gkvdb 的介绍及设计 Go 使用 grpc + http 打造高性能微服务 腾讯与阅文技术合作，微服务框架 Tars 再添 PHP 使用 Redis 实现分布式锁及其优化 gRPC &amp; Protocol Buffer 构建高性能接口实践 TSF：腾讯出品的基于协程和 Swoole 驱动的高性能 PHP 框架 带你领略 Clean 架构的魅力 阿里云基于 Go 的微服务架构分享 Colly：Go 实现的快速、优雅的高性能网页采集框架 MultiHttp：高性能的 PHP 封装的 HTTP Restful 多线程并发请求库 Biny：腾讯出品的高性能的超轻量级 PHP 框架 用 500 行 Golang 代码实现高性能的消息回调中间件 dubbo 源码解析：集群容错架构设计 php-msf：基于 Swoole 的工程级企业微服务框架 深入理解 iOS 设计模式 基于 Java、Kafka、ElasticSearch 的搜索框架的设计与实现 Android 应用架构组件实践 如何用 Go 打造亿级实时分布式出行平台 [译] 基于 Android Architecture Components 的应用架构指南 molten：PHP 应用透明链路追踪工具 swoft：基于 Swoole 协程 2.x 的高性能 PHP 微服务框架 浅谈 MVC、MVP 和 MVVM 架构模式 谈谈 Tomcat 架构及启动过程 iOS 从 0 到 1 搭建高可用 App 框架（二） 再谈 WebSocket，论架构设计 Laravel + go-micro + grpc 实践基于 Zipkin 的分布式链路追踪系统 两年 PHPer 聊下架构 iOS 架构实践：The Right Way to Architect iOS App with Swift Base 封装（一）：我的最简 MVP 架构 iOS 动态功能部署我们是这样实现的：理论设计篇 iOS 架构设计：URL 缓存 [译] Google 官方推出应用开发架构指南 针对 PHP 做的 Ragnar Fiery 分布式性能跟踪系统 [译] 为了更好地支持微服务，我们从 PHP 迁移到了 Go iOS 无埋点数据 SDK 的整体设计与技术实现 PHP 应用性能优化指南 华尔街见闻基于 Golang 的微服务实践 58 同城 iOS 客户端组件化演变历程 天弘基金 iOS App 架构优化之路 沪江学习 Android 端应用架构重构 Voyage：Java 实现的基于 Netty 的轻量、高性能分布式 RPC 服务框架 iOS 设计模式资料整理 [译] 用分层结构打造苗条 MVC 框架 [译] GitHub 上 star 超过 2k 的 Android MVP 架构指南 分布式任务队列 Celery 介绍 安居客 Android 项目架构演进 Golang 高性能分布式游戏服务器框架 mqant Antares：分布式任务调度平台 Android 架构思考 FastD：PHP 高性能 API 框架 Spring Cloud 构建微服务架构（一）：服务注册与发现 Gores：Go 语言编写的基于 Redis 的消息队列系统 人人车 Android 客户端架构演进实录 后台任务处理系统的架构演进和优化（Golang） PHP 完整实战 23 种设计模式 Mybatis 源码解读：设计模式总结 微服务架构的基础框架选择：Spring Cloud 还是 Dubbo？ 你知道途牛 Android 客户端架构是怎么优化的吗？ 如何使用 PHP 构建一个高性能的弹幕后端服务 The Clean Architecture in PHP 读书笔记（九） 没有单元测试，何谈重构 php-queue：PHP 开发的磁盘存储消息队列服务 JLiteSpider：轻量级的分布式 Java 爬虫框架 MVP 架构系列：豆瓣电影 Top 250 PHP 高级编程之消息队列 Android 存储系统之架构篇 Dora RPC：PHP 的分布式 RPC，支持微服务、服务发现 BLog4go：Go 实现的高性能日志库 用设计模式解析 RecyclerView SeimiCrawler：敏捷、独立部署、支持分布式的 Java 爬虫框架 Android 架构资源集合 HackerNews_Kotlin：Google MVP 架构的 Kotlin 实践 Hacker News Android 客户端 设计模式：PHP 和 Go 语言实现 RPCX：类似 Dubbo 的分布式 RPC 框架 iOS MVVM 架构：界面与数据 I/O 逻辑分离的实践 [译] PHP 中的设计模式 [译] 面向协议的 MVVM 架构介绍 App 环境分离的实现 Service Oriented 的 iOS 应用架构 微信 Android 客户端后台保活经验分享 深入分析 iBATIS 框架之系统架构与映射原理 实践移动端的 Flux 架构 Java 单例真的写对了么？ 滴滴出行 iOS 客户端架构演进之路 Android App 的设计架构：MVC, MVP, MVVM 与架构经验谈 iOS 应用架构谈：组件化方案 Sky Walking：对 Java 分布式应用程序集群业务运行情况进行追踪、告警和分析的系统 iOS 开发性能提高 Golang 微服务工具包 用 Swift 搭建数据驱动型 iOS 架构 设计模式实现（Java、C++、Golang） 端游、手游服务端常用的架构是什么样的？ 微信红包的随机算法是怎样实现的？ [译] Dapper，大规模分布式系统的跟踪系统 Nucleus - 一个 Android MVP 架构库 [译] iOS 架构模式 Android 应用开发架构概述 [译] 如何利用 Python 中的 @property 装饰器快速重构代码？ Java Web 架构知识整理：记一次阿里面试经历 Java 应用一般架构 [译] Android 架构演化之路 iOS 高性能图片架构与设计 如何实现支持数亿用户的长连消息系统 (周洋) Android 系统架构之微服务架构 (MrSimple) iOS 应用架构谈：网络层设计方案 (CasaTaloyum) iOS 应用架构谈：view 层的组织和调用方案 (@CasaTaloyum) iOS 应用架构谈 (@CasaTaloyum) Android 源码设计模式分析 (@MrSimp1e) iOS 设计模式解析 设计模式 设计模式太难了？看看这个 “说人话” 的版本再说！ 设计模式太难了？看看这个 “说人话” 的版本再说！ [译] Spring 中的设计模式 设计模式在外卖营销业务中的实践 Golang 设计模式 你真的懂 Builder 设计模式吗？论如何实现真正安全的 Builder 模式 你想知道的 React 组件设计模式这里都有（上） Go 并发设计模式之 Half-Sync/Half-Async Go 并发设计模式之 Active Object 函数式编程让你忘记设计模式 [译] 微服务通信的设计模式 被滥用的 GUI 设计模式 微服务设计模式之 API 网关 [译] 你需要了解的 23 种 JavaScript 设计模式 什么时候能用上设计模式？ 浅析 iOS 中的设计模式 浅谈 Chromium 中的设计模式（一）：Chromium 中模块分层和进程模型 分布式系统数据层设计模式 深入理解 iOS 设计模式 你了解 CSS 设计模式吗？ iOS 设计模式资料整理 使用微服务架构重构支付网关 当函数成为一等公民时，设计模式的变化 PHP 完整实战 23 种设计模式 Mybatis 源码解读：设计模式总结 [译] 深入理解 React &amp; Redux 原理套路 用设计模式解析 RecyclerView 别人再问你设计模式，叫他看这篇文章 设计模式：PHP 和 Go 语言实现 图说设计模式 [译] PHP 中的设计模式 Java 单例真的写对了么？ 服务化设计模式实践 设计模式实现（Java、C++、Golang） 这就是观察者模式 (@Android月) Android 源码设计模式分析 (@MrSimp1e) iOS 设计模式解析 重构 代码优化实战：我又优化了一百个 if else 靠谱程序员必备技能：重构也要有方法论 系统重构的道与术 3000 字详解 Kylin 查询缓存重构 CMS 后台重构技术方案 [译] 手把手介绍函数式编程：从命令式重构到函数式 领域驱动设计在马蜂窝优惠中心重构中的实践 记一次前端项目重构要点总结 快看！原来重构如此简单 携程国际 BU 的 SEO 重构实践 前端重构范式之 position 面向体验的重构优化 [译] 什么是代码整理？ 最佳实践：重构 AppDelegate（iOS） 前端重构范式之 float layout Go 代码重构：23 倍的性能爆增 重构 React 组件的实用清单 IntelliJ IDEA 复杂的重构操作 IntelliJ IDEA 复杂的重构技巧 6 个月清洗近千亿条微信支付交易记录，他们要搞什么大事情？ 电商工作后台首页的商业价值重构与产品化设计 巧用匿名函数重构你的代码 [译] 微服务从设计到部署（七）：重构单体为微服务 系统重构的 10 点经验总结 Spark 技术在唯品会财务系统重构中的实践总结 重构：靠谱程序员的必备技能 重构之十六字心法 沪江学习 Android 端应用架构重构 如何重构 “箭头型” 代码 使用微服务架构重构支付网关 没有单元测试，何谈重构 在重构脚手架中掌握 React / Redux / Webpack2 基本套路 [PPT] 一次重构引发的分布式服务管理 如何重构一个大型历史项目：百度经验改版总结 重构过程中的过度设计 重构的七宗罪 CSS 代码重构与优化之路 [译] 如何利用 Python 中的 @property 装饰器快速重构代码？ 前端技能训练：重构一 (@Phodal) 集群 创建高可用 RabbitMQ 集群 [译] 如何使用 Istio 1.6 管理多集群中的微服务？ 架构设计基础：单服务、集群、分布式的基本区别和联系 Egg.js 打造高可用服务集群 Zookeeper 集群如何高可用部署？ 滴滴 Elasticsearch 多集群架构实践 那些年用过的 Redis 集群架构 分布式高性能 Redis 集群线上常见问题 Node.js：浅析高并发与分布式集群 你不知道的 RabbitMQ 集群架构全解 MySQL 高可用集群方案之 PXC 集群资源调度系统设计架构总结 dubbo 源码解析：集群容错架构设计 微服务注册发现集群搭建：Registrator + Consul + Consul-template + nginx ActiveMQ 高可用集群方案 Sky Walking：对 Java 分布式应用程序集群业务运行情况进行追踪、告警和分析的系统 如果有 10000 台机器，你想怎么玩？ References 文章来源"},{"title":"gRPC SkyLB (an gRPC load balancer based on External Load Balancing Service)","date":"2020-07-22T14:00:08.000Z","updated":"2020-07-23T02:35:01.855Z","comments":true,"path":"2020/07/22/gRPC SkyLB/","permalink":"https://binchencoder.github.io/2020/07/22/gRPC%20SkyLB/","excerpt":"","text":"gRPC SkyLBgRPC 作为一款高性能、通用的 RPC 框架，相比传统的RPC框架有着自己天然的优势： protobuf二进制消息，性能好/效率高（空间和时间效率都很不错）； proto文件生成目标代码，简单易用； 序列化反序列化直接对应程序中的数据类，不需要解析后在进行映射(XML,JSON都是这种方式)； 支持向前兼容（新加字段采用默认值）和向后兼容（忽略新加字段），简化升级； 支持多种语言（可以把proto文件看做IDL文件）； Netty等一些框架集成； 服务注册/发现 是RPC框架的核心组件，但是gRPC 作为企业级框架，他的开源组件官方并未直接提供服务注册与发现的功能实现。而是在设计文档(load-balancing.md)中提供了实现的思路，并在不同语言的gRPC代码API中提供了命名解析和负载均衡接口供扩展。 关于gRPC 服务发现&amp;负载均衡的介绍，可以参见我之前写的一篇文章 gRPC服务发现&amp;负载均衡 OverviewgRPC SkyLB 采用独立LB进程（External Load Balancing Service）负载均衡方式，支持轮询、一致性哈希两种负载均衡策略，并支持服务端权重。采用etcd作为注册中心。 项目地址： https://github.com/binchencoder/grpc-skylb Architecture of SkyLB 服务提供者起来后向注册中心(SkyLB) 注册自己的信息，ip、端口、权重等，并保持心跳。客户端监听注册中心，获取服务器列表，一旦服务器发生变化，客户端马上更新本地的服务器列表。客户端每个请求都通过负载均衡策略选择一个合适的服务器去访问。 Usage Dependency Install skylb-client local repository 1chenbindeMacBook-Pro:grpc-skylb chenbin$ mvn clean install 12345&lt;dependency&gt; &lt;groupId&gt;com.binchencoder.skylb&lt;/groupId&gt; &lt;artifactId&gt;skylb-client&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; Implements gRPC API 12345678910111213141516171819202122232425262728293031323334public class DemoGrpcImpl extends DemoGrpc.DemoImplBase &#123; private final Logger LOGGER = LoggerFactory.getLogger(DemoGrpcImpl.class); private Random rand = new Random(System.currentTimeMillis()); private int port; public DemoGrpcImpl(int port_) &#123; this.port = port_; &#125; @Override public void greeting(GreetingProtos.GreetingRequest request, StreamObserver&lt;GreetingProtos.GreetingResponse&gt; responseObserver) &#123; LOGGER.info(\"Got req: &#123;&#125;\", request); // 随机耗时350~550毫秒. int elapse = 350 + rand.nextInt(200); try &#123; TimeUnit.MILLISECONDS.sleep(elapse); &#125; catch (InterruptedException ie) &#123; LOGGER.warn(\"sleep interrupted\"); &#125; GreetingResponse reply = GreetingResponse.newBuilder().setGreeting( \"Hello \" + request.getName() + \", from :\" + port + \", elapse \" + elapse + \"ms\").build(); responseObserver.onNext(reply); responseObserver.onCompleted(); &#125; @Override public void greetingForEver(GreetingProtos.GreetingRequest request, StreamObserver&lt;GreetingProtos.GreetingResponse&gt; responseObserver) &#123; super.greetingForEver(request, responseObserver); &#125;&#125; Register gRPC Server to SkyLB Server 123456789101112Server server = ServerTemplate.create( &#123;port&#125; 9090, &#123;bindableService&#125; new DemoGrpcImpl(), &#123;serviceName&#125; \"shared-test-client-service\") .build() .start();SkyLBServiceReporter reporter = ServerTemplate.reportLoad( &#123;skylbUri&#125; \"skylb://127.0.0.1:1900/\", &#123;serviceName&#125; ServiceNameUtil.toString(ServiceId.CUSTOM_EASE_GATEWAY_TEST), &#123;portName&#125; \"grpc\", &#123;port&#125; 9090); Call gRPC Server Create gRPC Stub 12345678ManagedChannel channel = ClientTemplate.createChannel( &#123;skylbAddr&#125; \"skylb://127.0.0.1:1900/\", &#123;calleeServiceName&#125; ServiceNameUtil.toString(ServiceId.CUSTOM_EASE_GATEWAY_TEST), &#123;calleePortName&#125; \"grpc\", &#123;calleeNamespace&#125; null, &#123;callerServiceName&#125; ServiceNameUtil.toString(ServiceId.SERVICE_NONE)).getOriginChannel();DemoGrpc.DemoBlockingStub blockingStub = DemoGrpc.newBlockingStub(channel); 123456GreetingRequest request = GreetingRequest.newBuilder() .setName(\"GC \" + Calendar.getInstance().get(Calendar.SECOND)) .build();GreetingResponse response = blockingStub .withDeadlineAfter(2000, TimeUnit.MILLISECONDS) .greeting(request); Run Demo Build SkyLB Server 12chenbindeMacBook-Pro:grpc-skylb chenbin$ cd skylb-serverchenbindeMacBook-Pro:skylb-server chenbin$ mvn clean package 最终skylb.jar 打包到 skylb-server/target 目录下 Start SkyLB Server Start ETCD3 123yum install etcd -ysystemctl enable etcd &amp;&amp; systemctl start etcd NOTE 部署ETCD遇到问题可参考 https://www.cnblogs.com/shawhe/p/10640820.html 12345678910111213141516171819202122chenbindeMacBook-Pro:skylb-server chenbin$ cd target/skylblibchenbindeMacBook-Pro:skylblib chenbin$ java -jar skylb.jar -h Usage: java -jar skylb.jar [options] [command] [command options] Options: --auto-disconn-timeout, -auto-disconn-timeout The timeout to automatically disconnect the resolve RPC. e.g. 10s(10 Seconds), 10m(10 Minutes) Default: PT5M Commands: etcd Help for etcd options Usage: etcd [options] Options: --etcd-endpoints, -etcd-endpoints The comma separated ETCD endpoints. e.g., http://etcd1:2379,http://etcd2:2379 Default: [http://127.0.0.1:2379] --etcd-key-ttl, -etcd-key-ttl The etcd key time-to-live. e.g. 10s(10 Seconds), 10m(10 Minutes) Default: PT10SchenbindeMacBook-Pro:skylblib chenbin$ java -jar skylb.jar -etcd-endpoints=http://127.0.0.1:2379 Start gRPC Server https://github.com/binchencoder/grpc-skylb/blob/master/examples/demo/src/main/java/com/binchencoder/skylb/demo/grpc/server/GreetingServer.java Run com/binchencoder/skylb/demo/grpc/server/GreetingServer#main Start gRPC Client https://github.com/binchencoder/grpc-skylb/blob/master/examples/demo/src/main/java/com/binchencoder/skylb/demo/grpc/client/GreetingClient.java Run com/binchencoder/skylb/demo/grpc/client/GreetingClient#main More Examplesgrpc-skylb/examples/echo 该示例采用SpringBoot脚手架，在spring-boot-grpc-common.jar中封装好了注册服务的逻辑，启动方式比较简单 123@GrpcService(applyGlobalInterceptors = true) // Default use Global Interceptorpublic class EchoGrpcService extends EchoServiceGrpc.EchoServiceImplBase &#123;&#125; 使用@GrpcService 注解方式标示gRPC Service 在 spring-boot-grpc-common.jar 中默认配置两个Global Interceptor(ExceptionInterceptor, AuthenticationInterceptor) 使用者可通过注解不使用Global Interceptor，实现自己的Interceptor 1@GrpcService(applyGlobalInterceptors = false, interceptors = ExceptionInterceptor.class) Features @GrpcService Annotation 支持配置全局拦截器 将来计划支持skylb-client Golang版本 References gRPC服务发现&amp;负载均衡 https://github.com/binchencoder/grpc-skylb https://github.com/grpc/grpc/blob/master/doc/load-balancing.md 部署ETCD3集群"},{"title":"gRPC服务发现&负载均衡","date":"2020-07-20T09:00:08.000Z","updated":"2020-07-20T09:50:50.033Z","comments":true,"path":"2020/07/20/gRPC服务发现&负载均衡/","permalink":"https://binchencoder.github.io/2020/07/20/gRPC%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0&%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"","text":"gRPC服务发现&amp;负载均衡gRPC 是一个高性能、开源、通用的 RPC 框架，面向移动和 HTTP/2 设计，是由谷歌发布的首款基于 Protocol Buffers 的 RPC 框架。 gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特性。 构建高可用、高性能的通信服务，通常采用服务注册与发现、负载均衡和容错处理等机制实现。根据负载均衡实现所在的位置不同，通常可分为以下三种解决方案： 集中式LB（Proxy Model） 在服务消费和服务提供者之间有一个独立的LB，通常是专门的硬件设备如 F5，或者基于软件如 LVS，HAproxy等实现。 LB上有所有服务的地址映射表，通常由运维配置注册，当服务消费方调用某个目标服务时，它向LB发起请求，由LB以某种策略，比如轮询（Round-Robin）做负载均衡后将请求转发到目标服务。LB一般具备健康检查能力，能自动摘除不健康的服务实例。该方案主要问题： 单点问题，所有服务调用流量都经过LB，当服务数量和调用量大的时候，LB容易成为瓶颈，且一旦LB发生故障影响整个系统 服务消费方、提供方之间增加了一级，有一定性能开销 进程内LB（Balancing-aware Client） 针对第一个方案的不足，此方案将LB的功能集成到服务消费方进程里，也被称为软负载或者客户端负载方案。服务提供方启动时，首先将服务地址注册到服务注册表，同时定期报心跳到服务注册表以表明服务的存活状态，相当于健康检查，服务消费方要访问某个服务时，它通过内置的LB组件向服务注册表查询，同时缓存并定期刷新目标服务地址列表，然后以某种负载均衡策略 (Round Robin, Random, etc) 选择一个目标服务地址，最后向目标服务发起请求。LB和服务发现能力被分散到每一个服务消费者的进程内部，同时服务消费方和服务提供方之间是直接调用，没有额外开销，性能比较好。该方案主要问题： 开发成本，该方案将服务调用方集成到客户端的进程里头，如果有多种不同的语言栈，就要配合开发多种不同的客户端，有一定的研发和维护成本 另外生产环境中，后续如果要对客户库进行升级，势必要求服务调用方修改代码并重新发布，升级较复杂 独立 LB 进程（External Load Balancing Service） 该方案是针对第二种方案的不足而提出的一种折中方案，原理和第二种方案基本类似。不同之处是将LB和服务发现功能从进程内移出来，变成主机上的一个独立进程。主机上的一个或者多个服务要访问目标服务时，他们都通过同一主机上的独立LB进程做服务发现和负载均衡。该方案也是一种分布式方案没有单点问题，一个LB进程挂了只影响该主机上的服务调用方，服务调用方和LB之间是进程内调用性能好，同时该方案还简化了服务调用方，不需要为不同语言开发客户库，LB的升级不需要服务调用方改代码。 该方案主要问题：部署较复杂，环节多，出错调试排查问题不方便 gRPC服务发现&amp;负载均衡实现gRPC开源组件官方并未直接提供服务注册与发现的功能实现，但其设计文档已提供实现的思路，并在不同语言的gRPC代码API中已提供了命名解析和负载均衡接口供扩展。 其实现基本原理： 服务启动后gRPC客户端向命名服务器发出名称解析请求，名称将解析为一个或多个IP地址，每个IP地址标示它是服务器地址还是负载均衡器地址，以及标示要使用那个客户端负载均衡策略或服务配置。 客户端实例化负载均衡策略，如果解析返回的地址是负载均衡器地址，则客户端将使用grpclb策略，否则客户端使用服务配置请求的负载均衡策略。 负载均衡策略为每个服务器地址创建一个子通道（channel）。 当有RPC请求时，负载均衡策略决定那个子通道即gRPC服务器将接收请求，当可用服务器为空时客户端的请求将被阻塞。 根据gRPC官方提供的设计思路，基于进程内LB方案（即第2个案，阿里开源的服务框架 Dubbo 也是采用类似机制），结合分布式一致的组件（如Zookeeper、Consul、Etcd），可找到gRPC服务发现和负载均衡的可行解决方案。 References https://github.com/grpc/grpc/blob/master/doc/load-balancing.md"},{"title":"Docular","date":"2020-07-14T09:00:08.000Z","updated":"2020-07-20T09:56:47.470Z","comments":true,"path":"2020/07/14/Docular/","permalink":"https://binchencoder.github.io/2020/07/14/Docular/","excerpt":"","text":"DocularDocular是一个个人文档服务，它提供了一个本地HTTP服务器来服务给定文件夹中的文档。该文件夹包含以下支持的文件格式：HTML，MarkDown，MAFF InstallDocular 在Linux 和 Mac 平台上都能很好的支持 Download Linux Docular Linux 1sudo dpkg -i docular_1.0_amd64.deb Mac Docular Mac NOTE Mac上安装稍微麻烦一点，需要将webstatic 目录下载到本地，然后在运行时指定 -webstatic Launch123456789101112131415chenbin@chenbin-ThinkPad:~&#x2F;$ docular -hDocular server.Usage: docular-server [options]Options: -allow-external Allow external access -doc-dir string The doc directory path. -port int The http port. (default 3455) -webstatic string The web static directory. (default &quot;&#x2F;usr&#x2F;share&#x2F;docular&#x2F;webstatic&quot;) 运行docular需要指定doc-dir，也就是你想预览的文件夹 可同时运行多个docular服务，需要制定port Screenshots References https://github.com/binchencoder/docular https://github.com/russross/blackfriday"},{"title":"多线程 — 概述及底层实现机制浅析","date":"2020-04-15T08:00:08.000Z","updated":"2020-04-15T08:46:27.495Z","comments":true,"path":"2020/04/15/多线程 — 概述及底层实现机制浅析/","permalink":"https://binchencoder.github.io/2020/04/15/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E2%80%94%20%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E6%B5%85%E6%9E%90/","excerpt":"","text":"多线程多线程是为了使得多个线程并行的工作以完成多项任务, 以提高系统的效率. 线程是在同一时间需要完成多项任务的时候被实现的. 什么是线程、进程在讨论多线程之前, 我们需要先认识一下, 进程、线程, 以及相关值得注意的问题. 我们一起先来读一个有趣的故事《进程与线程的一个简单解释》, 浅显易懂, 生动形象的解释了多线程相关的很多典型问题. 进程程序的一次执行 进程是计算机中的程序关于某数据集合上的一次运行活动. 是系统进行资源分配和调度的基本单位, 是操作系统结构的基础. 进程是计算机中已运行程序的实体. 其本身并不是内部运行单位, 是线程的容器 线程CPU的基本调度单位 线程是操作系统能够进行运算调度的最小单位. 线程是一组指令的集合它被包含在进程之中, 是进程中的实际运作单位. 一条线程指的是进程中一个单一顺序的控制流, 一个进程中可以并发多个线程, 每条线程并行执行不同的任务. 线程是独立调度和分派的基本单位. 同一进程中的多条线程将共享该进程中的全部系统资源, 但是自有调度堆栈和寄存器环境. 线程、进程的不同 主线程在程序中的地位和其他线程不同，它是其他线程最终的父线程，且所有界面的显示操作即AppKit或 UIKit的操作必须在主线程进行 进程和线程都是操作系统的概念。进程是应用程序的执行实例，每个进程是由私有的虚拟地址空间、代码、数据和其它各种系统资源组成 线程和进程十分相似，不同的只是线程比进程小。首先，线程采用了多个线程可共享资源的设计思想；例如，它们的操作大部分都是在同一地址空间进行的。其次，从一个线程切换到另一线程所花费的代价比进程低。再次，进程本身的信息在内存中占用的空间比线程大，因此线程更能允分地利用内存 线程是进程的一部分CPU调度的是线程系统为进程分配资源，不对线程分配资源 线程、进程的关系一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。 资源分配给进程，同一进程的所有线程共享该进程的所有资源。 处理机分给线程，即真正在处理机上运行的是线程。 线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步 References http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html"},{"title":"linux top命令VIRT,RES,SHR,DATA的含义","date":"2020-01-03T08:23:08.000Z","updated":"2020-01-03T10:24:56.010Z","comments":true,"path":"2020/01/03/linux top命令VIRT,RES,SHR,DATA的含义/","permalink":"https://binchencoder.github.io/2020/01/03/linux%20top%E5%91%BD%E4%BB%A4VIRT,RES,SHR,DATA%E7%9A%84%E5%90%AB%E4%B9%89/","excerpt":"","text":"一、VIRTvirtual memory usage 虚拟内存 1、进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等2、假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量 VIRT = SWAP + RES 二、RESresident memory usage 常驻内存 1、进程当前使用的内存大小，但不包括swap out2、包含其他进程的共享3、如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反4、关于库占用内存的情况，它只统计加载的库文件所占内存大小 RES = CODE + DATA 三、SHRshared memory 共享内存 1、除了自身进程的共享内存，也包括其他进程的共享内存2、虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小3、计算某个进程所占的物理内存大小公式：RES – SHR4、swap out后，它将会降下来 四、DATA1、数据占用的内存。如果top没有显示，按f键可以显示出来。2、真正的该程序要求的数据空间，是真正在运行中要使用的。 top 运行中可以通过 top 的内部命令对进程的显示方式进行控制 Command Description s 改变画面更新频率 l 关闭或开启第一部分第一行 top 信息的表示 t 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示 m 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示 N 以 PID 的大小的顺序排列表示进程列表 P 以 CPU 占用率大小的顺序排列进程列表 M 以内存占用率大小的顺序排列进程列表 h 显示帮助 n 设置在进程列表所显示进程的数量 q 退出 top s 改变画面更新周期 默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。可以通过下面的快捷键来更改显示内容。 通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定 按 o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z 可以将相应的列向左移动。最后按回车键确定 按大写的 F 或 O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的 R 键可以将当前的排序倒转"},{"title":"Java面试圣经","date":"2019-12-03T02:00:08.000Z","updated":"2021-06-18T08:20:29.564Z","comments":true,"path":"2019/12/03/Java面试圣经/","permalink":"https://binchencoder.github.io/2019/12/03/Java%E9%9D%A2%E8%AF%95%E5%9C%A3%E7%BB%8F/","excerpt":"","text":"基础篇基本功 面向对象的特征 final, finally, finalize 的区别 https://www.jianshu.com/p/c45b6d782e91 重载和重写的区别 说说反射的用途及实现 https://www.sczyh30.com/posts/Java/java-reflection-1 equals 与 == 的区别 数据结构 二叉树 链表 集合 List 和 Set 区别 List 和 Map 区别 Arraylist 与 LinkedList 区别 ArrayList 与 Vector 区别 HashMap、HashTable、ConcurrentHashMap共同点与区别 HashMap和HashTable 都是底层数组+链表实现，ConcurrentHashMap底层结构是散列表(数组+链表)+红黑树 HashMap可以存储null键和null值，HasTable和ConcurrentHashMap的key和value都不能为null HasMap线程不安全，HashTable和ConcurrentHashMap是线程安全的。HashTable实现线程安全的方式是在修改数据时锁住整个HashTable，效率低，而ConcurrentHashMap作为一个高并发的容器，它是通过部分锁定+CAS算法来进行实现线程安全的。CAS算法也可以认为是乐观锁的一种 HashSet 和 HashMap 区别 HashMap 的工作原理及代码实现 ConcurrentHashMap 的工作原理及代码实现 HashMap是如何扩容的 HashMap如何避免key碰撞 HashMap死循环问题 进阶篇网络 讲讲TCP/IP TCP/IP简介 讲讲TCP、UDP、IP IP、UDP和TCP的关系 TCP三次握手、四次握手 https://note.youdao.com/ynoteshare1/index.html?id=0e999579be9f295f0d895930c98a67b9&amp;type=note IO Java中IO流的分类 Java 常用IO流操作详解 NIO、BIO、AIO See：关于BIO和NIO的理解 BIO：同步阻塞式IO，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。 NIO：同步非阻塞式IO，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。 AIO(NIO 2.0)：异步非阻塞式IO，服务器实现模式为一个有效请求一个线程，客户端的IO请求都是由OS先完成了再通知服务器应用去启动线程进行处理。 线程 References Java线程模型 说说 CountDownLatch 原理 CountDownLatch是同步工具类之一，可以指定一个计数值，在并发环境下由线程进行减1操作，当计数值为0之后，被await方法阻塞的线程将会唤醒，实现线程间的同步。 See 分析CountDownLatch的实现原理 My Sample: https://github.com/binchencoder/java-tutorials/blob/master/src/test/java/com/binchencoder/study/concurrent/CountDownLatchTest.java 说说 CyclicBarrier 原理 CyclicBarrier 字面意思是可循环（Cyclic）使用的屏障（Barrier）。它要做的事情是让一组线程到达一个屏障（同步点）时被阻塞，直到最后一个线程到达屏障时候，屏障才会开门。所有被屏障拦截的线程才会运行。 CyclicBarrier是由ReentrantLock可重入锁和Condition共同实现的。 My Sample: https://github.com/binchencoder/java-tutorials/blob/master/src/test/java/com/binchencoder/study/concurrent/CyclicBarrierTest.java 说说 Semaphore 原理 Semaphore也叫信号量, 在JDK1.5被引入, 可以用来控制同时访问特定资源的线程数量, 通过协调各个线程, 以保证合理的使用资源. Semaphore内部维护了一组虚拟的许可, 许可的数量可以通过构造函数的参数指定. 访问特定资源前, 必须使用acquire方法获得许可, 如果许可数量为0, 该线程则一直阻塞, 直到有可用的许可 访问资源后, 使用release释放许可 Semaphore和ReentrantLock类似，获取许可有公平策略和非公平许可策略，默认情况下使用非公平策略 应用场景 : Semaphore可以用来做流量分流，特别是对公共资源有限的场景，比如数据库连接。假设有这个的需求，读取几万个文件的数据到数据库中，由于文件读取是IO密集型任务，可以启动几十个线程并发读取，但是数据库连接数只有10个，这时就必须控制最多只有10个线程能够拿到数据库连接进行操作。这个时候，就可以使用Semaphore做流量控制 My Sample: https://github.com/binchencoder/java-tutorials/blob/master/src/test/java/com/binchencoder/study/concurrent/PrintABC.java 说说 Exchanger 原理 说说 CountDownLatch 与 CyclicBarrier 区别 CountDownLatch CyclicBarrier 减计数方式 加计数方式 计算为0时释放所有等待的线程 计数达到指定值时释放所有等待线程 计数为0时，无法重置 计数达到指定值时，计数置为0重新开始 调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响 调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞 不可重复使用 可重复利用 CountDownLatch 强调的是一个线程（或多个）需要等待另外的n个线程干完某件事情之后才能继续执行。 举个例子：有五个人，一个裁判。这五个人同时跑，裁判开始计时，五个人都到终点了，裁判喊停，然后统计这五个人从开始跑到最后一个撞线用了多长时间。 我们实现代码的思路可能是这样：main线程是裁判，5个Worker是跑步的，运动员先准备，裁判喊跑，运动员才开始跑(这是第一次同步，对应begin)。5个人谁跑到终点了，countdown一下，直到5个人全部到达，裁判喊停(这是第二次同步，对应end)，然后算时间。 CyclicBarrier强调的是n个线程，大家相互等待，只要有一个没完成，所有人都得等着。 ThreadLocal 原理分析 用于防止对可变的单实例变量或全局变量进行共享 See ThreadLocal源码解读 讲讲线程池的实现原理 See 深入分析java线程池的实现原理 线程池的几种方式与使用场景 线程的生命周期及几种状态 锁机制 AQS详解 AQS是AbstractQueuedSynchronizer的简称。AQS提供了一种实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架。AQS为一系列同步器依赖于一个单独的原子变量（state）的同步器提供了一个非常有用的基础。子类们必须定义改变state变量的protected方法，这些方法定义了state是如何被获取或释放的。 See Java并发之AQS详解 说说线程安全问题 某个属性是被多线程共享的资源，同时多线程有读写操作，就有可能（注意是有可能）存在线程安全问题。 即使是有多线程对同一个共享资源都有读写，也不能笼统的说就一定存在线程安全问题 要考虑线程安全问题并不代表一定就有线程安全问题。仿佛有点矛盾。判断存不存在线程安全问题，还要根据业务特点和发生问题导致的结果来判断。 volatile 实现原理 如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。这个就是所谓的“可见性”，就是一个线程修改了，其他线程能知道这个操作，这就是可见性。如何实现的呢？volatile修饰的变量在生成汇编代码的时候，会产生一条lock指令，lock前缀的指令在多核处理器下会引发两件事情： 将当前处理器缓存行的数据写回到系统内存； 这个写回内存的操作会使得在其它cpu里缓存了该内存地址的数据无效。 See volatile与synchronized实现原理 synchronized 实现原理 synchronized是用java的monitor机制来实现的，就是synchronized代码块或者方法进入及退出的时候会生成monitorenter跟monitorexit两条命令。线程执行到monitorenter时会尝试获取对象所对应的monitor所有权，即尝试获取的对象的锁；monitorexit即为释放锁。 synchronized 与 lock 的区别 CAS 乐观锁 乐观锁的业务场景及实现方式 ABA 问题 核心篇数据存储 MySQL 索引使用的注意事项 说说 SQL 优化之道 负向条件(where != 条件)不能使用索引，可以优化为in 查询； Like 模糊查询左匹配不能使用索引, 只有右匹配能使用索引； 数据区分度不大的字段不宜使用索引，如：性别只有男，女，每次过滤掉的数据很少，不宜使用索引； 在属性上进行计算不能命中索引； 其他实践 See https://www.jianshu.com/p/906fd3ca8dc7 MySQL 遇到的死锁问题 如何避免死锁： 以固定的顺序访问表和行； 大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小； 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁概率； 降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁； 为表添加合理的索引。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。 数据库索引的原理 数据库-索引的原理（面试高危之必备技能） BTREE与HASH索引的区别, 为什么要用 BTREE索引 Hash 索引只能够用于使用 = 或者 &lt;=&gt; 运算符的相等比较(但是速度更快)。Hash 索引不能够用于诸如 &lt; 等用于查找一个范围值的比较运算符； B-tree 索引可以用于使用 =, &gt;, &gt;=, &lt;, &lt;= 或者 BETWEEN 运算符的列比较。如果 LIKE 的参数是一个没有以通配符起始的常量字符串的话也可以使用这种索引。 B-tree索引和Hash索引的区别 MySQL索引（一）为什么要用B+树 聚集索引与非聚集索引的区别 聚集索引：数据行的物理顺序与列值(一般是主键的那一列)的逻辑顺序相同，一个表中只能有一个聚集索引。Mysql中聚集索引就是主键索引，如果没有主键，系统会自动创建一个隐含列作为表的聚集索引。 非聚集索引：该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同，一个表中可以有多个非聚集索引。 See 聚集索引与非聚集索引的总结 limit 20000 加载很慢怎么解决 选择合适的数据存储方案 聊聊 MongoDB 使用场景 聊聊 ElasticSearch 使用场景 倒排索引 不是由记录来确定属性值，而是由属性值来确定记录的位置 事务隔离级别 未提交读(Read uncommitted) 读的都是最新版本的数据, 会出现脏读 已提交读(Read committed [RC]) 只能读取到已经提交的数据, 会出现不可重复读 可重复读(Repeatable read [RR])：在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别 解决了不可重复的问题, InnoDB解决了幻读问题 可串行化(Serializable) 用加锁的方式实现串行化 我们较常用的是RC和RR MySQL的事务隔离级别是如何实现的每行数据其实在数据库都是多个版本的，可能同一时间有很多事务在更新一条数据，事务在开始的时候会申请一个id，这个id是严格随着时间递增的，先开始的事务id总是小的，数据库的版本就是事务id的版本。 MySQL的事务隔离级别是怎么实现的？ 数据库范式 第一范式(1NF): 强调每一列都是不可分割的原子数据项 第二范式(2NF): 在1NF的基础上，非属性码的属性必须完全依赖于主码。（在1NF基础上消除非属性码的属性对主码的部分函数依赖） 第三范式(3NF): 在2NF基础上，消除传递依赖 解释一下关系数据库的第一第二第三范式？ - 刘慰的回答 - 知乎 References https://notes.diguage.com/mysql/ 缓存使用 Redis 有哪些类型 Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合) 类型 简介 特性 场景 String(字符串) 二进制安全 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M — Hash(字典) 键值对集合,即编程语言中的Map类型 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) 存储、读取、修改用户属性 List(列表) 链表(双向链表) 增删快,提供了操作某一段元素的API 1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列 Set(集合) 哈希表实现,元素不重复 1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 Sorted Set(有序集合) 将Set中的元素增加一个权重参数score,元素按score有序排列 数据插入集合时,已经进行天然排序 1、排行榜 2、带权重的消息队列 Redis 内部结构 Redis 内存淘汰机制 volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru：从数据集中挑选最近最少使用的数据淘汰 allkeys-random：从数据集中任意选择数据淘汰 no-enviction：当内存达到限制的时候，不淘汰任何数据，不可写入任何数据集，所有引起申请内存的命令会报错 聊聊 Redis 使用场景 http://blog.720ui.com/2017/redis_core_use Redis 持久化机制 RDB： 这是Redis默认的持久化方式，按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件； AOF： Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。 See http://blog.720ui.com/2016/redis_action_03_rdb_aof Redis 集群方案与实现 Redis实战（四） 集群机制 Redis 为什么是单线程的 缓存崩溃 缓存降级 使用缓存的合理性问题 http://blog.720ui.com/2016/redis_action_01_use_core 消息队列 消息队列的使用场景 消息的重发补偿解决思路 消息的堆积解决思路 自己如何实现消息队列 如何保证消息的有序性 Kafka为什么快 Kafka是如何实现几十万的高并发写入 框架篇Spring BeanFactory 和 ApplicationContext 有什么区别 Spring IOC 如何实现 说说 Spring AOP Spring AOP 实现原理 动态代理（cglib 与 JDK） JDK的动态代理机制只能代理实现了接口的类，而不能实现接口的类就不能实现JDK的动态代理，cglib是针对类来实现代理的，他的原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对final修饰的类进行代理。 Spring 事务实现方式 Spring 事务底层原理 Spring 其他产品（Srping Boot、Spring Cloud、Spring Secuirity、Spring Data、Spring AMQP 等） Netty 为什么选择 Netty 说说业务中，Netty 的使用场景 原生的 NIO 在 JDK 1.7 版本存在 epoll bug 什么是TCP 粘包/拆包 TCP粘包/拆包的解决办法 Netty 线程模型 彻底搞懂 netty 线程模型 说说 Netty 的零拷贝 Netty 内部执行流程 Netty 重连实现 微服务篇微服务 微服务有哪些框架 如何解决跨域 http://blog.720ui.com/2016/web_cross_domain/ 你怎么理解 RPC 框架 https://binchencoder.github.io/2019/07/21/RPC%E6%A1%86%E6%9E%B6/ 说说 RPC 的实现原理 说说 Dubbo 的实现原理 你怎么理解 RESTful 如何理解 RESTful API 的幂等性 http://blog.720ui.com/2016/restful_idempotent 如何保证接口的幂等性 说说 CAP 定理、 BASE 理论 CAP的结论非常简单：在分布式系统里，有3个属性非常重要，但只能同时满足其中的2个 Consistency：all nodes在任何时刻看到的data都是一样的（或说client的read操作总是返回最新写入的那个value） Availability：系统时刻都允许操作，并且操作总会快速被Coordinator响应，最终client很快就得到返回的结果 Partition-tolerance：尽管网路有时候会因为故障导致被分隔开，但是系统依然在正常工作（或者说在满足前述的条件下工作） CAP权衡 如今的云计算环境里，因为网络随时都会被隔离开来，这是无法避免的，P是必须满足的，那么CAP暗示一个system要在C和A中做出抉择。 比如，Cassandra就选择了AP，对于C只能保证 Eventual Consistency（弱一致性）；传统的RDBMS在一个partition里保证可用性。 分布式理论之BASE理论 怎么考虑数据一致性问题 说说最终一致性的实现方案 微服务如何进行数据库管理 http://blog.720ui.com/2017/msa_design/#论微服务的数据库管理 如何应对微服务的链式调用异常 http://blog.720ui.com/2017/msa_design/#应对微服务的链式调用异常 对于快速追踪与定位问题 http://blog.720ui.com/2017/msa_design/#如何快速追踪与定位问题 分布式 谈谈业务中使用分布式的场景 Session 分布式方案 分布式锁的场景 分布式锁的实现方案 三种实现分布式锁的方式 基于数据库实现排他锁 基于redis实现 基于zookeeper实现 分布式事务 集群与负载均衡的算法与实现 说说分库与分表设计 http://blog.720ui.com/2017/mysql_core_08_multi_db_table/ 分库与分表带来的分布式困境与应对之策 http://blog.720ui.com/2017/mysql_core_09_multi_db_table2/ 高级进阶算法排序算法See http://data.biancheng.net/sort/ 冒泡排序 桶排序 插入排序 JVM References JVM8中内存基本操作 JVM内存结构 JVM内存管理 JVM内存模型(JMM) Java内存模型的基础 JVM垃圾回收 JVM垃圾回收之世代垃圾收集过程 References Java 虚拟机底层原理知识总结 性能优化 性能指标有哪些 如何发现性能瓶颈 性能调优的常见手段 说说你在项目中如何进行性能调优 面试官拷问 平时碰到系统CPU飙高和频繁GC，你会怎么排查？ 面试官问：平时碰到系统CPU飙高和频繁GC，你会怎么排查？ References Java面试通关要点汇总集【终极版】 深入理解JVM-内存模型（jmm）和GC"},{"title":"排查CPU负载高","date":"2019-11-29T14:53:08.000Z","updated":"2019-12-02T02:10:12.029Z","comments":true,"path":"2019/11/29/排查CPU负载高/","permalink":"https://binchencoder.github.io/2019/11/29/%E6%8E%92%E6%9F%A5CPU%E8%B4%9F%E8%BD%BD%E9%AB%98/","excerpt":"","text":"一、Overview本篇文章针对的是排查Java程序出现高负载的情况，如果是其他语言写的程序，如：php、python、go，无非就是换个工具，排查的步骤是类似的 以下三类工具 从原生的top、jstack到功能强大的Arthas 和 一键式查找的show-busy-java-threads，它们都各有长处。在合适的环境选择合适的工具才是考察一个IT人员能力的时候。 1. 原生方法Linux 原生命令：top、printf JDK自带命令工具：jstack、jstat 1.1. 找到最耗CPU的进程1top -c 显示进程运行信息列表 按数字1，显示多核CPU信息 键入P(大写p)，进程按照CPU使用率排序 键入M(大写m)，进程按照内存使用率排序 1.2. 找到最耗CPU的线程1top -H -p [PID] 显示一个进程的线程运行信息列表 例：1top -Hp 17326 如下图所示，可以看到多个高耗CPU使用率的线程 1.3. 转换线程PID为十六进制1printf \"%x\\n\" [线程PID] 转换多个线程数字为十六进制，使用时前面加0x 例： 12345chenbindeMacBook-Pro:~ chenbin$ printf '%x\\n' 17378 17379 17412 1742643e243e344044412 1.4. 查看堆栈，定位线程1jstack [进程PID] | grep [线程转换后十六进制] -A10 使用jstack获取进程PID堆栈，利用grep定位线程id，打印后续10行信息 例： 1jstack 17376 | grep '0x43e2' -A10 看上图中的“GC task thread#0 (ParallelGC)”，代表垃圾回收线程，该线程会负责进行垃圾回收。为什么会有两个线程一直在进行垃圾回收，并且占用那么高的CPU使用率呢？ 1.5. 存储堆栈，批量查看可以先将jstack堆栈信息存储起来 1jstack [进程PID] &gt; [文件] 例： 1jstack 17376 &gt; yao.dump 存储17376进程的堆栈信息，再使用cat + grep查找看看后面几个高CPU线程的堆栈信息。 1cat -n yao.dump | grep -A10 '0x4404' 可以看到线程0x4404【线程17426】产生堆栈信息，直指方法whileTrue 1.6. GC查看我们看到CPU占用率最高的并不是0x4404，而是0x43e2、0x43e3。但是并没法看到其中是什么类与方法，只有一条GC信息。 是不是死循环导致了GC太频繁，导致CPU使用率居高不下呢？我们使用jstat看下jvm的GC信息看看。 1jstat -gcutil [进程PID] [毫秒] [打印次数] 例： 1jstat -gcutil 17376 2000 5 查看17376进程的GC信息，每2秒打印一次，共打印5次 可以看到Full GC的次数高达506次，Full GC的持续时间很长，平均每次Full GC耗时达到9秒（4766/506，即GCT/FGC）。 确实验证了我们之前的想法，再返回第4或第5步查看其他几个高CPU占用率线程，找到非GC信息的堆栈，查看具体的代码。 2. Arthas (阿里开源)这是阿里开源出来的一个针对Java的线上诊断工具，功能非常强大，支持Linux/Mac/Windows，采用命令行交互模式 具体可以看我之前的一篇写Arthas的文章 3. show-busy-java-threads这个工具是useful-scripts 工具集的其中一个工具，用于快速排查Java CPU性能问题(top us值过高)，能自动查出运行Java进程中消耗CPU多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用 NOTE： 这个工具只能在Linux下使用 二、References https://alibaba.github.io/arthas/ https://github.com/alibaba/arthas https://binchencoder.github.io/2018/07/22/UsefulScripts-Java%E8%84%9A%E6%9C%AC/#show-busy-java-threads-sh"},{"title":"Arthas","date":"2019-11-29T12:53:08.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/11/29/Arthas/","permalink":"https://binchencoder.github.io/2019/11/29/Arthas/","excerpt":"","text":"ArthasArthas 是Alibaba开源的Java诊断工具，深受开发者喜爱。 当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ 怎么快速定位应用的热点，生成火焰图？ 下载下载arthas-boot.jar，然后用java -jar的方式启动： 123curl -O https://alibaba.github.io/arthas/arthas-boot.jarjava -jar arthas-boot.jar 如果从github下载有问题，可以使用gitee镜像 curl -O https://arthas.gitee.io/arthas-boot.jar watch方法执行数据观测 让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写OGNL表达式进行对应变量的查看。 watch 的参数比较多，主要是因为它能在 4 个不同的场景观察对象 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 express 观察表达式 condition-express 条件表达式 [b] 在方法调用之前观察 [e] 在方法异常之后观察 [s] 在方法返回之后观察 [f] 在方法结束之后(正常返回和异常返回)观察 [E] 开启正则表达式匹配，默认为通配符匹配 [x:] 指定输出结果的属性遍历深度，默认为 1 Samples watch123watch com.xxx.uac.service.OrgService getCompanyStopedUserDeptNode \"&#123;params, returnObj&#125;\" params[0]==10 -b -s -x 5watch com.xxx.search.searchcenter.spi.sp.Searcher execute \"&#123;params, returnObj&#125;\" \"params[0].&#123;? #this.routings[0]==2&#125;.size()&gt;0\" -x 5 References https://alibaba.github.io/arthas/ https://github.com/alibaba/arthas"},{"title":"多线程, 到底该设置多少线程","date":"2019-11-09T10:35:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/11/09/多线程 到底该设置多少线程/","permalink":"https://binchencoder.github.io/2019/11/09/%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E5%88%B0%E5%BA%95%E8%AF%A5%E8%AE%BE%E7%BD%AE%E5%A4%9A%E5%B0%91%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"一、前言作为2年以上的开发人员，如果还不理解多线程与多进程之间的区别，那你就赶紧停停手头的工作，回去好好复习吧 现在的程序设计中基本上都是多线程的，作为业务开发人员可能很多人都没有写过多线程的代码，因为这些高危的代码都由框架帮我们实现了，我们大多时间主要关注于实现自己的业务。但是如果搞懂多线程对于程序的调优和解决问题会很有帮助 在讲多线程之前，我先带领大家了解下其中的一些概念： 多线程：指的是这个程序（一个进程）运行时产生了不止一个线程 并行与并发： 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时 并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS或者QPS来反应这个系统的处理能力 二、 线程执行线程的执行，是由CPU进行调度的，一个CPU在同一时刻只会执行一个线程 为了让用户感觉这些任务正在同时进行，操作系统利用了时间片轮转的方式，CPU给每个任务都服务一定的时间，然后把当前任务的状态保存下来，在加载下一任务的状态后，继续服务下一任务。任务的状态保存及再加载，这段过程就叫做上下文切换 三、为什么要用多线程系统执行流程 上图是我们我们在设计Web系统中一个比较简单的流程： 浏览器或者其他客户端发起网络请求 Web服务器解析请求 请求后端的数据库获取数据 数据库返回数据给应用服务，进行处理 将处理之后的数据返回给客户端（用户） 下面我们一起来看下以上的这几步流程会涉及到什么计算机处理呢 网络请求 —–&gt; 网络IO 解析请求 —–&gt; CPU 请求数据库 —–&gt; 网络IO MySQL查询数据 —–&gt; 磁盘IO MySQL返回数据 —–&gt; 网络IO 数据处理 —–&gt; CPU 返回数据给用户 —–&gt; 网络IO 在真实业务中我们不单单会涉及CPU计算，还有网络IO和磁盘IO处理，这些处理是非常耗时的。如果一个线程整个流程是上图的流程，真正涉及到CPU的只有2个节点，其他的节点都是IO处理，那么线程在做IO处理的时候，CPU就空闲出来了，CPU的利用率就不高 多线程提高程序执行效率 对于多核处理系统上，将要执行的任务分割成多个可并行执行线程，就可以提高执行速率 对于单处理器上多线程只能并发执行而不是并行，并发原理，其实就是CPU快速来回切换，在特定的时间执行特定的某一个任务。并发执行存在着线程间上下文切换的问题，会消耗一定的时间。如果不考虑阻塞，多线程并发执行其实比单线程执行更加耗费时间，线程过多也会造成CPU负荷过大，并且线程占用内存资源，创建销毁线程也都是需要开销的 多线程通过提供CPU利用率来提高效率。数据库访问、磁盘IO等操作的速度比CPU执行代码速度慢很多，单线程环境下，这些操作会阻塞程序执行，导致CPU空转，因此对于会产生这些阻塞的程序来说，使用多线程可以避免在等待期间CPU的空转，提高CPU利用率 四、提升QPS/TPS衡量系统性能如何，主要指标系统的（QPS/TPS） QPS/TPS：每秒能够处理请求/事务的数量 并发数：系统同时处理的请求/事务的数量 响应时间：就是平均处理一个请求/事务需要时长 QPS/TPS = 并发数/响应时间 上面公式代表并发数越大，QPS就越大；所以很多人就会以为调大线程池，并发数就会大，也会提升QPS 其实QPS还跟响应时间成反比，响应时间越大，QPS就会越小 虽然并发数调大了，就会提升QPS，但线程数也会影响响应时间，因为上面我们也提到了上下文切换的问题，那怎么设置线程数的呢？ 五、如何设置线程数最佳线程数目 = （（线程等待时间+线程CPU时间）/线程CPU时间 ）* CPU数目 备注这个公式也是前辈们分享的，当然之前看了淘宝前台系统优化实践的文章，和上面的公式很类似，不过在CPU数目那边，他们更细化了，上面的公式只是参考。不过不管什么公式，最终还是在生产环境中运行后，再优化调整 假如我们的服务器CPU核数为4核，一个任务线程cpu耗时为20ms，线程等待（网络IO、磁盘IO）耗时80ms，那最佳线程数目：( 80 + 20 )/20 * 4 = 20。也就是设置20个线程数最佳 从这个公式上面我们就得出，线程的等待时间越大，线程数就要设置越大，这个正好符合我们上面的分析，可提升CPU利用率。那从另一个角度上面说，线程数设置多大，是根据我们自身的业务的，需要自己去压力测试，设置一个合理的数值 设置线程数常规标准用上面的最佳公式，我们可能还不能评估出设置的线程数。因为很多业务集中到一个线程池中，不像上面的案例比较简单，事实上业务太多，怎么设置呢？这个就是要去压力测试去调整。不过我们的前辈已经帮我们总结了一个基础的值（最终还是要看运行情况自行调整） CPU密集型：操作内存处理的业务，一般线程数设置为：CPU核数 + 1 或者 CPU核数*2。核数为4的话，一般设置 5 或 8 IO密集型：文件操作，网络操作，数据库操作，一般线程设置为：cpu核数 / (1-0.9)，核数为4的话，一般设置 40 六、总结讲到这里大家是不是对线程有了更新的了解呢？遇到性能问题，应该要去分析为什么这么慢，系统的瓶颈出现在什么地方，减少瓶颈的耗时 另外推荐大家再去了解下线程的生命周期、Redis的线程模型 [线程生命周期] https://binchencoder.github.io/2018/08/31/Thread-State/ [为什么redis 是单线程的] https://cloud.tencent.com/developer/article/1120615"},{"title":"面试如戏, 全靠演技","date":"2019-11-04T10:35:08.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/11/04/面试如戏全靠演技/","permalink":"https://binchencoder.github.io/2019/11/04/%E9%9D%A2%E8%AF%95%E5%A6%82%E6%88%8F%E5%85%A8%E9%9D%A0%E6%BC%94%E6%8A%80/","excerpt":"","text":"面试http://www.ityouknow.com/cartoon/2019/10/25/twome.html"},{"title":"排查产线系统僵死","date":"2019-09-26T07:53:08.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/09/26/排查产线系统僵死/","permalink":"https://binchencoder.github.io/2019/09/26/%E6%8E%92%E6%9F%A5%E4%BA%A7%E7%BA%BF%E7%B3%BB%E7%BB%9F%E5%83%B5%E6%AD%BB/","excerpt":"","text":"查看某个进程下各个线程运行情况 12345678910toptop - 15:14:57 up 18 days, 20:55, 2 users, load average: 8.29, 8.57, 8.88Tasks: 16 total, 1 running, 15 sleeping, 0 stopped, 0 zombieCpu(s): 15.8%us, 3.7%sy, 0.0%ni, 75.2%id, 4.7%wa, 0.0%hi, 0.7%si, 0.0%stMem: 197987944k total, 197041256k used, 946688k free, 1459640k buffersSwap: 8388604k total, 2936792k used, 5451812k free, 85205540k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 31318 root 20 0 18.3g 1.0g 22m S 4.0 0.5 423:46.06 java 1234567891011121314top -Hp 31318top - 15:15:43 up 18 days, 20:55, 2 users, load average: 7.89, 8.42, 8.81Tasks: 541 total, 0 running, 541 sleeping, 0 stopped, 0 zombieCpu(s): 15.8%us, 3.7%sy, 0.0%ni, 75.2%id, 4.7%wa, 0.0%hi, 0.7%si, 0.0%stMem: 197987944k total, 197030020k used, 957924k free, 1459640k buffersSwap: 8388604k total, 2936792k used, 5451812k free, 85206008k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 31470 root 20 0 18.3g 1.0g 22m S 3.9 0.5 213:51.56 java 31318 root 20 0 18.3g 1.0g 22m S 0.0 0.5 0:00.02 java 31324 root 20 0 18.3g 1.0g 22m S 0.0 0.5 0:17.63 java 31325 root 20 0 18.3g 1.0g 22m S 0.0 0.5 0:27.14 java 31326 root 20 0 18.3g 1.0g 22m S 0.0 0.5 0:27.71 java"},{"title":"下班后的生活改变人的一生","date":"2019-09-06T07:53:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/09/06/下班后的生活改变人的一生/","permalink":"https://binchencoder.github.io/2019/09/06/%E4%B8%8B%E7%8F%AD%E5%90%8E%E7%9A%84%E7%94%9F%E6%B4%BB%E6%94%B9%E5%8F%98%E4%BA%BA%E7%9A%84%E4%B8%80%E7%94%9F/","excerpt":"","text":""},{"title":"synchronized和lock","date":"2019-09-05T13:01:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/09/05/synchronized和lock/","permalink":"https://binchencoder.github.io/2019/09/05/synchronized%E5%92%8Clock/","excerpt":"","text":"开篇Java 使用synchronized和Lock两种机制实现某种共享资源的同步 synchronized 使用Object对象本身的notify、wait、notifyAll调度机制 Lock 可以使用Condition(java.util.concurrent.locks.Condition)进行线程之间的调度，完成synchronized的所有功能 区别用法不一样在需要同步的对象中加入synchronized，synchronized既可以加在方法上，也可以加在特定的代码中，括号中表示需要锁的对象。而Lock需要显示的指定起始位置和终点位置。synchronized是托管给JVM执行的，而Lock的锁定是通过代码实现的，它有比synchronized 更精确的线程定义 性能不一样在JDK1.5中增加的ReentrantLock, 它不仅拥有和synchronized相同的并发性和内存语义，还增加了锁投票，定时锁。等候和中断锁等。 他们的性能在不同的情况下会不同：在资源竞争不是很激烈的情况下，synchronized的性能要优于ReentantLock, 而在资源竞争很激烈的情况下， synchronized的性能会下降的比较快，而ReentantLock的性能基本保持不变 锁机制不一样synchronized获得锁和释放锁的机制都在代码块中，当获得锁时，必须以相反的机制去释放，并且自动解锁，不会因为异常导致没有被释放而导致死锁。 Lock需要开发人员手动去释放，并且在finally代码块中，否则可能引起死锁问题。Lock提供了更强大的功能，可以通过tryLock的方式采用非阻塞的方式获取锁。"},{"title":"TCP三次握手和四次握手","date":"2019-08-31T09:36:21.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/31/TCP三次握手和四次握手/","permalink":"https://binchencoder.github.io/2019/08/31/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8F%A1%E6%89%8B/","excerpt":"","text":"唠叨几句笔者最近在进行跳槽的前期准备，把基础知识重新温故了一遍，整理了一篇Java面试圣经，估计很多人看到都会望而却步，停止跳槽的步伐 😅 这篇文章不仅适用于即将准备跳槽的Java程序猿朋友，也同样适用于希望扩充自己知识面的Java开发者。 在Java面试圣经，网络协议这一块属于进阶篇，属于基础偏上的内容。在本文中我们会深入学习下TCP协议 TCP协议说到TCP协议，大家应该能联想到TCP/IP，这是互联网世界中非常重要的一个名词。TCP/IP不是一个协议，而是一个协议族的统称。里面包括了IP协议、IMCP协议、TCP协议，以及我们更加熟悉的http、ftp、pop3协议等等。 本文我们主要介绍TCP协议，TCP 用于应用程序之间的通信。 当应用程序希望通过 TCP 与另一个应用程序通信时，它会发送一个通信请求。这个请求必须被送到一个确切的地址。在双方“握手”之后，TCP 将在两个应用程序之间建立一个全双工 (full-duplex) 的通信。 这个全双工的通信将占用两个计算机之间的通信线路，直到它被一方或双方关闭为止。 下面就来详细介绍TCP如何在计算机之间通信的。 TCP三次握手 TCP 三次握手就好比两个人在街上隔着50米看见了对方，但是因为雾霾等原因不能100%确认，所以要通过招手的方式相互确定对方是否认识自己。 上图包括两部分：建立链接、传输数据 第一次握手 客户端发送SYN包(seq=x)到服务器，并进入SYN_SEND状态，等待服务器确认 SYN：同步序列编号（Synchronize Sequence Numbers） 第二次握手 服务器收到SYN包，必须确认客户端的SYN（ACK=x+1），同时自己也发送一个SYN包(seq=y)，即SYN+ACK包，此时服务器进入SYN_RECV状态 第三次握手 客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功） 状态，完成三次握手 最后通过动画演示一下 传输数据过程1.超时重传 超时重传机制用来保证TCP传输的可靠性。每次发送数据包时，发送的数据报都有seq号，接收端收到数据后，会回复ack进行确认，表示某一seq 号数据已经收到。发送方在发送了某个seq包后，等待一段时间，如果没有收到对应的ack回复，就会认为报文丢失，会重传这个数据包。 2.快速重传 接受数据一方发现有数据包丢掉了。就会发送ack报文告诉发送端重传丢失的报文。如果发送端连续收到标号相同的ack包，则会触发客户端的快速重 传。比较超时重传和快速重传，可以发现超时重传是发送端在傻等超时，然后触发重传;而快速重传则是接收端主动告诉发送端数据没收到，然后触发发送端重传。 3.流量控制 这里主要说TCP滑动窗流量控制。TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己 还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 滑动窗可以是提高TCP传输效率的一种机制。 4.拥塞控制 滑动窗用来做流量控制。流量控制只关注发送端和接受端自身的状况，而没有考虑整个网络的通信情况。拥塞控制，则是基于整个网络来考虑的。考虑一下这 样的场景：某一时刻网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多 的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风 暴”，TCP这个协议就会拖垮整个网络。为此，TCP引入了拥塞控制策略。拥塞策略算法主要包括：慢启动，拥塞避免，拥塞发生，快速恢复。 TCP四次握手 第一次握手 客户端进程发起连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 第二次握手 服务器收到连接释放报文，发送确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务器进入CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用程序，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了。但是服务器若发送数据，客户端依然要接收。这个状态还要持续一段时间，也就是CLOSE-WAIT状态持续的时间。 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 第三次握手 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 第四次握手 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 最后通过动画演示一下 常见面试题为什么连接的时候是三次握手，关闭的时候是四次握手？因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 为什么不能用两次握手进行连接？3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。 现在把三次握手改成仅需要两次握手，死锁是可能发生的。作为例子，考虑计算机S和C之间的通信，假定C给S发送一个连接请求分组，S收到了这个分组，并发 送了确认应答分组。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据分组。可是，C在S的应答分组在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求分组。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据分 组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。 如果已经建立了连接，但是客户端突然出现故障了怎么办？TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 End在我近期学习的过程中，我发现通过亲自画图的方式边学边理解，印象会更深刻。 故：接下来在我的文章中我都会尽可能挂上图片，提供给读者清俗易懂的文章，希望大家继续关注我的博客"},{"title":"Java面试之基础篇 - HashMap","date":"2019-08-29T13:53:08.000Z","updated":"2020-08-14T10:08:12.448Z","comments":true,"path":"2019/08/29/Java面试之基础篇 - HashMap/","permalink":"https://binchencoder.github.io/2019/08/29/Java%E9%9D%A2%E8%AF%95%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%AF%87%20-%20HashMap/","excerpt":"","text":"前言掌握Java基础技能不仅能在工作中得心应手，在面试中也会占尽优势。相信大家在过去的面试过程中一定被问到过关于HashMap的知识，最近笔者也在准备面试，打算重新学习一遍Java集合的知识。在此带领大家一起来学习下 HashMap是Java程序员使用频率最高的映射(键值对)处理的数据类型。随着JDK(Java Development Kit)版本的升级，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。 Map接口类继承图 说明： HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。 HashTable：Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，任一时间只有一个线程能写Hashtable，并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 LinkedHashMap：是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 JDK1.8中HashMap是如何扩容的？与JDK1.7有什么区别先来看图，以下是JDK1.7中HashMap的扩容机制： 1.7中的扩容过程会出现hash冲突 在JDK1.8中HashMap的扩容有很大的改进，由于扩容数组的长度是2倍的关系，所以对于假设初始 tableSize = 4 要扩容到 8 来说就是 0100 到 1000 的变化（左移一位就是 2 倍），在扩容中只用判断原来的 hash 值与左移动的一位（newtable 的值）按位与操作是 0 或 1 就行，0 的话索引就不变，1 的话索引变成原索引加上扩容前数组 以下是JDK1.8源码核心实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K, V&gt;[] resize() &#123; Node&lt;K, V&gt;[] oldTab = table; //记住扩容前的数组长度和最大容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //超过数组在java中最大容量就无能为力了，冲突就只能冲突 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //长度和最大容量都扩容为原来的二倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) &#123; newThr = oldThr &lt;&lt; 1; &#125; double threshold &#125; //...... ...... //更新新的最大容量为扩容计算后的最大容量 threshold = newThr; //更新扩容后的新数组长度 Node&lt;K, V&gt;[] newTab = (Node&lt;K, V&gt;[]) new Node[newCap]; table = newTab; if (oldTab != null) &#123; //遍历老数组下标索引 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K, V&gt; e; //如果老数组对应索引上有元素则取出链表头元素放在e中 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果老数组j下标处只有一个元素则直接计算新数组中位置放置 if (e.next == null) &#123; newTab[e.hash &amp; (newCap - 1)] = e; &#125; else if (e instanceof TreeNode) //如果是树结构进行单独处理 &#123; ((TreeNode&lt;K, V&gt;) e).split(this, newTab, j, oldCap); &#125; else &#123; preserve order //能进来说明数组索引j位置上存在哈希冲突的链表结构 Node&lt;K, V&gt; loHead = null, loTail = null; Node&lt;K, V&gt; hiHead = null, hiTail = null; Node&lt;K, V&gt; next; //循环处理数组索引j位置上哈希冲突的链表中每个元素 do &#123; next = e.next; //判断key的hash值与老数组长度与操作后结果决定元素是放在原索引处还是新索引 if ((e.hash &amp; oldCap) == 0) &#123; //放在原索引处的建立新链表 if (loTail == null) &#123; loHead = e; &#125; else &#123; loTail.next = e; &#125; loTail = e; &#125; else &#123; //放在新索引（原索引 + oldCap）处的建立新链表 if (hiTail == null) &#123; hiHead = e; &#125; else &#123; hiTail.next = e; &#125; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; //放入原索引处 loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; //放入新索引处 hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 在 JDK1.7 中扩容操作时，哈希冲突的数组索引处的旧链表元素扩容到新数组时，如果扩容后索引位置在新数组的索引位置与原数组中索引位置相同，则链表元素会发生倒置（即如上面图1，原来链表头扩容后变为尾巴）；而在 JDK1.8 中不会出现链表倒置现象。 其次，由于 JDK1.7 中发生哈希冲突时仅仅采用了链表结构存储冲突元素，所以扩容时仅仅是重新计算其存储位置而已，而 JDK1.8 中为了性能在同一索引处发生哈希冲突到一定程度时链表结构会转换为红黑数结构存储冲突元素，故在扩容时如果当前索引中元素结构是红黑树且元素个数小于链表还原阈值（哈希冲突程度常量）时就会把树形结构缩小或直接还原为链表结构（其实现就是上面代码片段中的 split() 方法）。 HashMap是如何避免key碰撞References HashMap对HashCode碰撞的处理 JDK1.8 HashMap源码分析"},{"title":"Kafka是如何实现几十万的高并发写入","date":"2019-08-28T02:23:58.000Z","updated":"2020-08-21T09:57:04.409Z","comments":true,"path":"2019/08/28/kafka是如何实现几十万的高并发写入/","permalink":"https://binchencoder.github.io/2019/08/28/kafka%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%87%A0%E5%8D%81%E4%B8%87%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%99%E5%85%A5/","excerpt":"","text":"开篇在初识kafka 一文中讲了使用MQ(消息队列)来设计系统带来的好处：业务解耦、流量削峰、灵活扩展 当下流行的MQ有很多，因为我们公司在技术选型上选择了使用Kafka，所以我就整理了一篇关于Kafka的入门知识。通过技术选型 我们对业界主流的MQ进行了对比，Kakfa最大的优点就是吞吐量高 。 Kafka是高吞吐低延迟的高并发、高性能的消息中间件，在大数据领域有极为广泛的运用。配置良好的Kafka集群甚至可以做到每秒几十万、上百万的超高并发写入。 那么Kafka是如何做到这么高的吞吐量和性能的呢？在入门之后我们就来深入的扒一下Kafka的架构设计原理，掌握这些原理在互联网面试中会占据优势 持久化Kafka对消息的存储和缓存依赖于文件系统，每次接收数据都会往磁盘上写，人们对于“磁盘速度慢”的普遍印象，使得人们对于持久化的架构能够提供强有力的性能产生怀疑。 事实上，磁盘的速度比人们预期的要慢的多，也快得多，这取决于人们使用磁盘的方式。而且设计合理的磁盘结构通常可以和网络一样快。 通过上图对比，我们可以看出实际上顺序磁盘访问在某些情况下比随机内存访问还要快，其实Kafka就是利用这一优势来实现高性能写磁盘 See http://kafka.apachecn.org/documentation.html#persistence 页缓存技术 + 磁盘顺序写Kafka 为了保证磁盘写入性能，首先Kafka是基于操作系统的页缓存来实现文件写入的。 操作系统本身有一层缓存，叫做page cache，是在内存里的缓存，我们也可以称之为os cache，意思就是操作系统自己管理的缓存。 你在写磁盘文件的时候，可以直接写入os cache 中，也就是仅仅写入内存中，接下来由操作系统自己决定什么时候把os cache 里的数据真的刷入到磁盘中。 通过上图这种方式可以将磁盘文件的写性能提升很多，其实这种方式相当于写内存，不是在写磁盘 顺序写磁盘另外还有非常关键的一点，Kafka在写数据的时候是以磁盘顺序写的方式来落盘的，也就是说，仅仅将数据追加到文件的末尾(append)，而不是在文件的随机位置来修改数据。 对于普通的机械硬盘如果你要是随机写的话，确实性能极低，这里涉及到磁盘寻址的问题。但是如果只是追加文件末尾按照顺序的方式来写数据的话，那么这种磁盘顺序写的性能基本上可以跟写内存的性能本身是差不多的。 来总结一下： Kafka就是基于页缓存技术 + 磁盘顺序写 技术实现了写入数据的超高性能。 所以要保证每秒写入几万甚至几十万条数据的核心点，就是尽最大可能提升每条数据写入的性能，这样就可以在单位时间内写入更多的数据量，提升吞吐量。 零拷贝技术(zero-copy)说完了写入这块，再来谈谈消费这块。 大家应该都知道，从Kafka里我们经常要消费数据，那么消费的时候实际上就是要从kafka的磁盘文件里读取某条数据然后发送给下游的消费者，如下图所示： 如果Kafka以上面这种方式从磁盘中读取数据发送给下游的消费者，大概过程是： 先看看要读的数据在不在os cache中，如果不在的话就从磁盘文件里读取数据后放入os cache 接着从操作系统的os cache 里拷贝数据到应用程序进程的缓存里，再从应用程序进程的缓存里拷贝数据到操作系统层面的Socket缓存里，最后从Soket缓存里提取数据后发送到网卡，最后发送出去给下游消费者 整个过程如下图： 从上图可以看出，这整个过程有两次没必要的拷贝 一次是从操作系统的cache里拷贝到应用进程的缓存里，接着又从应用程序缓存里拷贝回操作系统的Socket缓存里。 而且为了进行这两次拷贝，中间还发生了好几次上下文切换，一会儿是应用程序在执行，一会儿上下文切换到操作系统来执行。 所以这种方式来读取数据是比较消耗性能的。 Kafka 为了解决这个问题，在读数据的时候是引入零拷贝技术。 也就是说，直接让操作系统的cache中的数据发送到网卡后传出给下游的消费者，中间跳过了两次拷贝数据的步骤，Socket缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到Socket缓存。 体会一下这个精妙的过程吧： 通过零拷贝技术，就不需要把os cache里的数据拷贝到应用缓存，再从应用缓存拷贝到Socket缓存了，两次拷贝都省略了，所以叫做零拷贝。 对Socket缓存仅仅就是拷贝数据的描述符过去，然后数据就直接从os cache中发送到网卡上去了，这个过程大大的提升了数据消费时读取文件数据的性能。 而且大家会注意到，在从磁盘读数据的时候，会先看看os cache内存中是否有，如果有的话，其实读数据都是直接读内存的。 如果kafka集群经过良好的调优，大家会发现大量的数据都是直接写入os cache中，然后读数据的时候也是从os cache中读。 相当于是Kafka完全基于内存提供数据的写和读了，所以这个整体性能会极其的高。 总结通过学习Kafka的优秀设计，我们了解了Kafka底层的页缓存技术的使用，磁盘顺序写的思路，以及零拷贝技术的运用，才能使得Kafka有那么高的性能，做到每秒几十万的吞吐量。 名词解释 吞吐量(TPS)：吞吐量是指对网络、设备、端口、虚电路或其他设施，单位时间内成功地传送数据的数量（以比特、字节、分组等测量） References http://kafka.apachecn.org/documentation.html#maximizingefficiency http://kafka.apachecn.org/documentation.html#persistence"},{"title":"初识Kafka","date":"2019-08-27T12:53:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2019/08/27/初识kafka/","permalink":"https://binchencoder.github.io/2019/08/27/%E5%88%9D%E8%AF%86kafka/","excerpt":"","text":"开篇在微服务的架构设计中我们一般都会考虑服务之间互相调用的问题，如何做到更好的解耦设计。在秒杀的系统中会使用异步处理的方式来设计高并发、低延迟的系统架构。提到这些相信大家都会想到使用MQ(消息队列)来处理这些问题。 MQ(消息队列) 是跨进程通信方式之一，可理解为异步RPC，上游系统对调用结果的态度往往是重要不紧急。使用消息队列有几个好处：业务解耦、流量削峰、灵活扩展 技术选型现在业界主流的MQ有很多，比如：ActiveMQ、RabbitMQ、RocketMQ、Kafka 等，那么我们在技术选型中该怎么选择呢？ 特性 Kafka ActiveMQ RabbitMQ RocketMQ 单击吞吐量 10万级别，这是Kafka最大的优点，就是吞吐量高。一般配合大数据类的系统来进行实时数据计算，日志采集等场景。 万级，吞吐量比RocketMQ和Kafka要低一个数量级 万级，吞吐量比RocketMQ和Kafka要低一个数量级 10万级，RocketMQ也是可以支撑高吞吐的一种MQ topic数量对吞吐量的影响 topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，Kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多机器资源。 topic可以达到几百，几千个的级别，吞吐量会较小幅度的下降，这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic。 时效性 延迟在ms以内 ms级 微妙级，这是rabbitMq的一大特点，延迟是最低的 ms级 可用性 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 高，基于主从框架实现高可用性 高，基于主从架构实现高可用性 非常高，分布式架构 消息可靠性 经过参数优化配置，消息可以做到0丢失 有较低的概率丢失数据 经过参数优化配置可以做到0丢失 功能支持 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准 MQ领域的功能及其完备 基于erlang开发，所以并发能力很强，性能及其好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 优劣势总结 kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 这个特性天然适合大数据实时计算以及日志收集 非常成熟，功能强大，在业内大量的公司以及项目中都有应用。 偶尔会有较低概率的丢失消息。 而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ维护越来越少，几个月才发布一个版本。 而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用。 erlang语言开发，性能及其好，延时很低：吞吐量到万级，MQ功能比较完备，而且开源提供的管理界面非常棒，用起来很好用。社区相对比较活跃，几乎每个月都发布几个版本。在国内公司用 rabbitmq也比较多一些 但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。 而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。 接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障 日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景 而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码 还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的 综上比较，可以看出RocketMQ和Kafka 优势较为明显，其实对于大多数的服务架构来说，吞吐量 和 消息可靠性 是我们选型中考虑较多的因素。接下来我们就一起来了解下Kafka 相关的内容 Kafka简介Apache Kafka 起源于LinkedIn，后来于2011年成为Apache开源项目。Kafka是用Scala和Java编写的。 Apache Kafka官网 上介绍，Kafka是一个分布式流处理平台，具有以下三个特性： 可以让你发布和订阅流式的记录。这一方面与消息队列或者企业消息系统类似； 可以储存流式的记录，并且有较好的容错性； 可以在流式记录产生时就进行处理。 接下来我们会就第一个特性，Kafka作为消息队列所具有的优势和特点： Kafka作为一个分布式消息队列，具有高性能、持久化、多副本备份、横向扩展能力。生产者往消息队列里写消息，消费者从队列里取消息进行业务逻辑。一般在架构设计中起到解耦、削峰、异步处理的作用。 Kafka 架构总览 上图清晰的描述了Kafka的总体数据流，关于broker、topics、partitions 的一些元信息用zk来存 Producers 负责往Brokers 里面指定Topic中写消息 Consumers 从Brokers 中拉取指定Topics的消息，然后进行自己的业务处理 图中有3个topic： topic1有2个partition（topic1-partition1、topic1-partition2），两副本备份 topic2有3个parition（topic2-partition1、topic2-partition2、topic2-partition3），三副本备份 topic3有2个partition（topic3-partition1、topic3-partition2），两副本备份 Topic消息的主题、队列，每一个消息都有它的topic，Kafka通过topic对消息进行归类。Kafka中可以将Topic从物理上划分成一个或多个分区（Partition），每个分区在物理上对应一个文件夹，以”topicName_partitionIndex”的命名方式命名，该dir包含了这个分区的所有消息(.log)和索引文件(.index)，这使得Kafka的吞吐率可以水平扩展 See http://kafka.apachecn.org/intro.html#intro_topics Partition每个分区都是一个 顺序的、不可变的消息队列， 并且可以持续的添加;分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的。 producer在发布消息的时候，可以为每条消息指定Key，这样消息被发送到broker时，会根据分区算法把消息存储到对应的分区中（一个分区存储多个消息），如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡。 See http://kafka.apachecn.org/intro.html#intro_distribution BrokerKafka server，用来存储消息，Kafka集群中的每一个服务器都是一个Broker，消费者将从Broker拉取订阅的消息 Producer向Kafka发送消息，生产者会根据topic分发消息。生产者也负责把消息关联到Topic上的哪一个分区。最简单的方式从分区列表中轮流选择。也可以根据某种算法依照权重选择分区。算法可由开发者定义。 See http://kafka.apachecn.org/intro.html#intro_producers CousumerConsumer实例可以是独立的进程，负责订阅和消费消息。消费者用consumerGroup来标识自己。同一个消费组可以并发地消费多个分区的消息，同一个partition也可以由多个consumerGroup并发消费，但是在consumerGroup中一个partition只能由一个consumer消费 See http://kafka.apachecn.org/intro.html#intro_consumers CousumerGroup同一个Consumer Group中的Consumers，Kafka将相应Topic中的每个消息只发送给其中一个Consumer 如图，这个 Kafka 集群有两台 server 的，四个分区(p0-p3)和两个消费者组。消费组A有两个消费者，消费组B有四个消费者。 通常情况下，每个 topic 都会有一些消费组，一个消费组对应一个”逻辑订阅者”。一个消费组由许多消费者实例组成，便于扩展和容错。这就是发布和订阅的概念，只不过订阅者是一组消费者而不是单个的进程。 在Kafka中实现消费的方式是将日志中的分区划分到每一个消费者实例上，以便在任何时间，每个实例都是分区唯一的消费者。维护消费组中的消费关系由Kafka协议动态处理。如果新的实例加入组，他们将从组中其他成员处接管一些 partition 分区;如果一个实例消失，拥有的分区将被分发到剩余的实例。 Kafka 只保证分区内的记录是有序的，而不保证主题中不同分区的顺序。每个 partition 分区按照key值排序足以满足大多数应用程序的需求。但如果你需要总记录在所有记录的上面，可使用仅有一个分区的主题来实现，这意味着每个消费者组只有一个消费者进程。 Kafka配置项http://kafka.apachecn.org/documentation.html#configuration 名词解释 吞吐量(TPS)：吞吐量是指对网络、设备、端口、虚电路或其他设施，单位时间内成功地传送数据的数量（以比特、字节、分组等测量） References 消息中间件如何实现每秒几十万的高并发写入 kafka系统设计开篇 https://www.jianshu.com/p/d3e963ff8b70"},{"title":"深入理解JVM - 垃圾回收之世代垃圾收集过程","date":"2019-08-24T09:00:18.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/08/24/深入理解JVM - 垃圾回收之世代垃圾收集过程/","permalink":"https://binchencoder.github.io/2019/08/24/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%20-%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E4%B9%8B%E4%B8%96%E4%BB%A3%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E8%BF%87%E7%A8%8B/","excerpt":"","text":"前言在 深入理解 - 垃圾回收 中我们详细讲解了JVM垃圾回收的机制、垃圾收集算法以及各种垃圾回收器的原理和优缺点。 通过上一篇文章我们知道现在主流的垃圾回收器都采用了分代收集算法，本文我们就来详细讲解下垃圾回收器是如何进行分代收集垃圾的 JVM分代分代其实就是将堆分成几个部分，分别是新生代、老年代和永久代 新对象会被分配在新生代内存。一旦新生代内存满了，就会开始对死掉的对象，进行所谓的小型垃圾回收过程。一旦新生代内存里，死掉的越多，回收过程就越快；至于那些还活着的对象，此时就会老化，并最终老到进入老年代内存。 Stop the World 事件 —— 小型垃圾回收属于一种叫 “Stop the World” 的事件。在这种事件发生时，所有的程序线程都要暂停，直到事件完成（比如这里就是完成了所有回收工作）为止。 老年代用来保存长时间存活的对象。通常设置一个阈值，当达到该年龄时，年轻代对象会被移动到老年代。最终老年代也会被回收。这个事件称为Major GC。 Major GC 也会触发STW（Stop the World）。通常，Major GC会慢很多，因为它涉及到所有存活对象。所以，对于响应性的应用程序，应该尽量避免Major GC。还要注意，Major GC的STW的时长受年老代垃圾回收器类型的影响。 永久代 包含JVM用于描述应用程序中类和方法的元数据。永久代是由JVM在运行时根据应用程序使用的类来填充的。此外，Java SE类库和方法也存储在这里。 如果JVM发现某些类不再需要，并且其他类可能需要空间，则这些类可能会被回收。 世代垃圾回收过程现在我们已经理解了为什么堆被分成不同的代，接下来我们一起来看看这些空间是如何相互作用，JVM中的对象是如何分配和老化的 首先，将任何新对象分配给Eden空间，两个survivor空间都是空的 当eden空间填满时，会触发轻微的垃圾收集 引用的对象被移动到第一个survivor空间，清除eden空间时，将删除未引用的对象 在下一次的Minor GC中，Eden区也会做同样的操作。删除未被引用的对象，并将被引用的对象移动到Survivor区。然后，他们被移动到了第二个Survivor区（S1）。此外，第一个Suvivor区（S0）中，在上一次Minor GC幸存的对象，会增加年龄，并被移动到S1中。待所有幸存对象都被移动到S1后，S0和Eden区会被清空。注意，Survivor区中有了不同年龄的对象。 在下一次的Minor GC中，会重复同样的动作。不过，这一次Survivor区会交换。被引用的对象移动到S0，幸存的对象增加年龄。Eden区和S1被清空 在较小的GC之后，当老化的物体达到一定的年龄阈值（在该示例中为8）时，它们从年轻一代晋升到老一代。 随着较小的GC持续发生，物体将继续被推广到老一代空间。 所以这几乎涵盖了年轻一代的整个过程。 最终，将主要对老一代进行GC，清理并最终压缩该空间。"},{"title":"深入理解JVM - 垃圾回收","date":"2019-08-23T15:00:18.000Z","updated":"2020-08-06T07:56:21.920Z","comments":true,"path":"2019/08/23/深入理解JVM - 垃圾回收/","permalink":"https://binchencoder.github.io/2019/08/23/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%20-%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"前言在 JVM内存结构 中我们详细讲解了JVM中的内存是如何分布和组成的。 我们已经知道JVM内存结构主要有三大块：堆内存、方法区和栈内存，而堆又是JVM中占用内存最大的一块，但是堆占用的空间也不是无限的(在JVM中会有参数来进行控制)，在程序运行的过程中，会不断的产生对象，导致堆的内存空间减少，这时我们会想到一定有一种机制来进行回收。接下来我们就一起来看看JVM是如何回收不再使用的对象空间的。 垃圾回收机制Java垃圾回收主要关注堆 Java内存运行时区域中的程序计数器、虚拟机栈、本地方法栈 都是线程私有的，因此它们的生命周期与线程的生命周期是一样的；栈中的栈帧随着方法的进入和退出有条无紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的（尽管在运行期会由JIT编译器进行一些优化）。因此这几个区域的内存分配和回收都具备确定性，不需要过多考虑回收的问题，因此方法结束或者线程结束时，内存自然就随着回收了。 而Java堆不一样，一个接口中的多个实现类需要的内存不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时才能知道创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器所关注的是这部分内存。 判断需要被回收对象的方法引用计数法 该方法简单高效，缺点是无法解决对象之间相互循环引用的问题 可达性分析法 解决了引用计数法 循环引用的问题 不可达的对象将暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程 垃圾收集算法一共有四种： 标记-清除算法、复制算法、标记-整理算法、分代收集算法 标记-清除算法(Mark-Sweep)这是最基础的算法，分为“标记” 和 “清除” 两个阶段。首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象 缺点： 效率问题 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多会导致以后需要分配较大的对象空间时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作 复制算法(Copying) 现在的商业虚拟机都采用这种算法来回收新生代 复制算法是为了为了解决效率的问题，它将可用内存分为大小相等的两块。每次只使用其中的一块。当这一块的内存用完了，就将还活着的对象复制到另外一块上，然后把已使用的内存空间一次性清理掉。 这个算法的缺点是可用内存缩小为原来的一半 标记-整理算法(Mark-Compact)复制算法在对象存活率较高的情况下要进行较多的复制操作，效率会降低。 复制算法并不适用于老年代，所以才有了“标记-整理” 算法，标记的过程与“标记-清除” 是一样的，第二步不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端便捷以外的内存 分代收集算法 (Generational Collection)现代商业虚拟机的垃圾收集都采用这一算法，它是根据对象存活周期的不同将内存划分为几块并采用不同的垃圾收集算法。 一般将Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 新生代：每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制法，只需要付出少量存活对象的复制成本就可以完成收集 老年代：因为对象存活率高，没有额外空间对它进行分配担保，那就必须使用标记-清理 或者 标记-整理 算法来进行回收 垃圾回收器分类如果垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现 Serial收集器(串行收集器) 这是一个单线程的收集器，它在进行垃圾收集时，必须暂停掉其他所有的工作线程，直到它收集结束（Stop The World） Serial Old收集器 这是Serial收集器是老年代版本，也是一个单线程，使用 标记-整理 算法。 ParNew收集器(串行收集器) ParNew收集器是Serial收集器的多线程版本 除了使用多条线程进行垃圾收集之外，其余行为包括 Serial 收集器可用的所有控制参数（例如：-XX:SurvivorRatio、-XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。 Parallel Scavenge收集器(并行收集器)这是一个新生代收集器，使用复制算法，又是并行的多线程收集器。Parallel Scavenge 收集器的目标是达到一个可控制的吞吐量(Througput) 吞吐量 = 运行用户代码时间 /（运行用户代码时间+垃圾收集时间），虚拟机总共运行了 100 分钟，其中垃圾收集花掉1分钟，那吞吐量就是99% Parallel Old收集器(并行收集器) 这是Parallel Scavenge收集器的老年代版本，使用多线程和标记-整理算法 Sample: 12java -Xmx3800m -Xms3800m -Xmn2g -Xss128k -XX:+UseParallelGC -XX:ParallelGCThreads&#x3D;20 -XX:+UseParallelOldGC MaxGCPauseMillis&#x3D;100 -XX:MaxGCPauseMillis&#x3D;100 CMS收集器(Concurrent Mark Sweep 并发标记扫描) 这是一种以获取最短回收停顿时间为目标的收集器 步骤： 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） 初始标记、重新标记这两个步骤仍然需要”Stop The World”。 优点： 并发收集，低停顿 缺点： 导致吞吐量降低：CMS收集器对CPU资源比较敏感，在并发阶段会占用一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量降低 无法处理浮动垃圾：可能出现”Concurrent Mode Failure”失败而导致另一次 Full GC（新生代和老年代同时回收） 的产生 产生空间碎片：空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次 Full GC Sample: 12java -Xmx3550m -Xms3550m -Xmn2g -Xss128k-XX:ParallelGCThreads&#x3D;20 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:CMSFullGCsBeforeCompaction&#x3D;5 -XX:+UseCMSCompactAtFullCollection G1收集器（Garbage-First）【重点】 G1 是一款面向服务端应用的垃圾收集器 步骤： 初始标记（Initial Marking） 并发标记（Concurrent Marking） 最终标记（Final Marking） 筛选回收（Live Data Counting and Evacuation） 优点： 并行与并发：G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短 Stop-The-World 停顿的时间，部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 Java 程序继续执行 分代收集：能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果 空间整合：G1从整体上看是基于“标记-整理”算法实现的，从局部（两个 Region 之间）上来看是基于“复制”算法实现的。这意味着G1运行期间不会产生内存碎片，收集后能提供规整的内存空间 可预测的停顿：可建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒 Rerferences 大白话讲解Jvm的G1垃圾收集器 GC日志阅读 GC 日志是处理 Java 虚拟机内存问题的基础技能，它只是一些人为确定的规则，没有太多技术含量。 每一种收集器的日志形式都是由它们自身的实现所决定的，换而言之，每个收集器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定的共性，例如以下两段典型的 GC 日志： 1233.125:[GC[DefNew:3324K-＞152K（3712K），0.0025925 secs]3324K-＞152K（11904K），0.0031680 secs]100.667:[Full GC[Tenured:0 K-＞210K（10240K），0.0149142secs]4603K-＞210K（19456K），[Perm:2999K-＞2999K（21248K）]，0.0150007 secs][Times:user=0.01 sys=0.00，real=0.02 secs] 最前面的数字33.125： 和 100.667： 代表了 GC 发生的时间，这个数字的含义是从 Java 虚拟机启动以来经过的秒数。 GC 日志开头的 [GC 和 [Full GC 说明了这次垃圾收集的停顿类型，而不是用来区分新生代 GC 还是老年代 GC 的。 如果有 Full，说明这次 GC 是发生了 Stop-The-World 的，例如下面这段新生代收集器 ParNew 的日志也会出现 [Full GC（这一般是因为出现了分配担保失败之类的问题，所以才导致 STW）。如果是调用 System.gc() 方法所触发的收集，那么在这里将显示 [Full GC（System） 1[Full GC 283.736:[ParNew:261599K-＞261599K（261952K），0.0000288 secs] 接下来的 [DefNew、[Tenured、[Perm 表示 GC 发生的区域，这里显示的区域名称与使用的 GC 收集器是密切相关的，例如上面样例所使用的 Serial 收集器中的新生代名为 “Default New Generation”，所以显示的是 [DefNew。如果是 ParNew 收集器，新生代名称就会变为 [ParNew，意为 “Parallel New Generation”。如果采用 Parallel Scavenge 收集器，那它配套的新生代称为 PSYoungGen，老年代和永久代同理，名称也是由收集器决定的。 后面方括号内部的 3324K-＞152K（3712K）含义是GC 前该内存区域已使用容量 -＞ GC 后该内存区域已使用容量 （该内存区域总容量）。而在方括号之外的 3324K-＞152K（11904K） 表示 GC 前 Java 堆已使用容量 -＞ GC 后 Java 堆已使用容量 （Java 堆总容量） 再往后，0.0025925 secs 表示该内存区域 GC 所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如 [Times:user=0.01 sys=0.00，real=0.02 secs] ，这里面的 user、sys 和 real 与 Linux 的 time 命令所输出的时间含义一致，分别代表用户态消耗的 CPU 时间、内核态消耗的 CPU 事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time） CPU 时间与墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘 I/O、等待线程阻塞，而 CPU 时间不包括这些耗时，但当系统有多 CPU 或者多核的话，多线程操作会叠加这些 CPU 时间，所以读者看到 user 或 sys 时间超过 real 时间是完全正常的 垃圾回收器的选择决定因素： 应用程序的场景 硬件的制约 吞吐量的需求 串行垃圾回收是最简单，但是效率最低的垃圾回收器。适用于控制台的单线程程序，简单任务。 并行垃圾回收器是64bit server默认的垃圾回收器，一般我们工作和产线上如果不配置，默认都是并行垃圾回收。对于一般的不要求吞吐的应用，并且硬件资源不是太充足的情况下，并行垃圾回收器差不多能满足需求。 重点 CMS垃圾回收器是对并行垃圾回收器的一个优化，它以CPU和系统资源为代价，换区GC的延迟。不会一GC就STW，而是根据情况STW。一定程度上是资源换取速度。 G1垃圾回收器是针对大Heap的垃圾回收器，如果heap分配的足够大，分的region的优先级回收策略会优先清理垃圾多的region。并且减少了内存空间碎片，分配大对象时不会因为无法找到连续的内存空间而提前触发下一次GC。 Option Description -XX:+UseSerialGC Serial Garbage Collector 串行垃圾回收器 -XX:+UseParallelGC Parallel Garbage Collector并行垃圾回收器 -XX:+UseConcMarkSweepGC CMS Garbage Collector并发标记垃圾回收器 -XX:ParallelCMSThreads= CMS Collector – number of threads to use 并发标记垃圾回收器使用的线程数，通常是cpu个数 -XX:+UseG1GC G1 Gargbage Collector 使用G1垃圾回收器 垃圾收集器参数总结 查看垃圾回收器12345chenbindeMacBook-Pro:BazelWorkspace chenbin$ java -XX:+PrintCommandLineFlags -version-XX:InitialHeapSize&#x3D;268435456 -XX:MaxHeapSize&#x3D;4294967296 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGCjava version &quot;1.8.0_112&quot;Java(TM) SE Runtime Environment (build 1.8.0_112-b16)Java HotSpot(TM) 64-Bit Server VM (build 25.112-b16, mixed mode) 名词术语 Full GC：新生代和老年代同时回收 References Java垃圾回收 Java 垃圾回收机制"},{"title":"深入理解JVM - 内存结构","date":"2019-08-21T15:00:18.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/08/21/深入理解JVM - 内存结构/","permalink":"https://binchencoder.github.io/2019/08/21/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%20-%20%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/","excerpt":"","text":"前言每个使用Java的开发者都知道Java字节码是在JRE中运行，JRE由Java API和JVM组成，JVM通过类加载器(Class Loader)加载Java应用，并通过Java API进行执行。 JVM则是JRE中的核心组成部分，承担分析和执行Java字节码的工作，而Java开发人员通常并不需要深入了解JVM运行情况就可以开发出大型应用和类库。尽管如此，相信所有的Java开发人员在工作中都会遇到这样的困惑：该为堆内存设置多大的空间？OutOfMemoryError的异常到底涉及到运行时数据的哪块区域，遇到了该如何解决？ 在Java成长的道路上，对JVM调优是一项最基本的技能。如果你是一名资深的Java开发人员，一定会接到解决服务器性能的任务，而深入理解JVM则是解决这一问题的根本。 JVM内存结构 JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代 组成。而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配的; 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名 Non-Heap(非堆); 栈又分为虚拟机栈和本地方法栈，主要用于方法的执行。 上图详细标注了如何通过参数来控制各区域的内存大小 控制参数 -Xms 设置堆的最小空间大小 -Xmx 设置堆的最大空间大小 -XX:NewSize 设置新生代最小空间大小 -XX:MaxNewSize 设置新生代最大空间大小 -XX:PermSize 设置永久代最小空间大小 -XX:MaxPermSize 设置永久代最大空间大小 -Xss 设置每个线程的堆栈大小 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制 老年代空间大小 = 堆空间大小 - 年轻代大空间大小 Java运行时数据区Java虚拟机在执行Java程序的过程中会将其管理的内存划分为若干个不同的数据区域，这些区域有各自的用途、创建和销毁的时间，有些区域随虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和结束来建立和销毁。Java虚拟机所管理的内存包括以下几个运行时数据区域，如图： Java堆(Heap)对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区(Method Area)方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 程序计数器(Program Counter Register) 指向当前线程正在执行的字节码指令。是线程私有的 程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈(JVM Stack) 包括局部变量表、操作数栈、动态链接、返回地址 局部变量表：包含了方法执行过程中的所有变量。局部变量数组所需要的空间在编译期间完成分配，在方法运行期间不会改变局部变量数组的大小。 返回值：如果有返回值的话，压入调用者栈帧中的操作数栈中，并且把PC的值指向 方法调用指令 后面的一条指令地址。 操作数栈：操作变量的内存模型。操作数栈的最大深度在编译的时候已经确定（写入方法区code属性的max_stacks项中）。操作数栈的的元素可以是任意Java类型，包括long和double，32位数据占用栈空间为1，64位数据占用2。方法刚开始执行的时候，栈是空的，当方法执行过程中，各种字节码指令往栈中存取数据。 动态链接：每个栈帧都持有在运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接。 与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈(Native Method Stacks)本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。"},{"title":"认识Bazel","date":"2019-08-16T12:53:08.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2019/08/16/认识Bazel/","permalink":"https://binchencoder.github.io/2019/08/16/%E8%AE%A4%E8%AF%86Bazel/","excerpt":"","text":"Bazel入门最近一直在研究网关这玩意，想借鉴我们公司的网关架构自己实现一下。思路是引入grpc-gateway，只是在这套系统的基础上增加一些定制的功能，如：负载均衡，权限验证，API参数检查。因为grpc-gateway采用的是Bazel来构建的，所以我要实现的网关也必须是用Bazel来构建。虽然在公司里接触过Bazel，但那也是在比较完善的平台上照葫芦画瓢。 为了完成自己的目标，只能硬着头皮边学边用，边用边学了 Bazel是什么Bazel 是一个开源的构建和测试工具，\b类似于Make、Maven及Gradle。它使用一种人易于理解的高级构建语言。Bazel 支持多种开发语言的项目，能够基于多个平台来构建。Bazel支持跨多个制品库和大规模用户的大型代码仓库。 为什么使用BazelBazel具有以下优势： 高级构建语言 Bazel使用一种抽象的、人易于理解的、语义级别的高级语言来描述项目的构建属性。与其他工具不同，Bazel基于库，二进制文件，脚本和数据集的概念进行操作，使您免于陷入将单个调用编写到编译器和链接器等工具的复杂性。 Bazel高效可靠 Bazel缓存以前完成的所有工作，并跟踪文件内容和构建命令的更改。通过这种方式，Bazel知道何时需要重建某些东西，并仅重建那些东西。为了进一步加快构建速度，您可以将项目设置为以并行和增量的方式构建。 Bazel是跨平台的 Bazel可以在Linux，macOS和Windows上运行。Bazel可以为同一个项目中的多个平台(包括桌面,服务器和移动设备)构建二进制文件和可部署软件包。 Bazel扩展性强 Bazel在使用100k+源文件处理构建时仍然保持良好的性能表现。它适用于多个制品存储库和10K用户规模。 核心概念Bazel根据在称为工作空间(WORKSPACE)的目录中组织的源代码构建软件。工作空间中的源文件以包的嵌套层次结构进行组织，其中每个包都是包含一组相关源文件和一个BUILD文件的目录。BUILD文件指定可以从源构建哪些软件输出。 工作空间工作空间是文件系统上的目录，每个工作空间目录都有一个名为WORKSPACE的文本文件，该文件可能为空(不建议这样做，至少定义一个name)，或者可能包含对构建输出所需的外部依赖项的引用。 Sample: 1workspace(name &#x3D; &quot;com_github_binchencoder_ease_gateway&quot;) 程序包工作空间中代码组织的主要单元是包。包是相关文件的集合，以及它们之间的依赖关系的规范。每个程序包中包含一个BUILD文件，此文件中描述了此工具包的生成构建方式。 目标生成的目标，每个target又可以作为另外一个规则的输入。绝大部分的target属于两种基本类型中的一种，file和rule。另外，还有一种其他的target类型，package group。但是他们很少见。 进阶上述就是bazel最简单的描述，如果要学习bazel的详细进阶，可以访问起官网，官网上的文档非常详细，不过是英文的。 另外，我的github有几个更多的例子，可以进一步学习和理解bazel。 References: https://bazel.build https://github.com/grpc-ecosystem/grpc-gateway https://github.com/binchencoder/ease-gateway"},{"title":"JVM内存管理","date":"2019-08-11T12:53:08.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/11/JVM内存管理/","permalink":"https://binchencoder.github.io/2019/08/11/JVM%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","excerpt":"","text":"JVM内存管理作为三大工业级别语言之一的JAVA如此受企业青睐有加，离不开她背后JVM的默默复出。只是由于JAVA过于成功以至于我们常常忘了JVM平台上还运行着像Clojure/Groovy/Kotlin/Scala/JRuby/Jython这样的语言。我们享受着JVM带来跨平台“一次编译到处执行”的便利和自动内存回收的安逸。 JVM是JAVA的核心基础，也是掌握JAVA语言的重难点，如果没有理解JVM的知识体系，就不要说自己是JAVA高手。最近我打算换工作，所以来重新回顾JVM的相关知识，为面试准备。JVM体系内知识点很多，通过以下关键词来简单概括下： 类结构，类加载器，加载，链接，初始化，双亲委派，热部署，隔离，堆，栈，方法区，计数器，内存回收，执行引擎，调优工具，JVMTI，JDWP，JDI，热替换，字节码，ASM，CGLIB，DCEVM 本文从JVM的内存结构入手，介绍JVM逻辑内存的分布和管理方式，同时列举常用的JVM调优工具和使用方法。 内存结构逻辑分区JVM内存从应用逻辑上可分为如下区域： 程序计数器程序计数器是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器，每个线程都需要一个程序计数器。在虚拟机的概念模型里（仅仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时，就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳准、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 简单理解就是程序计数器保证了程序的正常执行。 虚拟机栈方法执行时创建栈帧(存储局部变量，操作栈，动态链接，方法出口)编译时期就能确定占用空间大小，线程请求的栈深度超过jvm运行深度时抛StackOverflowError，当jvm栈无法申请到空闲内存时抛OutOfMemoryError，通过-Xss,-Xsx来配置初始内存 本地方法栈执行本地方法，如操作系统native接口 堆存放对象的空间，通过-Xmx,-Xms配置堆大小，当堆无法申请到内存时抛OutOfMemoryError 方法区存储类数据，常量，常量池，静态变量，通过MaxPermSize参数配置 对象访问初始化一个对象，其引用存放于栈帧，对象存放于堆内存，对象包含属性信息和该对象父类、接口等类型数据（该类型数据存储在方法区空间，对象拥有类型数据的地址） 内存模型堆内存堆内存是运行时的数据区，从中分配所有的Java类实例和数组的内存，可以理解为目标应用依赖的对象。堆在JVM启动时创建，并在应用程序运行时可能会增大或减小。可以使用-Xms`选项指定堆的大小。堆可以是固定大小或可变大小，具体取决于垃圾收集策略。可以使用-Xmx选项设置最大堆大小。默认情况下，最大堆大小设置为64M。 JVM堆内存在物理上分为两部分：新生代和老年代。新生代是为分配新对象而保留堆空间。当新生代占用完时，Minor GC垃圾收集器会对新生代区域执行垃圾回收动作。其中在新生代中生活了足够长的所有对象被迁移到老生代，从而释放新生代空间以进行更多的对象分配。此垃圾收集称为Minor GC。新生代分分为三个子区域：伊甸园Eden区和两个幸存区S0`和`S1。 关于新生代空间： 大多数新创建的对象都位于Eden区内存空间 当Eden区填满对象时，执行Minor GC并将所有幸存对象移动到其中一个幸存区空间 Minor GC还会检查幸存区对象并将其移动到其他幸存者空间，也即是幸存区总有一个是空的 在多次GC后还存活的对象被移动到老年代内存空间。至于经过多少次GC晋升老年代则由参数配置，通常为15 当老年区填满时，老年区同样会执行垃圾回收。老年区还包含那些经过多Minor GC后还存活的长寿对象。垃圾收集器在老年代内存中执行的垃圾回收称为Major GC，通常需要更长的时间。 Full GC ？？？ 非堆内存JVM堆以外的内存称为非堆内存。也即是JVM自身预留的内存区域，包含JVM缓存空间，类结构如常量池、字段和方法数据，方法，构造方法。类非堆内存的默认最大大小为64MB。可以用 -XX: MaxPermSize VM选项更改此选项，非堆内存通常包含如下性质的区域空间： 元空间（Metaspace） 在Java 8以上版本已经没有Perm Gen这块区域了，这也意味着不会再由关于“java.lang.OutOfMemoryError：PermGen”内存问题存在了。与驻留在Java堆中的Perm Gen不同，Metaspace不是堆的一部分。类元数据多数情况下都是从本地内存中分配的。默认情况下，元空间会自动增加其大小(直接又底层操作系统提供)，而Perm Gen始终具有固定的上限。可以使用两个新标志来设置Metaspace的大小，它们是：“ - XX：MetaspaceSize ”和“ -XX：MaxMetaspaceSize ”。Metaspace背后的含义是类的生命周期及其元数据与类加载器的生命周期相匹配。也就是说，只要类加载器处于活动状态，元数据就会在元数据空间中保持活动状态，并且无法释放。 代码缓存 运行Java程序时，它以分层方式执行代码。在第一层，它使用客户端编译器（C1编译器）来编译代码。分析数据用于服务器编译的第二层（C2编译器），以优化的方式编译该代码。默认情况下，Java 7中未启用分层编译，但在Java 8中启用了分层编译。实时（JIT）编译器将编译的代码存储在称为代码缓存的区域中。它是一个保存已编译代码的特殊堆。如果该区域的大小超过阈值，则该区域将被刷新，并且GC不会重新定位这些对象。Java 8中已经解决了一些性能问题和编译器未重新启用的问题，并且在Java 7中避免这些问题的解决方案之一是将代码缓存的大小增加到一个永远不会达到的程度。 方法区 方法区域是Perm Gen中空间的一部分，用于存储类结构（运行时常量和静态变量）以及方法和构造函数的代码。 内存池 内存池由JVM内存管理器创建，用于创建不可变对象池。内存池可以属于Heap或Perm Gen，具体取决于JVM内存管理器实现。 常量池 常量包含类运行时常量和静态方法，常量池是方法区域的一部分。 Java堆栈内存 Java堆栈内存用于执行线程。它们包含特定于方法的特定值，以及对从该方法引用的堆中其他对象的引用。 Java堆内存配置项 Java提供了许多内存配置项，我们可以使用它们来设置内存大小及其比例，常用的如下： VM Switch 描述 -Xms 用于在JVM启动时设置初始堆大小 -Xmx 用于设置最大堆大小 -Xmn 设置新生区的大小，剩下的空间用于老年区 -XX：PermGen 用于设置永久区存初始大小 -XX：MaxPermGen 用于设置Perm Gen的最大尺寸 -XX：SurvivorRatio 提供Eden区域的比例 -XX：NewRatio 用于提供老年代/新生代大小的比例，默认值为2 名词术语 Full GC：新生代和老年代同时回收 References: https://mp.weixin.qq.com/s/3_DEPdZTnGmdGBd5iTrVjQ https://www.cnblogs.com/manayi/p/9290490.html"},{"title":"Mac平台搭建Golang环境","date":"2019-08-08T04:10:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/08/Mac平台搭建Golang环境/","permalink":"https://binchencoder.github.io/2019/08/08/Mac%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BAGolang%E7%8E%AF%E5%A2%83/","excerpt":"","text":"Overview我大概是在两年前开始接触Golang语言，当时我们公司在北美成立研发中心，核心成员都是来自Google、微软等世界一流互联网公司。那时起我们才真正有了CTO这个职位。他来自Google，所以把Google的核心开发语言Golang带到我们公司并大力推广。要求全员学习Golang。 当时业务部门的同事都比较抵触学习Golang，包括我在内。大家都把Java语言当作了吃饭的饭碗，认为Golang是一门比较难的语言，不情愿在这个上面花时间。后来事实证明当初的想法是错误的，其实Golang入门还是很容易的，包括搭建环境，相比较Java而言，要容易的多。 听我啰嗦了这么多，大家可不要认为Golang就是万能的。任何一门语言都有其优点和缺点，Golang也不例外。 优点 Golang语法简单，可读性非常高，入门容易 基于 goroutines 和 channels 的简单并发编程 丰富的标准库 Golang性能优越 语言层面定义源代码的格式化 标准化的测试框架 Golang程序编译快，方便操作 Defer声明，避免忘记清理 方法多返回值：定义function可以返回多个值 缺点 Golang忽略了现代语言的进步 接口是结构类型 没有枚举 := / var 两难选择 说了这么多，让我们开始动手吧，本篇内容只会介绍如何搭建Golang开发环境 Mac搭建Golang开发环境介绍两种方式安装Golang环境 通过HomeBrew安装Homebrew有点类似于Linux操作系统中的apt-get（Ubuntu）、yum（yum），Mac的操作系统中使用它解决包依赖问题，套用官方的话来说：使用 Homebrew 安装 Apple 没有预装但 你需要的东西。 安装homebrew，已有则跳过1fabric:~ fabric$ ruby -e &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install)&quot; 安装成功则提示 12345678910&#x3D;&#x3D;&gt; Installation successful!&#x3D;&#x3D;&gt; Homebrew has enabled anonymous aggregate user behaviour analytics.Read the analytics documentation (and how to opt-out) here: https:&#x2F;&#x2F;docs.brew.sh&#x2F;Analytics.html&#x3D;&#x3D;&gt; Next steps:- Run &#96;brew help&#96; to get started- Further documentation: https:&#x2F;&#x2F;docs.brew.sh 安装Golang 首先看看有哪些Golang版本可用 123456789101112131415chenbindeMacBook-Pro:BazelWorkspace chenbin$ brew search go&#x3D;&#x3D;&gt; Formulaealgol68g gnu-go gocr google-authenticator-libpam gosu lgogdownloader percona-server-mongodbanycable-go go gocryptfs google-benchmark gotags libgosu protoc-gen-goarangodb go-bindata godep google-java-format goto mongo-c-driver pygobjectargon2 go-jira goenv google-sparsehash gource mongo-cxx-driver pygobject3aws-google-auth go-statik gofabric8 google-sql-tool govendor mongo-orchestration ringojsbogofilter go@1.10 goffice googler gowsdl mongodb spaceinvaders-gocargo-completion go@1.11 golang-migrate goolabs gox mongodb@3.0 spigotcertigo go@1.9 gollum goose gst-plugins-good mongodb@3.2 svgocgoban goaccess golo gopass gx-go mongodb@3.4 wegoclingo goad gom gor hugo mongodb@3.6 wireguard-godjango-completion gobby gomplate goreleaser jfrog-cli-go mongoose write-goodforego gobject-introspection goocanvas goreman jpegoptim pangofuego gobuster goofys gost lego pangomm 我们发现最新的有1.11可以使用 安装brew下最新版本的Golang 1fabric:~ fabric$ brew install go@1.11 配置Golang的环境变量 1chenbindeMacBook-Pro:BazelWorkspace chenbin$ vi &#x2F;Users&#x2F;chenbin&#x2F;.bash_profile NOTE: 在Linux环境下是 vim ~/.bashrc 1234export GOROOT&#x3D;&#x2F;usr&#x2F;local&#x2F;goexport GOPATH&#x3D;&#x2F;Volumes&#x2F;BazelWorkspace&#x2F;bazel-goexport PATH&#x3D;$GOROOT&#x2F;bin:$GOPATH&#x2F;bin:$PATH NOTE: GOPATH可以根据个人习惯设置为其他目录 让改动生效 1chenbindeMacBook-Pro:BazelWorkspace chenbin$ source ~&#x2F;.bash_profile 试一试Golang是否安装成功 出现以下内容，则安装成功 123456789101112131415161718192021222324252627chenbindeMacBook-Pro:BazelWorkspace chenbin$ go envGOARCH&#x3D;&quot;amd64&quot;GOBIN&#x3D;&quot;&quot;GOCACHE&#x3D;&quot;&#x2F;Users&#x2F;chenbin&#x2F;Library&#x2F;Caches&#x2F;go-build&quot;GOEXE&#x3D;&quot;&quot;GOFLAGS&#x3D;&quot;&quot;GOHOSTARCH&#x3D;&quot;amd64&quot;GOHOSTOS&#x3D;&quot;darwin&quot;GOOS&#x3D;&quot;darwin&quot;GOPATH&#x3D;&quot;&#x2F;Volumes&#x2F;BazelWorkspace&#x2F;bazel-go&quot;GOPROXY&#x3D;&quot;&quot;GORACE&#x3D;&quot;&quot;GOROOT&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;go&quot;GOTMPDIR&#x3D;&quot;&quot;GOTOOLDIR&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;go&#x2F;pkg&#x2F;tool&#x2F;darwin_amd64&quot;GCCGO&#x3D;&quot;gccgo&quot;CC&#x3D;&quot;clang&quot;CXX&#x3D;&quot;clang++&quot;CGO_ENABLED&#x3D;&quot;1&quot;GOMOD&#x3D;&quot;&quot;CGO_CFLAGS&#x3D;&quot;-g -O2&quot;CGO_CPPFLAGS&#x3D;&quot;&quot;CGO_CXXFLAGS&#x3D;&quot;-g -O2&quot;CGO_FFLAGS&#x3D;&quot;-g -O2&quot;CGO_LDFLAGS&#x3D;&quot;-g -O2&quot;PKG_CONFIG&#x3D;&quot;pkg-config&quot;GOGCCFLAGS&#x3D;&quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length&#x3D;0 -fdebug-prefix-map&#x3D;&#x2F;var&#x2F;folders&#x2F;hw&#x2F;12mwhf310xd8m8k3bhtjxqp00000gn&#x2F;T&#x2F;go-build698784611&#x3D;&#x2F;tmp&#x2F;go-build -gno-record-gcc-switches -fno-common&quot; 直接下载Golang包 直接在github下载源程序包 根据自己的需求下载适当的版本，推荐选择当下最新版本 下载地址： https://github.com/golang/go/releases 解压到你想配置的GOROOT目录 配置Golang环境变量（与通过Homebrew安装Golang的配置方式一样) END我个人推荐通过直接下载源程序包的方式安装，不仅省去了安装Homebrew的步骤，而且耗时更短。 我们开发golang的code一般放在 $GOPATH/src 目录下，下一章我会教大家如何利用工具简单而且方便的开发Golang NOTE: 提前剧透一下，大家可以先看看 https://github.com/linuxerwang/gobazel"},{"title":"Linux文件常用命令","date":"2019-08-02T09:36:21.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/02/Linux 文件常用命令/","permalink":"https://binchencoder.github.io/2019/08/02/Linux%20%E6%96%87%E4%BB%B6%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"Linux文件常用命令文件解压缩 解压 .tar.gz 和 .tgz1tar zxvf filename.tar.gz 压缩 .tar.gz 和 .tgz1tar zcvf filename.tar.gz linux下tar命令解压到指定的目录：1#tar xvf &#x2F;bbs.tar.zip -C &#x2F;zzz&#x2F;bbs 把根目录下的bbs.tar.zip解压到/zzz/bbs下，前提要保证存在/zzz/bbs这个目录这个和cp命令有点不同，cp命令如果不存在这个目录就会自动创建这个目录！附：用tar命令打包例：将当前目录下的zzz文件打包到根目录下并命名为zzz.tar.gz 1#tar zcvf &#x2F;zzz.tar.gz .&#x2F;zzz 解压 .zip1unzip filename.zip 压缩 .zip12zip filename.zip压缩一个目录使用 -r 参数， -r 递归。 例： $ zip -r filename.zip dirname 解压 .rar1rar x filename.rar 压缩 .rar1rar a filename.rar dirname 文件搜索最强大的搜索命令：findfind命令是我们在Linux系统中用来进行文件搜索用的最多的命令，功能特别强大。但是我们要说的是尽量少用find命令去执行搜索任务，就算要搜索我们也应该尽量的缩小范围，也不要在服务器使用高峰期进行文件搜索，因为搜索也是很占系统资源的。这就需要我们在进行Linux文件整理的时候，尽量规范化，什么文件放在什么目录下都要有比较好的约定。 根据文件或目录名称搜索 find 【搜索目录】【-name或者-iname】【搜索字符】：-name和-iname的区别一个区分大小写，一个不区分大小写 1234find &#x2F;etc -name init (精准搜索，名字必须为 init 才能搜索的到)find &#x2F;etc -iname init (精准搜索，名字必须为 init或者有字母大写也能搜索的到)find &#x2F;etc -name *init (模糊搜索，以 init 结尾的文件或目录名) find &#x2F;etc -name init??? (模糊搜索，？ 表示单个字符，即搜索到 init___) 根据 文件大小 搜索比如：在根目录下查找大于 100M 的文件 1find &#x2F; -size +204800 NOTE: 这里 +n 表示大于，-n 表示小于，n 表示等于1 数据块 == 512 字节 ==0.5KB，也就是1KB等于2数据块100MB == 102400KB==204800数据块 递归搜索并删除123find &#x2F;tmp&#x2F;98&#x2F;upload -name *.avi -type f -print -exec rm -rf &#123;&#125; \\;find . -name abc -type d -print -exec rm -rf &#123;&#125; \\; “.” 表示从当前目录开始递归查找 “ -name ‘*.exe’ “根据名称来查找，要查找所有以.exe结尾的文件夹或者文件 “ -type f “查找的类型为文件 “-print” 输出查找的文件目录名 最主要的是是-exec了，-exec选项后边跟着一个所要执行的命令，表示将find出来的文件或目录执行该命令。exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{}，一个空格和一个\\，最后是一个分号"},{"title":"Spring Boot中application.properties与bootstrap.properties的区别","date":"2019-07-31T16:00:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/08/01/Spring Boot中application.properties与bootstrap.properties的区别/","permalink":"https://binchencoder.github.io/2019/08/01/Spring%20Boot%E4%B8%ADapplication.properties%E4%B8%8Ebootstrap.properties%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"application.propertes (application.yml)现在使用SpringBoot是Java世界里的主流选择，它大大简化了应用初始搭建以及开发过程，该框架使用了特定的方式来进行配置，从而是开发人员不在需要定义样板化的配置。今天就带大家来了解下application.properties 使用application.properties，一般情况下主要用来配置服务中一些最基本的属性，如 数据库连接、日志相关配置。其他的用法还有 一般属性使用、自定义属性使用、属性间的引用(占位符)、随机数的使用、数据类型自动转换、嵌套属性注入 如：123456789101112spring.profiles.active&#x3D;dev,vexillary-service,skylb,file_server,kafka_monitor_0.8,metrics#gRPCgrpc.port&#x3D;6567#metricsmetrics.scrapePort&#x3D;10000# logging levellogging.level.root&#x3D;errorlogging.level.com.jingoal.grpc&#x3D;debuglogging.level.com.jingoal.approval&#x3D;debug application.properties与bootstrap.properties的区别两者主要区别是加载顺序不同，bootstrap.properties在application.properties 之前加载，bootstrap.properties用于应用程序上下文的引导阶段 典型场景 当时用Spring Cloud Config Server的时候，你应该在bootstraop.properties里面指定spring.application.name 和 spring.cloud.config.server.git.uri 一些加密/解密的信息 技术上, bootstrap.properties由父Spring ApplicationContext加载。父ApplicationContext 被加载到使用application.properties的之前。 当使用SpringCloud的时候，配置信息一般是从config server加载的，为了取得配置信息（比如密码等），你需要一些提早的或引导配置。因此，把config server信息放在bootstrap.properties，用来加载真正需要的配置信息。 属性覆盖问题启动上下文时，Spring Cloud会创建一个BootStrap Context，作为Spring应用的Application Context的父上下文。初始化的时候，Bootstrap Context负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的Environment。 Bootstrap属性有高优先级，默认情况下，他们不会被本地配置覆盖。Bootstrap Context和Application Context有着不同的约定，所以新增了一个bootstrap.properties，而不是使用application.properties。保证Bootstrap Context和Application Context配置的分离。"},{"title":"MySQL优化原理","date":"2019-07-29T14:10:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/07/29/MySQL优化原理/","permalink":"https://binchencoder.github.io/2019/07/29/MySQL%E4%BC%98%E5%8C%96%E5%8E%9F%E7%90%86/","excerpt":"","text":"前言说起MySQL的查询优化，相信大家收藏了一堆奇技淫巧：不能使用SELECT *、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。 MySQL逻辑架构如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。 MySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。 MySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。 最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。 MySQL查询过程我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。 当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？ 客户端/服务端通信协议MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。 客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。 与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。 查询缓存在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。 MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。 如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。 既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外： 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗 基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如： 用多个小表代替一个大表，注意不要过度设计 批量插入代替循环单条插入 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存 最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。"},{"title":"Linux查看系统硬件信息","date":"2019-07-29T05:36:21.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/07/29/Linux查看系统硬件信息/","permalink":"https://binchencoder.github.io/2019/07/29/Linux%E6%9F%A5%E7%9C%8B%E7%B3%BB%E7%BB%9F%E7%A1%AC%E4%BB%B6%E4%BF%A1%E6%81%AF/","excerpt":"","text":"Linux查看系统硬件信息查看当前操作系统内核信息12chenbin@chenbin-ThinkPad:~$ uname -aLinux chenbin-ThinkPad 4.15.0-36-generic #39-Ubuntu SMP Mon Sep 24 16:19:09 UTC 2018 x86_64 x86_64 x86_64 GNU&#x2F;Linux 查看当前操作系统发行版信息12chenbin@chenbin-ThinkPad:~$ cat &#x2F;etc&#x2F;issueUbuntu 18.04.1 LTS \\n \\l CPUCPU详细信息1234567891011121314151617181920212223242526ubuntu@mini-11:~$ lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bit #CPU 运行模式Byte Order: Little Endian #字节序CPU(s): 4 #CPU个数On-line CPU(s) list: 0-3 #在线 CPU 列表Thread(s) per core: 2 #每个核的线程数Core(s) per socket: 2 #每个cpu插槽核数&#x2F;每颗物理cpu核数Socket(s): 1 #CPU插槽数NUMA node(s): 1 #NUMA 节点Vendor ID: GenuineIntel #厂商 IDCPU family: 6 #CPU系列Model: 69 #型号Model name: Intel(R) Core(TM) i7-4600U CPU @ 2.10GHzStepping: 1CPU MHz: 2290.247 #CPU MHzCPU max MHz: 3300.0000 #CPU 最大 MHzCPU min MHz: 800.0000 #CPU 最小 MHzBogoMIPS: 5387.11Virtualization: VT-xL1d cache: 32K #一级缓存32K（google了下，这具体表示表示cpu的L1数据缓存为32k）L1i cache: 32K #一级缓存32K（具体为L1指令缓存为32K）L2 cache: 256K #二级缓存256KL3 cache: 4096K #三级缓存4096KNUMA node0 CPU(s): 0-3Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm abm cpuid_fault epb invpcid_single pti tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts NOTE: 查看/proc/cpuinfo,可以知道每个cpu信息，如每个CPU的型号，主频等 查看物理CPU个数123[root@DB-Server ~]# cat &#x2F;proc&#x2F;cpuinfo | grep &quot;physical id&quot; | sort | uniq | wc -l[root@DB-Server ~]# dmesg | grep CPU | grep &quot;Physical Processor ID&quot; | uniq | wc -l 查看逻辑CPU个数123[root@DB-Server ~]# cat &#x2F;proc&#x2F;cpuinfo | grep &quot;processor&quot; | wc -l[root@DB-Server ~]# dmesg | grep &quot;CPU&quot; | grep &quot;processor&quot; | wc -l 查看CPU是几核的123[root@DB-Server ~]# cat &#x2F;proc&#x2F;cpuinfo | grep &quot;cores&quot; | uniqcpu cores : 3 查看CPU的主频1234567[root@DB-Server ~]# cat &#x2F;proc&#x2F;cpuinfo | grep MHz | uniqcpu MHz : 800.000[root@DB-Server ~]# cat &#x2F;proc&#x2F;cpuinfo | grep MHzcpu MHz : 800.000cpu MHz : 800.000cpu MHz : 800.000 查看CPU型号信息123[root@DB-Server ~]# cat &#x2F;proc&#x2F;cpuinfo | grep name | cut -f2 -d: | uniq -c3 AMD Athlon(tm) II X3 450 Processor 通过physical id 可以判断物理CPU个数1234567[root@DB-Server ~]# cat &#x2F;proc&#x2F;cpuinfo | grep physical | uniq -cphysical id : 0address sizes : 48 bits physical, 48 bits virtualphysical id : 0address sizes : 48 bits physical, 48 bits virtualphysical id : 0address sizes : 48 bits physical, 48 bits virtual 查看CPU是否支持64位运算1234[root@DB-Server ~]# cat &#x2F;proc&#x2F;cpuinfo | grep flags | grep &#39;lm&#39; | wc -l3结果大于0，说明支持64位运算，lm指long mode 支持lm则是64bit 1234[root@DB-Server ~]# getconf LONG_BITetl:&#x2F;home&#x2F;etl&#x2F;$getconf LONG_BIT（另外一台服务器）说明当前CPU运行在32位模式下，当不代表CPU不支持64位 查看内存信息1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@DB-Server ~]# more &#x2F;proc&#x2F;meminfoMemTotal: 7541288 kBMemFree: 215388 kBBuffers: 186228 kBCached: 6433572 kBSwapCached: 77404 kBActive: 5489928 kBInactive: 1346252 kBActive(anon): 5193596 kBInactive(anon): 1015024 kBActive(file): 296332 kBInactive(file): 331228 kBUnevictable: 0 kBMlocked: 0 kBSwapTotal: 9781240 kBSwapFree: 9430432 kBDirty: 0 kBWriteback: 0 kBAnonPages: 139432 kBMapped: 3878064 kBShmem: 5992240 kBSlab: 328284 kBSReclaimable: 159572 kBSUnreclaim: 168712 kBKernelStack: 2056 kBPageTables: 99256 kBNFS_Unstable: 0 kBBounce: 0 kBWritebackTmp: 0 kBCommitLimit: 13551884 kBCommitted_AS: 6943792 kBVmallocTotal: 34359738367 kBVmallocUsed: 301620 kBVmallocChunk: 34359431420 kBHardwareCorrupted: 0 kBAnonHugePages: 30720 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBDirectMap4k: 8128 kBDirectMap2M: 2611200 kBDirectMap1G: 5242880 kB"},{"title":"RPC框架","date":"2019-07-21T10:00:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/07/21/RPC框架/","permalink":"https://binchencoder.github.io/2019/07/21/RPC%E6%A1%86%E6%9E%B6/","excerpt":"","text":"前言大概是三年前我开始接触RPC，那时作为一个刚入职场三年的新兵，在公司技术架构决策层上还没有什么发言权。一直沿用前辈搭建的技术架构来开发应用系统，当时还没有前后端分离，采用的框架是Spring MVC + JSP，每个应用服务都是一个war，服务间的调用是通过共享访问数据库的代码包(jar)来实现，现在想想那时的技术是真的Low，导致现在欠了很多的技术债，直到现在我们也还在努力的还债。 后来随着服务不断增加，而且服务之前还需要互相调用，这种方式导致维护的成本越来越高。这时领导才下定决心要重构技术架构，要引入微服务并进行前后端分离，这才拉开了服务化的进程，从那时起我们开始引入RPC框架。 本片文章我会带领大家来了解这几个方面的内容：什么是RPC，为什么要使用RPC以及常见的RPC框架。 RPC简介RPC 是远程过程调用（Remote Procedure Call）的缩写形式，Birrell 和 Nelson 在 1984 发表于 ACM Transactions on Computer Systems 的论文《Implementing remote procedure calls》对 RPC 做了经典的诠释。RPC 是指计算机 A 上的进程，调用另外一台计算机 B 上的进程，其中 A 上的调用进程被挂起，而 B 上的被调用进程开始执行，当值返回给 A 时，A 进程继续执行。调用方可以通过使用参数将信息传送给被调用方，而后可以通过传回的结果得到信息。而这一过程，对于开发人员来说是透明的。上图描述了数据报在一个简单的RPC传递的过程 当两个物理分离的子系统需要建立逻辑上的关联时，RPC 是牵线搭桥的常见技术手段之一。除 RPC 之外，常见的多系统数据交互方案还有分布式消息队列、HTTP 请求调用、数据库和分布式缓存等。 其中 RPC 和 HTTP 调用是没有经过中间件的，它们是端到端系统的直接数据交互。HTTP 调用其实也可以看成是一种特殊的 RPC，只不过传统意义上的 RPC 是指长连接数据交互，而 HTTP 一般是指即用即走的短链接。 RPC 在我们熟知的各种中间件中都有它的身影。Nginx/Redis/MySQL/Dubbo/Hadoop/Spark/Tensorflow 等重量级开源产品都是在 RPC 技术的基础上构建出来的，我们这里说的 RPC 指的是广义的 RPC，也就是分布式系统的通信技术。RPC 在技术中的地位好比我们身边的空气，它无处不在，但是又有很多人根本不知道它的存在。 为什么要使用RPC 首先要明确一点：RPC可以用HTTP协议实现，并且用HTTP是建立在TCP之上最广泛使用的RPC，但是互联网公司往往用自己的私有协议，比如鹅厂的JCE协议，私有协议不具备通用性为什么还要用呢？因为相比于HTTP协议，RPC采用二进制字节码传输，更加高效也更加安全。 现在业界提倡“微服务”的概念，而服务之间通信目前有两种方式，RPC就是其中一种。RPC可以保证不同服务之间的互相调用。即使是跨语言跨平台也不是问题，让构建分布式系统更加容易。 RPC框架都会有服务降级，流程控制的功能，保证服务的高可用。 RPC框架要想了解一个RPC框架是如何实现的，首先要明白以下几点： Call ID映射 我们怎么告诉远程机器我们要调用Multiply，而不是Add或者FooBar呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用Multiply，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。 序列化和反序列化 客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。 网络传输 远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西 常用的RPC框架常用的RPC框架在语言上支持Java的最多，golang次之 Netty - Netty框架不局限于RPC，更多的是作为一种网络协议的实现框架，比如HTTP，由于RPC需要高效的网络通信，就可能选择以Netty作为基础。 brpc是一个基于protobuf接口的RPC框架，在百度内部称为“baidu-rpc”，它囊括了百度内部所有RPC协议，并支持多种第三方协议，从目前的性能测试数据来看，brpc的性能领跑于其他同类RPC产品。 Dubbo是Alibaba开发的一个RPC框架，远程接口基于Java Interface, 依托于Spring框架。 gRPC的Java实现的底层网络库是基于Netty开发而来，其Go实现是基于net库。 Thrift是Apache的一个项目(http://thrift.apache.org)，前身是Facebook开发的一个RPC框架，采用thrift作为IDL (Interface description language)。 jsonrpc END后面我会继续发文深入介绍gRPC框架和在工作中是如何应用gRPC框架的"},{"title":"MySQL中 乐观锁、悲观锁、共享锁、排它锁、行锁、表锁的理解","date":"2019-01-20T02:00:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2019/01/20/MySQL锁的理解/","permalink":"https://binchencoder.github.io/2019/01/20/MySQL%E9%94%81%E7%9A%84%E7%90%86%E8%A7%A3/","excerpt":"","text":"前言MySQL/InnoDB的加锁，一直是一个面试中常见的话题。例如，数据库如果有高并发请求，如果保证数据完整性？产生死锁问题如何排查并解决？我在工作过程中，也会经常用到，乐观锁，排它锁 等。最近针对这几个概念进行学习，记录一下。 注: MySQL是一个支持插件式存储引擎的数据库系统。本文下面的所有介绍，都是基于InnoDB存储引擎，其他引擎的表现，会有较大的区别。 查看存储引擎MySQL给开发者提供了查询存储引擎的功能，我这里使用的是MySQL5.6.4，可以使用： 1SHOW ENGINES 乐观锁用数据版本(Version)记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库增加一个数字类型的“version”字段来实现。当读数据时，将version字段的值一同读出，数据每更新一次，对此version值加1。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次读取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。 举例 数据库表设计 三个字段，分别是id、value、version 1select id,value,version from TABLE where id&#x3D;#&#123;id&#125; 每次更新表中的value字段时，为了防止发生冲突，需要这样操作 123update TABLEset value&#x3D;2,version&#x3D;version+1where id&#x3D;#&#123;id&#125; and version&#x3D;#&#123;version&#125;; 悲观锁与乐观锁相对应的就是悲观锁了。悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟java中synchronized很相似，所以悲观锁需要耗费较多的时间。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。 说到这里，由悲观锁涉及到的另外两个概念就出来了，他们就是共享锁与排它锁。共享锁和排它锁是悲观锁的不同实现，它俩都属于悲观锁的范畴。 使用排它锁举例： 要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用autocommit模式，也就是说，当你执行一个更新操作时，MySQL会立刻将结果进行提交。 我们可以使用命令设置MySQL为非autocommit模式： 1234567891011121314151617181920212223set autocommit&#x3D;0;# 设置完autocommit后，我们就可以执行我们的正常业务了。具体如下：# 1. 开始事务begin;&#x2F;begin work;&#x2F;start transaction; (三者选一就可以)# 2. 查询表信息select status from TABLE where id&#x3D;1 for update;# 3. 插入一条数据insert into TABLE (id,value) values (2,2);# 4. 修改数据为update TABLE set value&#x3D;2 where id&#x3D;1;# 5. 提交事务commit;&#x2F;commit work; 共享锁共享锁又称读锁 read lock，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。 如果事务T对数据A加上共享锁后，则其他事务只能对数据A再加共享锁，不能加排他锁。获得共享锁的事务只能读数据，不能修改数据 排他锁排他锁 exclusive lock（也叫writer lock）又称写锁。 排它锁是悲观锁的一种实现，在上面悲观锁也介绍过。 若事务 1 对数据对象A加上X锁，事务 1 可以读A也可以修改A，其他事务不能再对A加任何锁，直到事物 1 释放A上的锁。这保证了其他事务在事物 1 释放A上的锁之前不能再读取和修改A。排它锁会阻塞所有的排它锁和共享锁 读取为什么要加读锁呢：防止数据在被读取的时候被别的线程加上写锁， 使用方式：在需要执行的语句后面加上for update就可以了 行锁行锁又分共享锁和排他锁,由字面意思理解，就是给某一行加上锁，也就是一条记录加上锁。 NOTE: 行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。 表锁如何加表锁 innodb 的行锁是在有索引的情况下,没有索引的表是锁定全表的. Innodb中的行锁与表锁 前面提到过，在Innodb引擎中既支持行锁也支持表锁，那么什么时候会锁住整张表，什么时候或只锁住一行呢？只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ 在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。 行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。 死锁死锁（Deadlock） 所谓死锁：是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。由于资源占用是互斥的，当某个进程提出申请资源后，使得有关进程在无外力协助下，永远分配不到必需的资源而无法继续运行，这就产生了一种特殊现象死锁。 下列方法有助于最大限度地降低死锁： 按同一顺序访问对象。 避免事务中的用户交互。 保持事务简短并在一个批处理中。 使用低隔离级别。 使用绑定连接。"},{"title":"如何查看MariaDB bin log","date":"2018-09-04T13:53:08.000Z","updated":"2019-12-02T02:08:24.481Z","comments":true,"path":"2018/09/04/查看MariaDB-binlog/","permalink":"https://binchencoder.github.io/2018/09/04/%E6%9F%A5%E7%9C%8BMariaDB-binlog/","excerpt":"","text":"MariaDB bin log今天在学习MariaDB在产线的部署架构时，重新了解了主从复制的原理，同时产生想查看bin log的好奇心，折腾了一番最终搞定 MariaDB主从复制 MySQL的复制就是基于二进制日志而完成的，其工作原理如下： 当MySQL的Master节点的数据有更改的时候，Master会主动通知Slave，让Slave主动来Master获取二进制日志，于是Slave开启一个I/O thread，向Master请求二进制日志中记录的语句；Master将二进制日志中记录的语句发给Slave，Slave则将这些语句存到中继日志中，进而从中继日志中读取一句，执行一句，直到所有的语句被执行完。而经SQL语句从中继日志中读取出来，再一一执行的进程叫做SQL thread；将这些语句执行完之后，从节点的数据就和主节点的数据相同了，这就是所谓的MySQL主从复制。 查看bin log在我们的一个测试环境上，通过如下命令查看 1234567891011121314151617181920212223242526272829MariaDB [(none)]&gt; show binary logs;1381 - You are not using binary loggingMariaDB [(none)]&gt; show variables like &#39;log_bin&#39;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | OFF |+---------------+-------+错误原因：测试环境中部署的实例没有开启bin logMariaDB [(none)]&gt; set global log_bin_trust_function_creators&#x3D;1;MariaDB [(none)]&gt; show variables like &#39;log_bin_trust_function_creators&#39;;+---------------------------------+-------+| Variable_name | Value |+---------------------------------+-------+| log_bin_trust_function_creators | ON |+---------------------------------+-------+这样添加了参数以后，如果mysqld重启，那个参数又会消失，因此记得在my.cnf配置文件中添加：log_bin_trust_function_creators&#x3D;1log_bin&#x3D;mysql_bin添加参数之后重启mysql 123456MariaDB [(none)]&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql_bin.000001 | 217795 |+------------------+-----------+ 123456789101112131415[root@mariadb bin]# mysqlbinlog –no-defaults mysql-bin.00001;&#x2F;*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE&#x3D;1*&#x2F;;&#x2F;*!40019 SET @@session.max_insert_delayed_threads&#x3D;0*&#x2F;;&#x2F;*!50003 SET @OLD_COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;0*&#x2F;;DELIMITER &#x2F;*!*&#x2F;;mysqlbinlog: File &#39;&#39; not found (Errcode: 2)DELIMITER ;# End of log fileROLLBACK &#x2F;* added by mysqlbinlog *&#x2F;;&#x2F;*!50003 SET COMPLETION_TYPE&#x3D;@OLD_COMPLETION_TYPE*&#x2F;;&#x2F;*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE&#x3D;0*&#x2F;; 遗留问题从上面Mariadb复制原理中我认为bin log记录的master上执行的sql语句，但是为什么bin log看不到呢？"},{"title":"使用正则引发的血案","date":"2018-09-01T13:43:21.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2018/09/01/使用正则引发的血案/","permalink":"https://binchencoder.github.io/2018/09/01/%E4%BD%BF%E7%94%A8%E6%AD%A3%E5%88%99%E5%BC%95%E5%8F%91%E7%9A%84%E8%A1%80%E6%A1%88/","excerpt":"","text":"正则表达式正则表达式, 一个十分古老而又强大的文本处理工具, 仅仅用一段非常简短的表达式语句, 便能够快速实现一个非常复杂的业务逻辑. 熟练地掌握正则表达式的话, 能够使你的开发效率得到极大的提升. 对于一些简单的表单式语句我们可以自己编写, 但是复杂一些并且通用的表达式我们往往会从网上直接拷贝来用. 经过大部分人实践过的一般不会出现问题, 但是偶尔也会踩坑. 最近我就在这个上面掉进了深坑. 案发最近产线上的一个服务连续两天出现问题, 现象就是访问出现 “502 Bad Gateway” 错误. 这个服务是部署在Tomcat下的, 字面上理解就是网关出现问题了, 第一次出现问题后为了紧急修复就直接重启了服务器, 重启后就正常了. 这次事故就这样草草收场，没有留下任何有用的日志信息用来分析, 就没有继续追查下去了. 偷懒是会受到惩罚的. 果不其然, 第二天问题继续出现, 并且还引起了其他的故障. 有了前车之鉴, 这一次受到了足够重视. 为了尽快恢复服务, 重启了部分节点用来恢复产线服务. 留了一个故障节点来断案. 断案排查思路 系统本身代码有问题, 如果是这样, 通过查看日志应该能发现集中的日志. 但是却没有, 初步排除代码逻辑处理错误 内部下游系统的问题导致的雪崩效应, 我们联系了内部下游系统观察了他们的监控，发现一起正常。可以排除下游系统故障对我们的影响 机器本身的问题, 查看机器监控, 排除机器故障问题。 即通过上述方法没有直接定位到问题。 解决方案之前为了快速恢复服务, 我们留下了一个故障节点, 从产线上摘除, 重启了其他节点恢复服务. 下面通过jstack来分析故障 查看当前Tomcat线程pid 12[root@xxx ~]# ps -ef | grep tomcatroot 142 1 0 Aug20 ? 02:46:26 &#x2F;usr&#x2F;local&#x2F;jdk&#x2F;jre&#x2F;bin&#x2F;java -Djava.util.logging.config.file&#x3D;&#x2F;usr&#x2F;local&#x2F;tomcat_xxx&#x2F;conf&#x2F;logging.properties -Djava.util.logging.manager&#x3D;org.apache.juli.ClassLoaderLogManager -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;tmp&#x2F;tomcat_xxx&#x2F; -server -Xmx512m -Xms512m -XX:NewSize&#x3D;64m -XX:MaxNewSize&#x3D;128m -Djava.library.path&#x3D;&#x2F;usr&#x2F;local&#x2F;apr&#x2F;lib -Dsun.lang.ClassLoader.allowArraySyntax&#x3D;true -Djava.net.preferIPv4Stack&#x3D;true -XX:PermSize&#x3D;64M -XX:MaxPermSize&#x3D;378m -Dcom.sun.management.jmxremote.authenticate&#x3D;false -Dcom.sun.management.jmxremote.ssl&#x3D;false -Dcom.sun.management.jmxremote.port&#x3D;7080 -Dcom.sun.management.jmxremote -classpath &#x2F;usr&#x2F;local&#x2F;tomcat_igoal&#x2F;bin&#x2F;bootstrap.jar -Dcatalina.base&#x3D;&#x2F;usr&#x2F;local&#x2F;tomcat_igoal -Dcatalina.home&#x3D;&#x2F;usr&#x2F;local&#x2F;tomcat_igoal -Djava.io.tmpdir&#x3D;&#x2F;usr&#x2F;local&#x2F;tomcat_igoal&#x2F;temp org.apache.catalina.startup.Bootstrap start 打印jstack日志 1[root@xxx ~]# jstack -l 142 &gt; &#x2F;tmp&#x2F;jstack.txt jstack.txt 文件中的内容很多， 根据关键字(程序中的包名或者类名 等) 找到匹配的内容分析线程状态 如何分析线程状态，可以查看我博客中的一篇文章 Thread State 我通过查找 ‘xxx’ 关键字找到很多内容， 但是有些是正常的，就直接过滤掉。最后找到这样一段内容，发现jstack日志中大量重复出现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146&quot;http-192.168.0.185-12491-600&quot; #4971 daemon prio&#x3D;5 os_prio&#x3D;0 tid&#x3D;0x00007f59a0334000 nid&#x3D;0x1e7e runnable [0x00007f58c7ffc000] java.lang.Thread.State: RUNNABLE at java.util.regex.Pattern$5.isSatisfiedBy(Pattern.java:5251) at java.util.regex.Pattern$5.isSatisfiedBy(Pattern.java:5251) at java.util.regex.Pattern$CharProperty.match(Pattern.java:3776) at java.util.regex.Pattern$Curly.match(Pattern.java:4227) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.match(Pattern.java:4785) at java.util.regex.Pattern$GroupTail.match(Pattern.java:4717) at java.util.regex.Pattern$Ques.match(Pattern.java:4182) at java.util.regex.Pattern$Curly.match0(Pattern.java:4272) at java.util.regex.Pattern$Curly.match(Pattern.java:4234) at java.util.regex.Pattern$GroupHead.match(Pattern.java:4658) at java.util.regex.Pattern$Loop.matchInit(Pattern.java:4804) at java.util.regex.Pattern$Prolog.match(Pattern.java:4741) at java.util.regex.Pattern$Begin.match(Pattern.java:3525) at java.util.regex.Matcher.match(Matcher.java:1270) at java.util.regex.Matcher.matches(Matcher.java:604) at com.xxx.xxx.util4sysmng.ValidateUtil.checkEmail(ValidateUtil.java:30) at com.xxx.xxx.register.action.RegisterController.regAccountSendVcode(RegisterController.java:538) at com.xxx.xxx.register.action.RegisterController$$FastClassByCGLIB$$58ed8719.invoke(&lt;generated&gt;) at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:191) at org.springframework.aop.framework.Cglib2AopProxy$CglibMethodInvocation.invokeJoinpoint(Cglib2AopProxy.java:689) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:150) at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:80) at com.xxx.prometheus.aspect.PrometheusAspect.process(PrometheusAspect.java:35) at sun.reflect.GeneratedMethodAccessor121.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:621) at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:610) at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:65) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:161) at org.springframework.aop.framework.adapter.ThrowsAdviceInterceptor.invoke(ThrowsAdviceInterceptor.java:124) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:90) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172) at org.springframework.aop.framework.Cglib2AopProxy$DynamicAdvisedInterceptor.intercept(Cglib2AopProxy.java:622) at com.xxx.xxx.register.action.RegisterController$$EnhancerByCGLIB$$972a02bd.regAccountSendVcode(&lt;generated&gt;) at sun.reflect.GeneratedMethodAccessor124.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:212) at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:126) at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:96) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:617) at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:578) at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:80) at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:900) at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:827) at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:882) at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:778) at javax.servlet.http.HttpServlet.service(HttpServlet.java:617) at javax.servlet.http.HttpServlet.service(HttpServlet.java:723) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at com.xxx.xxx.sysmng.filter.SysmngSecurityFilter.doFilter(SysmngSecurityFilter.java:46) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:88) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:76) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191) at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:615) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293) at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:861) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:606) at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489) at java.lang.Thread.run(Thread.java:745) 通过上面这段内容分析，在正则验证时出现大量线程等待，一直消耗系统CPU，最终造成服务处于假死状态，无法响应。 定位到具体的代码，经过测试 确认是验证Email的一个正则表达式有问题。代码中使用的Email正则表达式是这样写的：1^([a-z0-9A-Z]+[-|\\\\._]?)+[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\\\.)+[a-zA-Z]&#123;2,&#125;$ 测试代码123456789@Testpublic void testRegexFailed() &#123; String email &#x3D; &quot;dnjnfslkffkjkjkslioeo9edkdjfks&quot;; String regex &#x3D; &quot;^([a-z0-9A-Z]+[-|_|\\\\\\\\.]?)*[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\\\\\\\.)+[a-z0-9A-Z]&#123;2,&#125;$&quot;; Pattern pattern &#x3D; Pattern.compile(regex); Matcher matcher &#x3D; pattern.matcher(email); System.out.println(email + &quot; : &quot; + matcher.matches());&#125; 这段代码会出现死循环，使我电脑消耗CPU急剧增加，我在测试过程中打印了该进程消耗系统资源的数据1234567891011121314151617181920212223242526chenbin@chenbin-ThinkPad:~$ jps 23617 Launcher 21422 JUnitStarter chenbin@chenbin-ThinkPad:~$ top -Hp 21422Threads: 16 total, 1 running, 15 sleeping, 0 stopped, 0 zombie %Cpu(s): 30.8 us, 3.6 sy, 0.0 ni, 65.4 id, 0.1 wa, 0.0 hi, 0.1 si, 0.0 st KiB Mem : 7861372 total, 202784 free, 6652340 used, 1006248 buff&#x2F;cache KiB Swap: 8076284 total, 3543620 free, 4532664 used. 872480 avail Mem PID USER PR NI VIRT RES SHR S% CPU% MEM TIME+ COMMAND 21425 chenbin 20 0 4468684 100360 18136 R 99.7 1.3 0:22.25 java 21422 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21434 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21435 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21436 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21437 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21438 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21439 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21440 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21441 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21442 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21443 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.88 java 21444 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.72 java 21445 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.09 java 21446 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 21447 chenbin 20 0 4468684 100360 18136 S 0.0 1.3 0:00.00 java 测试中发现 在输入的字符串比较短的时候，验证没有问题。但是在输入字符较长，并且不符合email规则的时候，会出现死循环。如果输入过长，但是符合这个email规则，也不会有这个问题！ 结案最后我们只能修改代码，替换这个正则表达式。因为这是通过的表达式，而且比较复杂，我们就没有造轮子。直接在网上找的, 经过验证，发现这个网站提供的正则比较靠谱Java Email Address Validation END能匹配空字符串的子匹配不要循环无限次。如果括号内的子表达式中的每一部分都可以匹配 0 次，而这个括号整体又可以匹配无限次，匹配过程中可能死循环。虽然现在有些正则表达式引擎已经通过办法避免了这种情况出现死循环了，比如 .NET 的正则表达式，但是我们仍然应该尽量避免出现这种情况。如果我们在写表达式时遇到了死循环，也可以从这一点入手。 正则表达式虽然使用起来很方便, 但是一定要慎用."},{"title":"Thread State","date":"2018-08-31T12:53:08.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2018/08/31/Thread-State/","permalink":"https://binchencoder.github.io/2018/08/31/Thread-State/","excerpt":"","text":"Java 线程状态分析Java线程的生命周期中, 存在着六种状态. 在Thread类里有一个枚举类型State, 定义了线程的几种状态. 下图比较清晰的展示了这六种状态之间的转换关系 NEW: 线程创建之后，但是还没有启动(not yet started)。这时候它的状态就是NEW RUNNABLE: 正在Java虚拟机下跑任务的线程的状态。在RUNNABLE状态下的线程可能会处于等待状态， 因为它正在等待一些系统资源的释放，比如IO BLOCKED: 阻塞状态，等待锁的释放，比如线程A进入了一个synchronized方法，线程B也想进入这个方法，但是这个方法的锁已经被线程A获取了，这个时候线程B就处于BLOCKED状态 WAITING: 等待状态，处于等待状态的线程是由于执行了3个方法中的任意方法。 Object的wait方法，并且没有使用timeout参数; Thread的join方法，没有使用timeout参数 LockSupport的park方法。 处于waiting状态的线程会等待另外一个线程处理特殊的行为。 再举个例子，如果一个线程调用了一个对象的wait方法，那么这个线程就会处于waiting状态直到另外一个线程调用这个对象的notify或者notifyAll方法后才会解除这个状态 TIMED_WAITING: 有等待时间的等待状态，比如调用了以下几个方法中的任意方法，并且指定了等待时间，线程就会处于这个状态。 Thread.sleep方法 Object的wait方法，带有时间 Thread.join方法，带有时间 LockSupport的parkNanos方法，带有时间 LockSupport的parkUntil方法，带有时间 TERMINATED: 线程中止的状态，这个线程已经完整地执行了它的任务 NEW StateNEW状态比较简单，实例化一个线程之后，并且这个线程没有开始执行，这个时候的状态就是NEW：12Thread thread &#x3D; new Thread();System.out.println(thread.getState()); &#x2F;&#x2F; NEW RUNNABLE State正在运行的状态123456789Thread thread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i &#x3D; 0; i &lt; Integer.MAX_VALUE; i ++) &#123; System.out.println(i); &#125; &#125;&#125;, &quot;RUNNABLE-Thread&quot;);thread.start(); 使用jstack查看线程状态： 123456789101112131415161718192021&quot;RUNNABLE-Thread&quot; #10 prio&#x3D;5 os_prio&#x3D;31 tid&#x3D;0x00007f8e04981000 nid&#x3D;0x4f03 runnable [0x000070000124c000] java.lang.Thread.State: RUNNABLE at java.io.FileOutputStream.writeBytes(Native Method) at java.io.FileOutputStream.write(FileOutputStream.java:315) at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82) at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140) - locked &lt;0x000000079764cc50&gt; (a java.io.BufferedOutputStream) at java.io.PrintStream.write(PrintStream.java:482) - locked &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221) at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:291) at sun.nio.cs.StreamEncoder.flushBuffer(StreamEncoder.java:104) - locked &lt;0x0000000797604d78&gt; (a java.io.OutputStreamWriter) at java.io.OutputStreamWriter.flushBuffer(OutputStreamWriter.java:185) at java.io.PrintStream.write(PrintStream.java:527) - eliminated &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at java.io.PrintStream.print(PrintStream.java:597) at java.io.PrintStream.println(PrintStream.java:736) - locked &lt;0x0000000797604dc0&gt; (a java.io.PrintStream) at study.thread.ThreadStateTest$1.run(ThreadStateTest.java:23) at java.lang.Thread.run(Thread.java:745) BLOCKED State线程A和线程B都需要持有lock对象的锁才能调用方法。如果线程A持有锁，那么线程B处于BLOCKED状态；如果线程B持有锁，那么线程A处于BLOCKED状态。例子中使用Thread.sleep方法主要是用于调试方便：1234567891011121314151617181920212223242526272829final Object lock &#x3D; new Object();Thread threadA &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; invoke&quot;); try &#123; Thread.sleep(20000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;BLOCKED-Thread-A&quot;);Thread threadB &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; invoke&quot;); try &#123; Thread.sleep(20000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;BLOCKED-Thread-B&quot;);threadA.start();threadB.start(); 使用jstack查看线程状态。由于线程A先执行，线程B后执行，而且线程A执行后调用了Thread.sleep方法，所以线程A会处于TIMED_WAITING状态，线程B处于BLOCKED状态：123456789101112&quot;BLOCKED-Thread-B&quot; #11 prio&#x3D;5 os_prio&#x3D;31 tid&#x3D;0x00007fa7db8ff000 nid&#x3D;0x5103 waiting for monitor entry [0x000070000134f000] java.lang.Thread.State: BLOCKED (on object monitor) at study.thread.ThreadStateTest$3.run(ThreadStateTest.java:50) - waiting to lock &lt;0x0000000795a03bf8&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745)&quot;BLOCKED-Thread-A&quot; #10 prio&#x3D;5 os_prio&#x3D;31 tid&#x3D;0x00007fa7db15a000 nid&#x3D;0x4f03 waiting on condition [0x000070000124c000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$2.run(ThreadStateTest.java:39) - locked &lt;0x0000000795a03bf8&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745) WAITING StateObject的wait方法、Thread的join方法以及Conditon的await方法都会产生WAITING状态。 1.没有时间参数的Object的wait方法1234567891011121314151617181920212223242526272829final Object lock &#x3D; new Object();Thread threadA &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; lock.wait(); System.out.println(&quot;wait over&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;, &quot;WAITING-Thread-A&quot;);Thread threadB &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.notifyAll(); &#125; &#125;&#125;, &quot;WAITING-Thread-B&quot;);threadA.start();threadB.start();WAITING-Thread-A调用了lock的wait，处于WAITING状态：123456789101112131415&quot;WAITING-Thread-B&quot; #11 prio&#x3D;5 os_prio&#x3D;31 tid&#x3D;0x00007f8de992d800 nid&#x3D;0x5103 waiting on condition [0x000070000134f000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$5.run(ThreadStateTest.java:84) - locked &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745)&quot;WAITING-Thread-A&quot; #10 prio&#x3D;5 os_prio&#x3D;31 tid&#x3D;0x00007f8dea193000 nid&#x3D;0x4f03 in Object.wait() [0x000070000124c000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Object.wait(Object.java:502) at study.thread.ThreadStateTest$4.run(ThreadStateTest.java:71) - locked &lt;0x0000000795a03e40&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:745) 2.Thread的join方法1234567891011121314151617Thread threadA &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Thread-A over&quot;); &#125;&#125;, &quot;WAITING-Thread-A&quot;);threadA.start();try &#123; threadA.join();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;主线程main处于WAITING状态：12345678910111213141516171819&quot;WAITING-Thread-A&quot; #10 prio&#x3D;5 os_prio&#x3D;31 tid&#x3D;0x00007fd2d5100000 nid&#x3D;0x4e03 waiting on condition [0x000070000124c000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at study.thread.ThreadStateTest$6.run(ThreadStateTest.java:103) at java.lang.Thread.run(Thread.java:745)&quot;main&quot; #1 prio&#x3D;5 os_prio&#x3D;31 tid&#x3D;0x00007fd2d3815000 nid&#x3D;0x1003 in Object.wait() [0x0000700000182000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000795a03ec0&gt; (a java.lang.Thread) at java.lang.Thread.join(Thread.java:1245) - locked &lt;0x0000000795a03ec0&gt; (a java.lang.Thread) at java.lang.Thread.join(Thread.java:1319) at study.thread.ThreadStateTest.WAITING_join(ThreadStateTest.java:118) at study.thread.ThreadStateTest.main(ThreadStateTest.java:13) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:483) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140) 3.没有时间参数的Condition的await方法 Condition的await方法跟Obejct的wait方法原理是一样的，故也是WAITING状态 TIMED_WAITING StateTIMED_WAITING状态跟TIMEING状态类似，是一个有等待时间的等待状态，不会一直等待下去。 最简单的TIMED_WAITING状态例子就是Thread的sleep方法：123456789101112131415161718Thread threadA &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Thread-A over&quot;); &#125;&#125;, &quot;WAITING-Thread-A&quot;);threadA.start();try &#123; Thread.sleep(5000);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;System.out.println(threadA.getState()); &#x2F;&#x2F; TIMED_WAITING 或者是Object的wait方法带有时间参数、Thread的join方法带有时间参数也会让线程的状态处于TIMED_WAITING状态。 TERMINATED State线程终止的状态，线程执行完成，结束生命周期。12345678Thread threadA &#x3D; new Thread();threadA.start();try &#123; Thread.sleep(5000l);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;System.out.println(threadA.getState()); &#x2F;&#x2F; TERMINATED END了解线程的状态可以分析一些问题。 比如线程处于BLOCKED状态，这个时候可以分析一下是不是lock加锁的时候忘记释放了，或者释放的时机不对。导致另外的线程一直处于BLOCKED状态。 比如线程处于WAITING状态，这个时候可以分析一下notifyAll或者signalAll方法的调用时机是否不对。 java自带的jstack工具可以分析查看线程的状态、优先级、描述等具体信息。"},{"title":"UsefulScripts-Java脚本","date":"2018-07-22T05:46:57.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2018/07/22/UsefulScripts-Java脚本/","permalink":"https://binchencoder.github.io/2018/07/22/UsefulScripts-Java%E8%84%9A%E6%9C%AC/","excerpt":"show-busy-java-threads.sh 用法 示例 贡献者 show-duplicate-java-classes 用法 JDK开发场景使用说明 对于一般的工程 对于Web工程 Android开发场景使用说明 示例 贡献者 find-in-jars.sh 用法 示例 参考资料","text":"show-busy-java-threads.sh 用法 示例 贡献者 show-duplicate-java-classes 用法 JDK开发场景使用说明 对于一般的工程 对于Web工程 Android开发场景使用说明 示例 贡献者 find-in-jars.sh 用法 示例 参考资料 show-busy-java-threads.sh 用于快速排查Java的CPU性能问题(top us值过高)，自动查出运行的Java进程中消耗CPU多的线程，并打印出其线程栈，从而确定导致性能问题的方法调用。 PS，如何操作可以参见@bluedavy的《分布式Java应用》的【5.1.1 cpu消耗分析】一节，说得很详细： top命令找出有问题Java进程及线程id： 开启线程显示模式 按CPU使用率排序 记下Java进程id及其CPU高的线程id 用进程id作为参数，jstack有问题的Java进程 手动转换线程id成十六进制（可以用printf %x 1234） 查找十六进制的线程id（可以用grep） 查看对应的线程栈 查问题时，会要多次这样操作以确定问题，上面过程太繁琐太慢了。 用法12345678910111213show-busy-java-threads.sh# 从 所有的 Java进程中找出最消耗CPU的线程（缺省5个），打印出其线程栈。show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt;show-busy-java-threads.sh -c &lt;要显示的线程栈数&gt; -p &lt;指定的Java Process&gt;############################### 注意：############################### 如果Java进程的用户 与 执行脚本的当前用户 不同，则jstack不了这个Java进程。# 为了能切换到Java进程的用户，需要加sudo来执行，即可以解决：sudo show-busy-java-threads.sh 示例1234567891011121314151617181920212223242526272829$ show-busy-java-threads.sh[1] Busy(57.0%) thread(23355/0x5b3b) stack of java process(23269) under user(admin):\"pool-1-thread-1\" prio=10 tid=0x000000005b5c5000 nid=0x5b3b runnable [0x000000004062c000] java.lang.Thread.State: RUNNABLE at java.text.DateFormat.format(DateFormat.java:316) at com.xxx.foo.services.common.DateFormatUtil.format(DateFormatUtil.java:41) at com.xxx.foo.shared.monitor.schedule.AppMonitorDataAvgScheduler.run(AppMonitorDataAvgScheduler.java:127) at com.xxx.foo.services.common.utils.AliTimer$2.run(AliTimer.java:128) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662)[2] Busy(26.1%) thread(24018/0x5dd2) stack of java process(23269) under user(admin):\"pool-1-thread-2\" prio=10 tid=0x000000005a968800 nid=0x5dd2 runnable [0x00000000420e9000] java.lang.Thread.State: RUNNABLE at java.util.Arrays.copyOf(Arrays.java:2882) at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:100) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:572) at java.lang.StringBuffer.append(StringBuffer.java:320) - locked &lt;0x00000007908d0030&gt; (a java.lang.StringBuffer) at java.text.SimpleDateFormat.format(SimpleDateFormat.java:890) at java.text.SimpleDateFormat.format(SimpleDateFormat.java:869) at java.text.DateFormat.format(DateFormat.java:316) at com.xxx.foo.services.common.DateFormatUtil.format(DateFormatUtil.java:41) at com.xxx.foo.shared.monitor.schedule.AppMonitorDataAvgScheduler.run(AppMonitorDataAvgScheduler.java:126) at com.xxx.foo.services.common.utils.AliTimer$2.run(AliTimer.java:128) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)... 上面的线程栈可以看出，CPU消耗最高的2个线程都在执行java.text.DateFormat.format，业务代码对应的方法是shared.monitor.schedule.AppMonitorDataAvgScheduler.run。可以基本确定： AppMonitorDataAvgScheduler.run调用DateFormat.format次数比较频繁。 DateFormat.format比较慢。（这个可以由DateFormat.format的实现确定。） 多个执行几次show-busy-java-threads.sh，如果上面情况高概率出现，则可以确定上面的判定。# 因为调用越少代码执行越快，则出现在线程栈的概率就越低。 分析shared.monitor.schedule.AppMonitorDataAvgScheduler.run实现逻辑和调用方式，以优化实现解决问题。 贡献者 silentforce改进此脚本，增加对环境变量JAVA_HOME的判断。 #15 liuyangc3 优化性能，通过read -a简化反复的awk操作 #51 发现并解决jstack非当前用户Java进程的问题 #50 show-duplicate-java-classes找出Java Lib（Java库，即Jar文件）或Class目录（类目录）中的重复类。 Java开发的一个麻烦的问题是Jar冲突（即多个版本的Jar），或者说重复类。会出NoSuchMethod等的问题，还不见得当时出问题。找出有重复类的Jar，可以防患未然。 用法 通过脚本参数指定Libs目录，查找目录下Jar文件，收集Jar文件中Class文件以分析重复类。可以指定多个Libs目录。 注意，只会查找这个目录下Jar文件，不会查找子目录下Jar文件。因为Libs目录一般不会用子目录再放Jar，这样也避免把去查找不期望Jar。 通过-c选项指定Class目录，直接收集这个目录下的Class文件以分析重复类。可以指定多个Class目录。 1234567891011# 查找当前目录下所有Jar中的重复类show-duplicate-java-classes# 查找多个指定目录下所有Jar中的重复类show-duplicate-java-classes path/to/lib_dir1 /path/to/lib_dir2# 查找多个指定Class目录下的重复类。 Class目录 通过 -c 选项指定show-duplicate-java-classes -c path/to/class_dir1 -c /path/to/class_dir2# 查找指定Class目录和指定目录下所有Jar中的重复类的Jarshow-duplicate-java-classes path/to/lib_dir1 /path/to/lib_dir2 -c path/to/class_dir1 -c path/to/class_dir2 JDK开发场景使用说明以Maven作为构建工程示意过程。 对于一般的工程123456# 在项目模块目录下执行，拷贝依赖Jar到目录target/dependency下$ mvn dependency:copy-dependencies -DincludeScope=runtime...# 检查重复类$ show-duplicate-java-classes target/dependency... 对于Web工程对于Web工程，即war maven模块，会打包生成war文件。 123456789# 在war模块目录下执行，生成war文件$ mvn install...# 解压war文件，war文件中包含了应用的依赖的Jar文件$ unzip target/*.war -d target/war...# 检查重复类$ show-duplicate-java-classes -c target/war/WEB-INF/classes target/war/WEB-INF/lib... Android开发场景使用说明Android开发，有重复类在编译打包时会报[Dex Loader] Unable to execute dex: Multiple dex files define Lorg/foo/xxx/Yyy。 但只会给出一个重复类名，如果重复类比较多时，上面打包/报错/排查会要进行多次，而Android的打包比较费时，这个过程比较麻烦，希望可以一次把所有重复类都列出来，一起排查掉。 以Gradle作为构建工程示意过程。 在App的build.gradle中添加拷贝库到目录build/dependencies下。 12345678910task copyDependencies(type: Copy) &#123; def dest = new File(buildDir, \"dependencies\") // clean dir dest.deleteDir() dest.mkdirs() // fill dir with dependencies from configurations.compile into dest&#125; 123456# 拷贝依赖$ ./gradlew app:copyDependencies...# 检查重复类$ show-duplicate-java-classes app/build/dependencies... 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ show-duplicate-java-classes WEB-INF/libCOOL! No duplicate classes found!================================================================================class paths to find:================================================================================1 : WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar2 : WEB-INF/lib/misc.htmlparser-0.0.0.jar3 : WEB-INF/lib/normandy.client-1.0.2.jar...$ show-duplicate-java-classes -c WEB-INF/classes WEB-INF/libFound duplicate classes in below class path:1 (293@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.orm-2.5.6.SEC02.jar2 (2@3): WEB-INF/lib/servlet-api-3.0-alpha-1.jar WEB-INF/lib/jsp-api-2.1-rev-1.jar WEB-INF/lib/jstl-api-1.2-rev-1.jar3 (104@2): WEB-INF/lib/commons-io-2.2.jar WEB-INF/lib/jakarta.commons.io-2.0.jar4 (6@3): WEB-INF/lib/jakarta.commons.logging-1.1.jar WEB-INF/lib/commons-logging-1.1.1.jar WEB-INF/lib/org.slf4j.jcl104-over-slf4j-1.5.6.jar5 (344@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar...================================================================================Duplicate classes detail info:================================================================================1 (293@2): WEB-INF/lib/sourceforge.spring-2.5.6.SEC02.jar WEB-INF/lib/sourceforge.spring.modules.orm-2.5.6.SEC02.jar 1 org/springframework/orm/toplink/TopLinkTemplate$13.class 2 org/springframework/orm/hibernate3/HibernateTemplate$24.class 3 org/springframework/orm/jpa/vendor/HibernateJpaDialect.class 4 org/springframework/orm/hibernate3/TypeDefinitionBean.class 5 org/springframework/orm/hibernate3/SessionHolder.class ...2 (2@3): WEB-INF/lib/servlet-api-3.0-alpha-1.jar WEB-INF/lib/jsp-api-2.1-rev-1.jar WEB-INF/lib/jstl-api-1.2-rev-1.jar 1 javax/servlet/ServletException.class 2 javax/servlet/ServletContext.class3 (104@2): WEB-INF/lib/commons-io-2.2.jar WEB-INF/lib/jakarta.commons.io-2.0.jar 1 org/apache/commons/io/input/ProxyReader.class 2 org/apache/commons/io/output/FileWriterWithEncoding.class 3 org/apache/commons/io/output/TaggedOutputStream.class 4 org/apache/commons/io/filefilter/NotFileFilter.class 5 org/apache/commons/io/filefilter/TrueFileFilter.class ......================================================================================class paths to find:================================================================================1 : WEB-INF/lib/sourceforge.spring.modules.context-2.5.6.SEC02.jar2 : WEB-INF/lib/misc.htmlparser-0.0.0.jar3 : WEB-INF/lib/normandy.client-1.0.2.jar4 : WEB-INF/lib/xml.xmlgraphics__batik-css-1.7.jar-1.7.jar5 : WEB-INF/lib/jakarta.ecs-1.4.2.jar... 贡献者tgic提供此脚本。友情贡献者的链接commandlinefu.cn|微博linux命令行精选 find-in-jars.sh在当前目录下所有jar文件里，查找类或资源文件。 用法1234find-in-jars.sh 'log4j\\.properties'find-in-jars.sh 'log4j\\.xml$' -d /path/to/find/directoryfind-in-jars.sh log4j\\\\.xmlfind-in-jars.sh 'log4j\\.properties|log4j\\.xml' 注意，后面Pattern是grep的 扩展正则表达式。 示例123$ ./find-in-jars 'Service.class$'./WEB-INF/libs/spring-2.5.6.SEC03.jar!org/springframework/stereotype/Service.class./rpc-benchmark-0.0.1-SNAPSHOT.jar!com/taobao/rpc/benchmark/service/HelloService.class 参考资料在多个Jar(Zip)文件查找Log4J配置文件的Shell命令行"},{"title":"gRPC Status and HTTP Code Relation","date":"2018-07-22T03:53:08.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2018/07/22/GRPC-Status-HTTP-Status/","permalink":"https://binchencoder.github.io/2018/07/22/GRPC-Status-HTTP-Status/","excerpt":"","text":"Status.INVALID_ARGUMENT [400] Status.OK [200] Status.CANCELLED [408] Status.UNKNOWN [500] Status.DEADLINE_EXCEEDED [408] Status.NOT_FOUND [404] Status.ALREADY_EXISTS [409] Status.PERMISSION_DENIED [403] Status.RESOURCE_EXHAUSTED [403] Status.FAILED_PRECONDITION [412] Status.ABORTED [409] Status.OUT_OF_RANGE [400] Status.UNIMPLEMENTED [501] Status.INTERNAL [500] Status.UNAVAILABLE [503] Status.DATA_LOSS [500] Status.UNAUTHENTICATED [401]"},{"title":"Hexo配合搭建github个人主页","date":"2018-07-21T10:03:18.000Z","updated":"2019-12-02T02:08:24.473Z","comments":true,"path":"2018/07/21/Hexo搭建github主页/","permalink":"https://binchencoder.github.io/2018/07/21/Hexo%E6%90%AD%E5%BB%BAgithub%E4%B8%BB%E9%A1%B5/","excerpt":"前言“工欲善其事，必先利其器”，在搭建个人博客的过程中，我深刻体会到这句话的含义。虽然早就决定了要搭建个人博客，但是我并没有草草动手，而是提前做了大量的调研工作，包括采用哪种博客系统、选择哪种主题、怎么购买并绑定个性域名等等。事实证明，正因为前期的充分准备，搭建过程才能按部就班地进行。下面先介绍为何选择GitHub Pages和Hexo来搭建博客 准备 Node js环境 Git环境","text":"前言“工欲善其事，必先利其器”，在搭建个人博客的过程中，我深刻体会到这句话的含义。虽然早就决定了要搭建个人博客，但是我并没有草草动手，而是提前做了大量的调研工作，包括采用哪种博客系统、选择哪种主题、怎么购买并绑定个性域名等等。事实证明，正因为前期的充分准备，搭建过程才能按部就班地进行。下面先介绍为何选择GitHub Pages和Hexo来搭建博客 准备 Node js环境 Git环境 检查环境安装是否正确12345678chenbin@chenbin-ThinkPad:~$ node -vv8.9.4chenbin@chenbin-ThinkPad:~$ npm -v5.6.0chenbin@chenbin-ThinkPad:~$ git --versiongit version 2.17.1如果结果如上, 则说明安装正确， 可以进行下一步了。 如果不正确， 则需要回头检查自己的安装过程 Install Hexo1$ npm install -g hexo-cli Link:https://hexo.io/zh-cn/docs/index.html 建站安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install NOTE: Init 必须是完全空的目录. 不能存在任何文件, 包括隐藏文件 新建完成后，指定文件夹的目录如下：12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 查看建站效果自动根据当前目录下文件,生成静态网页1hexo g 运行本地服务, 出现以下结果说明本地服务运行成功. 这时就可以在浏览器输入http://localhost:4000/ 就可以看到效果了.12345hexo schenbin@chenbin-ThinkPad:~&#x2F;...&#x2F;github-workspace&#x2F;Hexo-code$ hexo sINFO Start processingINFO Hexo is running at http:&#x2F;&#x2F;localhost:4000&#x2F;. Press Ctrl+C to stop. 效果图: DeployHexo提供了快速方便的一键部署功能，让您只需一条命令就能将网站部署到服务器上。 1$ hexo deploy 在开始之前，您必须先在 _config.yml 中修改参数，一个正确的部署配置中至少要有 type 参数，例如：12deploy: type: git 您可同时使用多个 deployer，Hexo 会依照顺序执行每个 deployer。12345deploy:- type: git repo:- type: heroku repo: 缩进 YAML依靠缩进来确定元素间的从属关系。因此，请确保每个deployer的缩进长度相同，并且使用空格缩进。 详细说明请查看:https://hexo.io/zh-cn/docs/configuration.html Git Deploy以下是我在本地使用Git Deploy配置的例子:123456# Deployment## Docs: https:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F;deployment.htmldeploy: type: git repository: https:&#x2F;&#x2F;github.com&#x2F;binchencoder&#x2F;binchencoder.github.io.git branch: master Install Git Deployer安装 hexo-deployer-git1$ npm install hexo-deployer-git --save 安装成功之后就可以使用Git将网站部署到指定的服务器上1234567891011chenbin@chenbin-ThinkPad:~&#x2F;...&#x2F;github-workspace&#x2F;Hexo-code$ hexo deployINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...INFO Copying files from extend dirs...位于分支 master无文件要提交，干净的工作区To https:&#x2F;&#x2F;github.com&#x2F;binchencoder&#x2F;binchencoder.github.io.git 8a8903c..dac6bed HEAD -&gt; master分支 &#39;master&#39; 设置为跟踪来自 &#39;https:&#x2F;&#x2F;github.com&#x2F;binchencoder&#x2F;binchencoder.github.io.git&#39; 的远程分支 &#39;master&#39;。INFO Deploy done: git 出现如上结果，就大功告成了。 Hexo Hello-World网站已经部署到Git服务上。就可以通过https://binchencode.github.io 地址访问部署的网站了"},{"title":"Hello World","date":"2018-07-21T07:00:18.000Z","updated":"2019-12-02T02:08:24.477Z","comments":true,"path":"2018/07/21/hello-world/","permalink":"https://binchencoder.github.io/2018/07/21/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"}]}